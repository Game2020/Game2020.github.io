<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  

  
  <title>节选：常见机器学习算法列表（Python 调用） | Game 2020</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="线性回归 逻辑回归 决策树 支持向量机 朴素贝叶斯 神经网络 K均值 随机森林 降维算法 梯度提升算法  GBM XGBoost LightGBM Catboost">
<meta property="og:type" content="article">
<meta property="og:title" content="节选：常见机器学习算法列表（Python 调用）">
<meta property="og:url" content="https://2020.iosdevlog.com/2020/03/08/algorithms/index.html">
<meta property="og:site_name" content="Game 2020">
<meta property="og:description" content="线性回归 逻辑回归 决策树 支持向量机 朴素贝叶斯 神经网络 K均值 随机森林 降维算法 梯度提升算法  GBM XGBoost LightGBM Catboost">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Linear_Regression.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Logistic_Regression.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Decision_Tree.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Jezzball.jpg">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM1.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM2.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Bayes_rule.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/KNN.webp">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Ink.jpg">
<meta property="og:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Kmenas.webp">
<meta property="article:published_time" content="2020-03-08T14:49:41.000Z">
<meta property="article:modified_time" content="2020-03-08T15:48:54.648Z">
<meta property="article:author" content="iOSDevLog">
<meta property="article:tag" content="ml">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://2020.iosdevlog.com/2020/03/08/algorithms/Linear_Regression.webp">
  
    <link rel="alternate" href="/atom.xml" title="Game 2020" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Game 2020</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">https://2020.iosdevlog.com</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/2020">2020 Calendar</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://2020.iosdevlog.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-algorithms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/08/algorithms/" class="article-date">
  <time datetime="2020-03-08T14:49:41.000Z" itemprop="datePublished">2020-03-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/algorithm/">algorithm</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      节选：常见机器学习算法列表（Python 调用）
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol type="1">
<li>线性回归</li>
<li>逻辑回归</li>
<li>决策树</li>
<li>支持向量机</li>
<li>朴素贝叶斯</li>
<li>神经网络</li>
<li>K均值</li>
<li>随机森林</li>
<li>降维算法</li>
<li>梯度提升算法
<ol type="1">
<li>GBM</li>
<li>XGBoost</li>
<li>LightGBM</li>
<li>Catboost</li>
</ol></li>
</ol>
<a id="more"></a>
<p>大致而言，共有 3 种类型的机器学习算法</p>
<ul>
<li>监督学习</li>
</ul>
<p>工作原理：此算法由目标/结果变量（或因变量）组成，该目标/结果变量将从给定的一组预测变量（因变量）中进行预测。使用这些变量集，我们生成了一个将输入映射到所需输出的函数。训练过程将继续进行，直到模型在训练数据上达到所需的准确性水平为止。</p>
<p>监督学习的例子：线性回归，决策树，随机森林，KNN，逻辑回归等。</p>
<ul>
<li>无监督学习</li>
</ul>
<p>工作原理： 在此算法中，我们没有任何目标或结果变量可以预测/估算。它用于对不同组中的人群进行聚类，广泛用于对不同组中的客户进行细分以进行特定干预。</p>
<p>无监督学习的示例：Apriori算法，K均值。</p>
<ul>
<li>强化学习：</li>
</ul>
<p>工作原理：使用此算法，机器经过训练后可以做出特定决策。它是这样工作的：机器处于反复试验不断训练自身的环境中。该机器将从过去的经验中学习，并尝试捕获最佳的知识以做出准确的业务决策。</p>
<p>强化学习的例子：马尔可夫决策过程</p>
<h2 id="常见机器学习算法列表">常见机器学习算法列表</h2>
<h3 id="线性回归">1.线性回归</h3>
<p>它用于根据连续变量估算实际价值（房屋成本，通话次数，总销售额等）。在这里，我们通过拟合一条最佳线来建立自变量和因变量之间的关系。该最佳拟合线称为回归线，并由线性方程 <span class="math inline">\(Y = a * X + b\)</span> 表示。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Linear_Regression.webp" alt="" /><figcaption>Linear_Regression</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Linear Regression</span></span><br><span class="line"><span class="string">Created by- ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Linear Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and normalize</span></span><br><span class="line"><span class="string">Documentation of sklearn LinearRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'\nCoefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'\nIntercept of model'</span>,model.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on training data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on training dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the testing dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on testing dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br></pre></td></tr></table></figure>
<h3 id="logistic回归">2. Logistic回归</h3>
<p>不要被它的名字弄糊涂了！它是一种分类，而不是回归算法。它用于基于给定的一组独立变量来估计离散值（二进制值，如 <code>0/1，yes/no，true/false</code>）。简而言之，它通过将数据拟合到logit函数来预测事件发生的可能性。因此，这也称为 <strong>对数回归</strong>。由于可以预测概率，因此其输出值介于0和1之间（如预期）。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Logistic_Regression.webp" alt="" /><figcaption>Logistic_Regression</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Logistic Regression</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(train_data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Logistic Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and penalty</span></span><br><span class="line"><span class="string">Documentation of sklearn LogisticRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'Coefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'Intercept of model'</span>,model.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="决策树">3. 决策树</h3>
<p>这是我最喜欢的算法之一，我经常使用它。它是一种监督学习算法，主要用于分类问题。令人惊讶的是，它适用于分类因变量和连续因变量。在此算法中，我们将总体分为两个或多个同构集合。这是基于最重要的属性/自变量来完成的，以尽可能地形成不同的组。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Decision_Tree.webp" alt="" /><figcaption>Decision Tree</figcaption>
</figure>
<p>理解决策树如何工作的最好方法是玩 Jezzball，这是 Microsoft 的经典游戏（下图）。本质上，您有一间活动墙的房间，您需要创建墙以使最大的区域在没有球的情况下被清除。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Jezzball.jpg" alt="" /><figcaption>Jezzball</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Decision Tree</span></span><br><span class="line"><span class="string">Created by - Analytics Vidhya</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Decision Tree model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and max_features</span></span><br><span class="line"><span class="string">Documentation of sklearn DecisionTreeClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># depth of the decision tree</span></span><br><span class="line">print(<span class="string">'Depth of the Decision Tree :'</span>, model.get_depth())</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="svm支持向量机">4. SVM（支持向量机）</h3>
<p>这是一种分类方法。在此算法中，我们将每个数据项绘制为n维空间（其中n是您拥有的特征数）中的一个点，其中每个特征的值就是特定坐标的值。</p>
<p>例如，如果我们只有两个特征，例如一个人的身高和头发长度，我们首先将这两个变量绘制在二维空间中，其中每个点都有两个坐标（这些坐标称为支持向量）</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM1.webp" alt="" /><figcaption>SVM1</figcaption>
</figure>
<p>现在，我们将找到一行将数据划分为两个不同分类的数据组。这条线将使距两组中最近点的距离最远。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM2.webp" alt="" /><figcaption>SVM2</figcaption>
</figure>
<p>在上面显示的示例中，将数据分为两个不同类别的组的线是黑线，因为两个最接近的点距离该线最远。这行是我们的分类器。然后，根据测试数据在行两边的位置，可以将新数据归类为该类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Support Vector Machines</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Support Vector Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : kernal and degree</span></span><br><span class="line"><span class="string">Documentation of sklearn Support Vector Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="朴素贝叶斯">5. 朴素贝叶斯</h3>
<p>这是一种基于贝叶斯定理的分类技术，假设预测变量之间具有独立性。简单来说，朴素贝叶斯分类器假定类中某个特定功能的存在与任何其他功能的存在无关。例如，如果水果是红色，圆形且直径约3英寸，则可以将其视为苹果。即使这些特征相互依赖或依赖于其他特征的存在，朴素的贝叶斯分类器也会考虑所有这些特征，以独立地有助于该果实是苹果的可能性。</p>
<p>朴素贝叶斯模型易于构建，对于非常大的数据集特别有用。除简单之外，朴素的贝叶斯（Naive Bayes）甚至胜过非常复杂的分类方法。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Bayes_rule.webp" alt="" /><figcaption>Bayes_rule</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Naive Bayes</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Naive Bayes model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : var_smoothing</span></span><br><span class="line"><span class="string">Documentation of sklearn GaussianNB: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = GaussianNB()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="knnk-最近邻">6. kNN（k-最近邻）</h3>
<p>它可以用于分类和回归问题。但是，它更广泛地用于行业中的分类问题。K个最近邻居是一种简单的算法，可以存储所有可用案例，并通过其k个邻居的多数票对新案例进行分类。在通过距离函数测得的K个最近邻居中，分配给该类别的案例最为常见。</p>
<p>这些距离函数可以是欧几里得距离，曼哈顿距离，明可夫斯基距离和汉明距离。前三个函数用于连续函数，第四个函数（汉明）用于分类变量。如果K = 1，则将案例简单分配给其最近邻居的类别。有时，执行kNN建模时选择K确实是一个挑战。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/KNN.webp" alt="" /><figcaption>KNN</figcaption>
</figure>
<p>KNN可以轻松地映射到我们的现实生活。如果您想了解一个没有信息的人，则可能想了解他的密友和他所进入的圈子并获得他/她的信息！</p>
<p>选择kNN之前要考虑的事项：</p>
<ol type="1">
<li>KNN在计算上很昂贵</li>
<li>变量应归一化，否则范围较大的变量会对其产生偏差</li>
<li>在进行kNN处理之前（如离群值，噪声消除）在预处理阶段进行更多工作</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Nearest Neighbors</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Nearest Neighbor model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_neighbors, leaf_size</span></span><br><span class="line"><span class="string">Documentation of sklearn K-Neighbors Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = KNeighborsClassifier()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Neighbors used to predict the target</span></span><br><span class="line">print(<span class="string">'\nThe number of neighbors used to predict the target : '</span>,model.n_neighbors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="k-均值聚类">7. K-均值聚类</h3>
<p>这是一种无监督算法，可以解决聚类问题。它的过程遵循一种简单的方法，可以通过一定数量的聚类（假设k个聚类）对给定的数据集进行分类。集群中的数据点对同级组是同质的，并且是异构的。</p>
<p>还记得从墨水印迹中找出形状吗？k表示此活动有点类似。您查看形状并展开以解释存在多少个不同的群集/种群！</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Ink.jpg" alt="" /><figcaption>Ink</figcaption>
</figure>
<p>K-均值如何形成聚类：</p>
<ol type="1">
<li>K均值为每个聚类选择k个点，称为质心。</li>
<li>每个数据点形成一个具有最接近质心的聚类，即k个聚类。</li>
<li>根据现有集群成员查找每个集群的质心。在这里，我们有了新的质心。</li>
<li>当我们有了新的质心时，请重复步骤2和3。找到每个数据点与新质心的最近距离，并与新的k簇相关联。重复此过程，直到会聚即质心不变为止。</li>
</ol>
<p>如何确定K的值：</p>
<p>在K均值中，我们有簇，每个簇都有自己的质心。质心和群集中数据点之间的差平方和构成该群集的平方值之和。同样，当所有聚类的平方和相加时，它成为聚类解的平方和之和。</p>
<p>我们知道，随着簇数的增加，该值会不断减少，但是如果绘制结果，您可能会看到平方距离的总和急剧减小，直至达到某个k值，然后逐渐减小。在这里，我们可以找到最佳的群集数量。</p>
<figure>
<img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Kmenas.webp" alt="" /><figcaption>Kmenas</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Means</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to divide the training data into differernt clusters</span></span><br><span class="line"><span class="comment"># and predict in which cluster a particular data point belongs.  </span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Means model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_clusters and max_iter</span></span><br><span class="line"><span class="string">Documentation of sklearn KMeans: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line"></span><br><span class="line">model = KMeans()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nDefault number of Clusters : '</span>,model.n_clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we will train a model with n_cluster = 3</span></span><br><span class="line">model_n3 = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_n3.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nNumber of Clusters : '</span>,model_n3.n_clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train_3 = model_n3.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train_3) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test_3 = model_n3.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test_3)</span><br></pre></td></tr></table></figure>
<h3 id="随机森林">8. 随机森林</h3>
<p>随机森林是决策树集合的商标术语。在随机森林中，我们收集了决策树（也称为“森林”）。为了基于属性对新对象进行分类，每棵树都进行了分类，我们称该树为该类“投票”。森林选择投票最多的类别（在森林中的所有树木上）。</p>
<p>每棵树的种植和生长如下：</p>
<ol type="1">
<li>如果训练集中的病例数为N，则随机抽取N个病例作为样本，并进行替换。该样本将成为树木生长的训练集。</li>
<li>如果有M个输入变量，则指定数字m &lt;&lt; M，以便在每个节点上从M个中随机选择m个变量，并使用对这m个变量的最佳分割来分割节点。在森林生长过程中，m的值保持恒定。</li>
<li>每棵树都尽可能地生长。没有修剪。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Random Forest</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Create the object of the Random Forest model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_estimators and max_depth</span></span><br><span class="line"><span class="string">Documentation of sklearn RandomForestClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of trees used</span></span><br><span class="line">print(<span class="string">'Number of Trees used : '</span>, model.n_estimators)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h3 id="降维算法">9.降维算法</h3>
<p>在过去的4-5年中，每个可能阶段的数据捕获都呈指数级增长。公司/政府机构/研究组织不仅提供了新的来源，而且还非常详细地捕获数据。</p>
<p>例如：电子商务公司正在捕获有关客户的更多详细信息，例如他们的人口统计信息，网络爬网历史记录，他们喜欢或不喜欢的东西，购买历史记录，反馈以及许多其他信息，这些东西比最近的杂货店店主更能给予他们个性化的关注。</p>
<p>作为数据科学家，我们提供的数据还包含许多功能，这对于构建良好的鲁棒模型听起来不错，但仍存在挑战。您如何识别1000或2000中的高有效变量？在这种情况下，降维算法可与其他各种算法（例如决策树，随机森林，PCA，因子分析，基于相关矩阵识别，缺失值比率等）一起帮助我们。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Principal Component Analysis (PCA)</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error  </span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(train_x.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create the object of the PCA (Principal Component Analysis) model</span></span><br><span class="line"><span class="comment"># reduce the dimensions of the data to 12</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : svd_solver, iterated_power</span></span><br><span class="line"><span class="string">Documentation of sklearn PCA:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model_pca = PCA(n_components=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">new_train = model_pca.fit_transform(train_x)</span><br><span class="line">new_test  = model_pca.fit_transform(test_x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(new_train.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model_new = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_new.fit(new_train,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new train dataset</span></span><br><span class="line">predict_train_pca = model_new.predict(new_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train_pca = mean_squared_error(train_y,predict_train_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new train dataset : '</span>, rmse_train_pca)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new test dataset</span></span><br><span class="line">predict_test_pca = model_new.predict(new_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test_pca = mean_squared_error(test_y,predict_test_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new test dataset : '</span>, rmse_test_pca)</span><br></pre></td></tr></table></figure>
<h3 id="梯度提升算法">10. 梯度提升算法</h3>
<h4 id="gbm">10.1 GBM</h4>
<p>当我们处理大量数据以进行具有高预测能力的预测时，GBM是一种增强算法。Boosting实际上是一种学习算法的集合，该算法结合了多个基本估计量的预测，以提高单个估计量的鲁棒性。它将多个弱或平均预测变量组合为一个构建强的预测变量。这些增强算法在Kaggle，AV Hackathon，CrowdAnalytix等数据科学竞赛中始终能很好地发挥作用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Gradient Boosting</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the GradientBoosting Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : learning_rate, n_estimators</span></span><br><span class="line"><span class="string">Documentation of sklearn GradientBoosting Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = GradientBoostingClassifier(n_estimators=<span class="number">100</span>,max_depth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h4 id="xgboost">10.2 XGBoost</h4>
<p>在某些Kaggle比赛中，另一种经典的梯度提升算法是决定胜负的决定性选择。</p>
<p>XGBoost具有极高的预测能力，这使其成为事件准确性的最佳选择，因为它同时具有线性模型和树学习算法，这使得该算法比现有的梯度增强技术快了近10倍。</p>
<p>支持包括各种目标功能，包括回归，分类和排名。</p>
<p>关于XGBoost的最有趣的事情之一是，它也被称为正则化增强技术。这有助于减少过拟合模型，并且对Scala，Java，R，Python，Julia和C ++等多种语言提供了广泛的支持。</p>
<p>支持在包含GCE，AWS，Azure和Yarn群集的许多计算机上进行分布式和广泛的培训。XGBoost还可以与Spark，Flink和其他云数据流系统集成，在提升过程的每次迭代中都具有内置的交叉验证。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for XGBoost</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the XGBoost model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and n_estimators</span></span><br><span class="line"><span class="string">Documentation of xgboost:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://xgboost.readthedocs.io/en/latest/</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>
<h4 id="lightgbm">10.3 LightGBM</h4>
<p>LightGBM 是使用基于树的学习算法的梯度增强框架。它被设计为分布式且高效的，具有以下优点：</p>
<ul>
<li>更快的训练速度和更高的效率</li>
<li>降低内存使用量</li>
<li>精度更高</li>
<li>支持并行和GPU学习</li>
<li>能够处理大规模数据</li>
</ul>
<p>该框架是基于决策树算法的一种快速，高性能的梯度提升算法，用于排名，分类和许多其他机器学习任务。它是在Microsoft的分布式机器学习工具包项目下开发的。</p>
<p>由于LightGBM基于决策树算法，因此它以最佳拟合的方式对树进行拆分，而其他增强算法则对树的深度或层次进行拆分，而不是对叶进行拆分。因此，当在Light GBM中的同一叶上生长时，与逐级算法相比，逐叶算法可以减少更多的损失，因此可以得到更好的精度，而现有的任何增强算法都很少达到这种精度。</p>
<p>而且，它出奇地快，因此是“ Light”一词。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.rand(<span class="number">500</span>, <span class="number">10</span>) <span class="comment"># 500 entities, each contains 10 features</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">500</span>) <span class="comment"># binary target</span></span><br><span class="line"></span><br><span class="line">train_data = lgb.Dataset(data, label=label)</span><br><span class="line">test_data = train_data.create_valid(<span class="string">'test.svm'</span>)</span><br><span class="line"></span><br><span class="line">param = &#123;<span class="string">'num_leaves'</span>:<span class="number">31</span>, <span class="string">'num_trees'</span>:<span class="number">100</span>, <span class="string">'objective'</span>:<span class="string">'binary'</span>&#125;</span><br><span class="line">param[<span class="string">'metric'</span>] = <span class="string">'auc'</span></span><br><span class="line"></span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])</span><br><span class="line"></span><br><span class="line">bst.save_model(<span class="string">'model.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7 entities, each contains 10 features</span></span><br><span class="line">data = np.random.rand(<span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">ypred = bst.predict(data)</span><br></pre></td></tr></table></figure>
<h4 id="catboost">10.4 Catboost</h4>
<p>CatBoost是Yandex最近提供的开源机器学习算法。它可以轻松地与深度学习框架（如Google的TensorFlow和Apple的Core ML）集成。</p>
<p>关于CatBoost的最好之处在于，它不需要像其他ML模型一样进行大量的数据培训，并且可以处理多种数据格式。不会破坏它的坚固性。</p>
<p>在继续实施之前，请确保处理好丢失的数据。</p>
<p>Catboost可以自动处理分类变量，而不会显示类型转换错误，这可以帮助您专注于更好地调整模型，而不是解决琐碎的错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment">#Read training and testing files</span></span><br><span class="line">train = pd.read_csv(<span class="string">"train.csv"</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">"test.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Imputing missing values for both train and test</span></span><br><span class="line">train.fillna(<span class="number">-999</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">test.fillna(<span class="number">-999</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Creating a training set for modeling and validation set to check model performance</span></span><br><span class="line">X = train.drop([<span class="string">'Item_Outlet_Sales'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = train.Item_Outlet_Sales</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=<span class="number">0.7</span>, random_state=<span class="number">1234</span>)</span><br><span class="line">categorical_features_indices = np.where(X.dtypes != np.float)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#importing library and building model</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressormodel=CatBoostRegressor(iterations=<span class="number">50</span>, depth=<span class="number">3</span>, learning_rate=<span class="number">0.1</span>, loss_function=<span class="string">'RMSE'</span>)</span><br><span class="line"></span><br><span class="line">model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_validation, y_validation),plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">submission[<span class="string">'Item_Identifier'</span>] = test[<span class="string">'Item_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Outlet_Identifier'</span>] = test[<span class="string">'Outlet_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Item_Outlet_Sales'</span>] = model.predict(test)</span><br></pre></td></tr></table></figure>
<p>节选自：<a href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms" target="_blank" rel="noopener">Commonly used Machine Learning Algorithms (with Python and R Codes)</a><br />
作者：<a href="https://www.analyticsvidhya.com/blog/author/sunil-ray/" target="_blank" rel="noopener">SUNIL RAY</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://2020.iosdevlog.com/2020/03/08/algorithms/" data-id="ck905xkgt0081nn2wh4zkec2s" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ml/" rel="tag">ml</a></li></ul>

      
        <p><span>作  者:</span><span><a href="https://iosdevlog.com" target="_blank" rel="noopener">iOSDevLog</a></span></p>
        <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ml/" rel="tag">ml</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/09/50-books/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          2020年每位数据科学家必读的50本免费书籍
        
      </div>
    </a>
  
  
    <a href="/2020/03/07/nn/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">《神经网络与深度学习》读书笔记</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/1001/">1001</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AI/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DL/">DL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tool/">Tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/academy/">academy</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/code/">code</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs/">cs</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/dl/">dl</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/editor/">editor</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/game/">game</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/geek/">geek</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/math/">math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/party/">party</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/plan/">plan</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/software/">software</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%86%99%E4%BD%9C/">写作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%87%86%E5%A4%87/">准备</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B0%8F%E6%AD%A6/">小武</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/">编译原理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%82%BA%E7%82%8E/">肺炎</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/">自我提升</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E5%88%92/">计划</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6/">读书</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6-%E6%94%B9%E9%9D%A9-%E5%A4%A7%E6%B1%9F%E5%A4%A7%E6%B2%B3/">读书 - 改革 - 大江大河</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BF%90%E8%90%A5/">运营</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/3b1b/" rel="tag">3b1b</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ANN/" rel="tag">ANN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AR/" rel="tag">AR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algebra/" rel="tag">Algebra</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/" rel="tag">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/App/" rel="tag">App</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apple/" rel="tag">Apple</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CV/" rel="tag">CV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Client/" rel="tag">Client</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code/" rel="tag">Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Compiler/" rel="tag">Compiler</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Construction/" rel="tag">Construction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Coursera/" rel="tag">Coursera</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/" rel="tag">DL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DS/" rel="tag">DS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DataMining/" rel="tag">DataMining</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deployment/" rel="tag">Deployment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/English/" rel="tag">English</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Godot/" rel="tag">Godot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/" rel="tag">Google</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kindle/" rel="tag">Kindle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Language/" rel="tag">Language</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lua/" rel="tag">Lua</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/" rel="tag">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MediaWiki/" rel="tag">MediaWiki</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NN/" rel="tag">NN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scene/" rel="tag">Scene</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Swift/" rel="tag">Swift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UI/" rel="tag">UI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VR/" rel="tag">VR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/action/" rel="tag">action</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/" rel="tag">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/basic/" rel="tag">basic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/beginner/" rel="tag">beginner</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/book/" rel="tag">book</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/calculus/" rel="tag">calculus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cheatsheets/" rel="tag">cheatsheets</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cheeksheet/" rel="tag">cheeksheet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/" rel="tag">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cs/" rel="tag">cs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cv/" rel="tag">cv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data/" rel="tag">data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/devops/" rel="tag">devops</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dl/" rel="tag">dl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/download/" rel="tag">download</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/free/" rel="tag">free</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/geek/" rel="tag">geek</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/geektime/" rel="tag">geektime</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/https/" rel="tag">https</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/iOS/" rel="tag">iOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/infoq/" rel="tag">infoq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/information/" rel="tag">information</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jetbrain/" rel="tag">jetbrain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/js/" rel="tag">js</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/keras/" rel="tag">keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kindle/" rel="tag">kindle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kotlin/" rel="tag">kotlin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linear/" rel="tag">linear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lr/" rel="tag">lr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/manager/" rel="tag">manager</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/manim/" rel="tag">manim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/" rel="tag">matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mindmap/" rel="tag">mindmap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ml/" rel="tag">ml</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mobile/" rel="tag">mobile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/network/" rel="tag">network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nginx/" rel="tag">nginx</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/" rel="tag">nlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nn/" rel="tag">nn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper/" rel="tag">paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plan/" rel="tag">plan</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plugin/" rel="tag">plugin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pm/" rel="tag">pm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/protocal/" rel="tag">protocal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scipy/" rel="tag">scipy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/slm/" rel="tag">slm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/svm/" rel="tag">svm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/" rel="tag">test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tf/" rel="tag">tf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tf2/" rel="tag">tf2</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/theory/" rel="tag">theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/todo/" rel="tag">todo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tool/" rel="tag">tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vscode/" rel="tag">vscode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wiki/" rel="tag">wiki</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/year/" rel="tag">year</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/" rel="tag">东野圭吾</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AD%E5%9B%BD/" rel="tag">中国</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%BA%E7%89%A9/" rel="tag">人物</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%BD%E5%88%A9%E7%95%A5%E7%B3%BB%E5%88%97/" rel="tag">伽利略系列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BD%93%E8%82%B2/" rel="tag">体育</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%81%87%E9%9D%A2%E7%B3%BB%E5%88%97/" rel="tag">假面系列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%8D%E8%B4%B9/" rel="tag">免费</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/" rel="tag">公众号</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A0%E8%B4%BA%E6%81%AD%E4%B8%80%E9%83%8E%E7%B3%BB%E5%88%97/" rel="tag">加贺恭一郎系列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9C%B0%E7%90%83%E7%BC%96%E5%B9%B4%E5%8F%B2/" rel="tag">地球编年史</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%B1%9F%E5%A4%A7%E6%B2%B3/" rel="tag">大江大河</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A9%E4%B8%8B%E4%B8%80%E5%A4%A7%E4%BA%94%E9%83%8E%E7%B3%BB%E5%88%97/" rel="tag">天下一大五郎系列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%94%B9%E9%9D%A9/" rel="tag">改革</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%88%E7%8E%87/" rel="tag">效率</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/" rel="tag">极客时间</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%83%AD%E7%82%B9/" rel="tag">热点</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%88%E6%9D%83/" rel="tag">版权</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%B4%E6%92%AD/" rel="tag">直播</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%BB%E5%8A%A8/" rel="tag">移动</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%98%E6%9C%AC/" rel="tag">绘本</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A5%BF%E7%90%B4/" rel="tag">西琴</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1/" rel="tag">设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6/" rel="tag">读书</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%94%99%E8%AF%AF/" rel="tag">错误</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/3b1b/" style="font-size: 11.11px;">3b1b</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/ANN/" style="font-size: 11.11px;">ANN</a> <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/Algebra/" style="font-size: 10px;">Algebra</a> <a href="/tags/Android/" style="font-size: 12.22px;">Android</a> <a href="/tags/App/" style="font-size: 10px;">App</a> <a href="/tags/Apple/" style="font-size: 10px;">Apple</a> <a href="/tags/CV/" style="font-size: 13.33px;">CV</a> <a href="/tags/Client/" style="font-size: 10px;">Client</a> <a href="/tags/Code/" style="font-size: 10px;">Code</a> <a href="/tags/Compiler/" style="font-size: 11.11px;">Compiler</a> <a href="/tags/Construction/" style="font-size: 11.11px;">Construction</a> <a href="/tags/Coursera/" style="font-size: 10px;">Coursera</a> <a href="/tags/DL/" style="font-size: 17.78px;">DL</a> <a href="/tags/DS/" style="font-size: 11.11px;">DS</a> <a href="/tags/DataMining/" style="font-size: 10px;">DataMining</a> <a href="/tags/Deployment/" style="font-size: 10px;">Deployment</a> <a href="/tags/English/" style="font-size: 10px;">English</a> <a href="/tags/Godot/" style="font-size: 18.89px;">Godot</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Kindle/" style="font-size: 10px;">Kindle</a> <a href="/tags/Language/" style="font-size: 10px;">Language</a> <a href="/tags/Lua/" style="font-size: 10px;">Lua</a> <a href="/tags/ML/" style="font-size: 20px;">ML</a> <a href="/tags/Math/" style="font-size: 13.33px;">Math</a> <a href="/tags/MediaWiki/" style="font-size: 11.11px;">MediaWiki</a> <a href="/tags/NN/" style="font-size: 11.11px;">NN</a> <a href="/tags/PyTorch/" style="font-size: 12.22px;">PyTorch</a> <a href="/tags/Python/" style="font-size: 14.44px;">Python</a> <a href="/tags/Scene/" style="font-size: 10px;">Scene</a> <a href="/tags/Swift/" style="font-size: 10px;">Swift</a> <a href="/tags/TensorFlow/" style="font-size: 11.11px;">TensorFlow</a> <a href="/tags/UI/" style="font-size: 10px;">UI</a> <a href="/tags/VR/" style="font-size: 10px;">VR</a> <a href="/tags/action/" style="font-size: 10px;">action</a> <a href="/tags/algorithm/" style="font-size: 16.67px;">algorithm</a> <a href="/tags/basic/" style="font-size: 10px;">basic</a> <a href="/tags/beginner/" style="font-size: 11.11px;">beginner</a> <a href="/tags/book/" style="font-size: 11.11px;">book</a> <a href="/tags/calculus/" style="font-size: 10px;">calculus</a> <a href="/tags/cheatsheets/" style="font-size: 10px;">cheatsheets</a> <a href="/tags/cheeksheet/" style="font-size: 10px;">cheeksheet</a> <a href="/tags/code/" style="font-size: 10px;">code</a> <a href="/tags/cs/" style="font-size: 10px;">cs</a> <a href="/tags/cv/" style="font-size: 10px;">cv</a> <a href="/tags/data/" style="font-size: 15.56px;">data</a> <a href="/tags/devops/" style="font-size: 13.33px;">devops</a> <a href="/tags/dl/" style="font-size: 12.22px;">dl</a> <a href="/tags/download/" style="font-size: 10px;">download</a> <a href="/tags/free/" style="font-size: 10px;">free</a> <a href="/tags/geek/" style="font-size: 10px;">geek</a> <a href="/tags/geektime/" style="font-size: 10px;">geektime</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/https/" style="font-size: 10px;">https</a> <a href="/tags/iOS/" style="font-size: 14.44px;">iOS</a> <a href="/tags/infoq/" style="font-size: 10px;">infoq</a> <a href="/tags/information/" style="font-size: 10px;">information</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/jetbrain/" style="font-size: 10px;">jetbrain</a> <a href="/tags/js/" style="font-size: 10px;">js</a> <a href="/tags/keras/" style="font-size: 10px;">keras</a> <a href="/tags/kindle/" style="font-size: 10px;">kindle</a> <a href="/tags/kotlin/" style="font-size: 10px;">kotlin</a> <a href="/tags/linear/" style="font-size: 10px;">linear</a> <a href="/tags/lr/" style="font-size: 10px;">lr</a> <a href="/tags/manager/" style="font-size: 10px;">manager</a> <a href="/tags/manim/" style="font-size: 14.44px;">manim</a> <a href="/tags/matplotlib/" style="font-size: 10px;">matplotlib</a> <a href="/tags/mindmap/" style="font-size: 10px;">mindmap</a> <a href="/tags/ml/" style="font-size: 13.33px;">ml</a> <a href="/tags/mobile/" style="font-size: 10px;">mobile</a> <a href="/tags/network/" style="font-size: 12.22px;">network</a> <a href="/tags/nginx/" style="font-size: 10px;">nginx</a> <a href="/tags/nlp/" style="font-size: 11.11px;">nlp</a> <a href="/tags/nn/" style="font-size: 11.11px;">nn</a> <a href="/tags/numpy/" style="font-size: 10px;">numpy</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/paper/" style="font-size: 12.22px;">paper</a> <a href="/tags/plan/" style="font-size: 10px;">plan</a> <a href="/tags/plugin/" style="font-size: 11.11px;">plugin</a> <a href="/tags/pm/" style="font-size: 10px;">pm</a> <a href="/tags/protocal/" style="font-size: 10px;">protocal</a> <a href="/tags/python/" style="font-size: 11.11px;">python</a> <a href="/tags/scipy/" style="font-size: 10px;">scipy</a> <a href="/tags/slm/" style="font-size: 10px;">slm</a> <a href="/tags/svm/" style="font-size: 10px;">svm</a> <a href="/tags/test/" style="font-size: 10px;">test</a> <a href="/tags/tf/" style="font-size: 10px;">tf</a> <a href="/tags/tf2/" style="font-size: 10px;">tf2</a> <a href="/tags/theory/" style="font-size: 10px;">theory</a> <a href="/tags/todo/" style="font-size: 10px;">todo</a> <a href="/tags/tool/" style="font-size: 10px;">tool</a> <a href="/tags/vscode/" style="font-size: 11.11px;">vscode</a> <a href="/tags/wiki/" style="font-size: 11.11px;">wiki</a> <a href="/tags/year/" style="font-size: 10px;">year</a> <a href="/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/" style="font-size: 20px;">东野圭吾</a> <a href="/tags/%E4%B8%AD%E5%9B%BD/" style="font-size: 10px;">中国</a> <a href="/tags/%E4%BA%BA%E7%89%A9/" style="font-size: 10px;">人物</a> <a href="/tags/%E4%BC%BD%E5%88%A9%E7%95%A5%E7%B3%BB%E5%88%97/" style="font-size: 10px;">伽利略系列</a> <a href="/tags/%E4%BD%93%E8%82%B2/" style="font-size: 10px;">体育</a> <a href="/tags/%E5%81%87%E9%9D%A2%E7%B3%BB%E5%88%97/" style="font-size: 10px;">假面系列</a> <a href="/tags/%E5%85%8D%E8%B4%B9/" style="font-size: 10px;">免费</a> <a href="/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/" style="font-size: 10px;">公众号</a> <a href="/tags/%E5%8A%A0%E8%B4%BA%E6%81%AD%E4%B8%80%E9%83%8E%E7%B3%BB%E5%88%97/" style="font-size: 13.33px;">加贺恭一郎系列</a> <a href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 10px;">可视化</a> <a href="/tags/%E5%9C%B0%E7%90%83%E7%BC%96%E5%B9%B4%E5%8F%B2/" style="font-size: 10px;">地球编年史</a> <a href="/tags/%E5%A4%A7%E6%B1%9F%E5%A4%A7%E6%B2%B3/" style="font-size: 10px;">大江大河</a> <a href="/tags/%E5%A4%A9%E4%B8%8B%E4%B8%80%E5%A4%A7%E4%BA%94%E9%83%8E%E7%B3%BB%E5%88%97/" style="font-size: 10px;">天下一大五郎系列</a> <a href="/tags/%E6%94%B9%E9%9D%A9/" style="font-size: 10px;">改革</a> <a href="/tags/%E6%95%88%E7%8E%87/" style="font-size: 10px;">效率</a> <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/" style="font-size: 10px;">极客时间</a> <a href="/tags/%E7%83%AD%E7%82%B9/" style="font-size: 10px;">热点</a> <a href="/tags/%E7%89%88%E6%9D%83/" style="font-size: 10px;">版权</a> <a href="/tags/%E7%9B%B4%E6%92%AD/" style="font-size: 10px;">直播</a> <a href="/tags/%E7%A7%BB%E5%8A%A8/" style="font-size: 10px;">移动</a> <a href="/tags/%E7%BB%98%E6%9C%AC/" style="font-size: 10px;">绘本</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 10px;">统计学习方法</a> <a href="/tags/%E8%A5%BF%E7%90%B4/" style="font-size: 10px;">西琴</a> <a href="/tags/%E8%AE%BE%E8%AE%A1/" style="font-size: 10px;">设计</a> <a href="/tags/%E8%AF%BB%E4%B9%A6/" style="font-size: 11.11px;">读书</a> <a href="/tags/%E9%94%99%E8%AF%AF/" style="font-size: 10px;">错误</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/04/13/network/">网络协议</a>
          </li>
        
          <li>
            <a href="/2020/04/12/nginx/">Nginx 思维导图</a>
          </li>
        
          <li>
            <a href="/2020/04/11/jetbrains/">JetBrains Academy Knowledge Map</a>
          </li>
        
          <li>
            <a href="/2020/04/10/pm/">人人都是产口经理 3.0</a>
          </li>
        
          <li>
            <a href="/2020/04/09/Design-pattern/">设计模式</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 iOSDevLog<br>
      Powered by © 2020 - <a href="https://www.iosdevlog.com" target="_blank">贾献华 2020 博客</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/2020" class="mobile-nav-link">2020 Calendar</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>