<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Game 2020</title>
  
  <subtitle>https://2020.iosdevlog.com</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://2020.iosdevlog.com/"/>
  <updated>2020-03-02T15:07:18.836Z</updated>
  <id>https://2020.iosdevlog.com/</id>
  
  <author>
    <name>iOSDevLog</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Google工作法》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/03/02/9787540492908/"/>
    <id>https://2020.iosdevlog.com/2020/03/02/9787540492908/</id>
    <published>2020-03-02T12:01:27.000Z</published>
    <updated>2020-03-02T15:07:18.836Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/1.jpg" alt="" /><figcaption>Google工作法</figcaption></figure><p>书名：Google工作法<br />作者：[波]彼得·费利克斯·格日瓦奇<br />译者：朱悦玮<br />出版社：湖南文艺出版社<br />出版时间：2019-08<br />ISBN：9787540492908</p><blockquote><p>明明很努力地工作，但工作总是做不完。<br />明明很努力地工作，但工作总是不顺利。<br />而且，这样的状态还一直在持续</p></blockquote><p>——这本书将彻底解决你的烦恼。</p><a id="more"></a><h2 id="简介">简介</h2><p>《Google工作法》是一本介绍Google内部高效工作法的经管图书。 工作高效的人为什么不爱用邮件？为什么明明很努力工作，却怎么也做不完，而且还不顺利？本书传授57个核心技巧，一次性把Google的高效秘密倾囊相授。</p><p>AI时代来临，与其担心工作是否被取代，不如改变低效的工作方式，找到让个人或者企业立足的强有力资本。所谓高效，并不是快速完成某项工作而已，而是把更多时间留给更有价值的工作。把握这个核心，就能很好地理解Google为什么能成为令全世界侧目的高科技企业。</p><p>本书适合企业中各个层次的读者阅读，在快速变化的时代找到自己的核心价值。 Google“每一分钟”的使用方法都不一样！ 不把工作带回去。明白就是明白，不明白就是不明白。不要过分依赖邮件。不做过多分析。需要休息的时候就休息一下。考虑让自己的工作消失。</p><h2 id="为什么日本的企业生产效率低下">为什么日本的企业生产效率低下</h2><ol type="1"><li>过度推迟讨论</li><li>过分讨论</li><li>过度的交流</li></ol><h2 id="改变工作方式方法才是生存之道">改变工作方式方法才是生存之道</h2><p>很多人都害怕自己的工作会被IT（信息技术）和AI（人工智能）所取代。</p><p>我们不应该害怕“自己的工作消失”，而是应该思考“怎样做才能够用IT来代替自己的工作”“怎样做才能够更加自动化、省力化”。</p><p>当时我最深刻的感受就是 <strong>变化突然就到来了</strong>，并且认识到 <strong>自己也必须做出改变才行</strong>。</p><h2 id="让你比世界更快的工作术-不要依赖邮件">让你比世界更快的工作术 不要依赖邮件</h2><p>我认为决定工作效率的关键在于对“现在”的使用方法。</p><p>谷歌为了取得10倍的成果，“现在做”和“现在不做的话那要等到什么时候做”的意识非常强。</p><ul><li>过度“推迟”会浪费许多人的时间<ul><li>明明当场就能够做完的事情，很多人却用“我以后再做”将这件事推迟到后面去。</li></ul></li><li>不要“推迟讨论”<ul><li>“如果现在有必要的话，现在就联系。”</li><li>“如果现在应该决定的话，现在就决定。”</li><li>通过谷歌文档（Google Docs，一款可以在网页上共享文件的文件制作软件）等共享工具，能够实现随时随地访问自己的文件，从而增加你“立刻能做”的事情。</li></ul></li><li>当场做出决定<ul><li>一定要给“做出决定”规定期限</li></ul></li><li>活用“身边的人”<ul><li>要想解决这个问题，需要收集这些必要的资源</li></ul></li><li>即便“不知道应该怎样做才好”仍然能够采取行动的人才会成功<ul><li>将“知道的内容”和“不知道的内容”区分开</li><li>提出问题</li><li>留出时间<br /><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/2.jpg">在“不知道应该怎样做才好”的时候仍然能做的事</a></li></ul></li><li>增加“现在”的密度<ul><li>一次结束</li><li>当场做完</li></ul></li><li>不用邮件，所有人同时工作的话可以将工作时间缩短到原本的十分之一<ul><li>当场一次完成</li><li>微软的Office 365</li><li>苹果的iCloud</li><li>谷歌文档</li></ul></li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/3.jpg">利用谷歌文档共享资料</a></p><ul><li>绝对不要用邮件来进行日程调整<ul><li>谷歌日历（Google Calendar）</li></ul></li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/4.jpg">谷歌日历可以添加附件</a></p><ul><li>为了提高效率，英语必不可少<ul><li>翻译：时间和成本的二次浪费</li></ul></li><li>直接见面最有效率！</li><li>邮件是“等待文化”，即时通信是“实时文化”<ul><li>当场将问题全部解决。这种速度上的差异会非常明显地表现在工作成果上。</li></ul></li><li>限制访问是阻碍竞争的主要因素</li><li><strong>给“尽快”规定一个期限</strong><ul><li>规定期限，集中精神</li></ul></li><li>由委托人来决定优先顺序<ul><li>明确工作的优先顺序和品质要求是专业人士的基本素养。</li></ul></li><li>创意性工作也需要规定期限<ul><li>如果不规定一个期限，工作就很容易停滞不前。</li></ul></li><li>大胆地将期限提前</li><li>不要把时间浪费在选择衣服上</li><li>对“此时此刻”持有明确的目的</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/5.jpg">会议前的准备列表</a></p><ul><li>事先预测、控制局面</li><li>将一周每天要做的事情区分开</li><li>选择舒适的工作环境</li><li>如果想提高工作效率，一个舒适的工作环境十分重要。</li></ul><h3 id="总结">总结</h3><ul><li>想办法“一次结束”</li><li>先将能够当场确定的事情确定下来，切实地取得进展</li><li>思考不用邮件而让所有人一次做完的方法</li><li>给所有的工作都规定期限</li><li>将精力集中于“此时此刻”</li><li>选择一个能够让自己集中精神工作的环境</li></ul><h2 id="没时间去进行逻辑分析用集体智慧来进行思考">没时间去进行逻辑分析！用集体智慧来进行思考</h2><ul><li>没有结论的分析毫无意义<ul><li>不知道自己究竟为什么要调查</li><li>也就是没有明确调查的目的</li></ul></li><li>分析的目的是什么<ul><li>创意思维需要的是灵感以及来自丰富经验的直觉</li><li>多准备一些能够激发灵感的材料</li></ul></li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/6.jpg">线索卡的示例</a></p><ul><li>通过制造混乱让大脑活跃起来<ul><li>通过人为地制造混乱，可以使潜意识活性化，从而更容易思考出新的创意</li></ul></li><li>靠集体智慧才能产生创意思维<ul><li>集体智慧（Collective intelligence）是产生创意的秘诀</li></ul></li><li>只对竞争对手进行“分析”不可能开发出新产品<ul><li>只对竞争对手的商品进行分析无法实现差异化</li></ul></li><li>一味地模仿不可能实现差异化</li><li>企划会议不需要总结报告</li><li>总结报告式的会议无法拓展思考</li><li>需要的不是“评价”而是“成果”</li><li>独自思考不如大家一起思考</li><li>积极听取不同类型和立场的意见</li></ul><p>总结<br />* 与逻辑分析相比“灵感”更加重要<br />* 灵活利用线索卡，大家一起进行思考<br />* 将企划会议变成大家一起思考的会议<br />* 积极听取其他部门和其他领域的人的意见</p><h2 id="第三章取得10倍成果的方法-以10倍的速度思考就能更快地取得成果">第三章取得10倍成果的方法 以10倍的速度思考，就能更快地取得成果</h2><ul><li>目标不是提高 <code>10%</code>，而是提高到 <code>10</code> 倍</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/7.jpg">以取得10倍的成果为目标，就算没达成目标也是成功</a></p><ul><li>不打破规则就不可能取得10倍的成果</li><li>做一个敢于打破规则的人</li><li>承担风险是为了取得成功</li><li>“比去年提高10%”这一目标的错误之处</li><li>活用“20%规则”的方法</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/8.jpg">应该自己做的工作与应该交给别人的工作</a></p><ul><li>为了走入新的阶段必须“让自己的工作消失”</li><li>Think like an owner</li><li>成功取得10倍成果的人的共同点<ol type="1"><li>拥有预见性<ul><li>预见机会与威胁</li><li>寻找周期、趋势以及规律</li><li>短期、中期与长期思考</li></ul></li><li>换位思考</li><li>敢于提出自己的见解</li><li>敢说真话</li><li>积极参与交流</li><li>倾听自己内心的声音</li><li>打破常规</li><li>不害怕失败</li><li>勤于思考、保持怀疑</li><li>改变视角<ul><li>整体视角</li><li>局部视角</li><li>反面视角</li><li>未来视角</li><li>顾客视角</li><li>竞争对手视角</li><li>特殊视角（一般情况下、更深层次的情况下、反常的情况下）</li></ul></li></ol></li></ul><h3 id="总结-1">总结</h3><ul><li>思考如何取得10倍的成果</li><li>为了取得10倍的成果必须要打破规则</li><li>为了进入下一个阶段，必须“让自己的工作消失”</li><li>像公司的所有者那样思考</li></ul><h2 id="创建提高工作效率的人际关系的方法-能够让每个人都发挥出全部实力的心理安全究竟是什么">创建提高工作效率的人际关系的方法 能够让每个人都发挥出全部实力的“心理安全”究竟是什么</h2><ul><li>用“实物”说话</li></ul><blockquote><p>与对程序员说“我想在这里增加一个这样的功能……”相比，将拥有这个功能的程序实际运行起来给对方看更加便于理解。</p></blockquote><ul><li>让自己平易近人</li><li>告诉部下“上司的使用方法”<ul><li>自己能解决的事情请自己解决。</li><li>不要只带着问题来找我，同时还要带来解决办法。</li><li>遇到无法解决的问题，请告诉我你需要什么（比如需要建议、决定，还是需要我出面动用权限）。</li></ul></li><li>如何创建心理安全程度较高的环境</li><li>创建“反馈渠道”</li><li>绝对不能完全否定对方的意见</li><li>提高工作效率的不是流程而是“人”</li><li>你的人际圈将改变你的人生</li><li>发现最有能力的人</li><li>改变人际关系的优先顺序</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/11.jpg">人际关系的优先顺序</a></p><ul><li>与关键人物建立联系</li></ul><h3 id="总结-2">总结</h3><ul><li>用“实物”说话可以使工作更有效率</li><li>取消多余的会议</li><li>与部下的交流每周一次就够了</li><li>在工作之外也建立起人际关系，可以使工作更有效率</li><li>优先与“新结识的人”“不断变化的人”“高水平的人”交流</li></ul><h2 id="迅速学习必要技能的方法-去学校学习不如向同事学习">迅速学习必要技能的方法 去学校学习不如向同事学习</h2><ul><li>应该学习的不是知识而是经验</li><li>“检索时代”学习的基本原则</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/12.jpg">新的“学习循环”</a></p><ul><li>与学习相关的“询问”规则<ul><li>向别人询问的时候，一定要提出自己的假设</li></ul></li><li>向擅长工作的人询问</li><li>在职场中“学习”</li><li>利用反馈获得自己意想不到的情报</li><li>工作前进行“前馈”</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/13.jpg">反馈与前馈</a></p><ul><li>提问 4 要素<ol type="1"><li>具体来说</li><li>要在什么地方</li><li>改变什么</li><li>怎样做，才能让工作比较顺利</li></ol></li><li>实践比研修更容易获得自信</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/14.jpg">NLP（神经语言程序学）行动金字塔</a></p><ul><li>通过交流学习</li><li>多参加交流</li><li>不要排斥不同领域的人</li><li>孤身一人不如齐心协力</li><li>“for”与“with”</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/15.jpg">“for”与“with”</a></p><ul><li>为什么要学习<ul><li>拥有的“选项”越多，在竞争中生存下来的可能性就越大</li><li>不一定是最强大，但一定是最有适应性</li></ul></li><li>思维模式<ul><li><strong>成长型思维</strong></li><li>学习型思维</li><li>回避型思维</li><li>证明型思维。</li></ul></li><li>不断改变，坚持学习</li></ul><h3 id="总结-3">总结</h3><ul><li>学习=检索+询问专业人士·询问他人·询问同事</li><li>只有反馈远远不够，还要灵活利用“前馈”</li><li>预先建立一个能够轻松询问的交流关系</li><li>不断改变，坚持学习</li></ul><h2 id="谷歌的轻松工作方法-简化心灵">谷歌的轻松工作方法 简化心灵</h2><ul><li>留出关闭电脑的时间</li><li>将同时进行多项工作的时间与专心致志的时间区分开</li><li>同时进行多项工作的技<ul><li>冲刺工作法</li></ul></li><li>应对感情波动<ul><li><strong>你发现自己现在正在生气，那就将这个情绪状态说出来</strong></li></ul></li><li>睡午觉、吃零食、放松是自己的责任</li><li>用性善论来管理企业</li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/16.jpg">日本人拥有“工作价值”的比率较低</a></p><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/17.jpg">new work rules（新的工作要求）</a></p><h3 id="总结-4">总结</h3><ul><li>偶尔关闭电脑</li><li>一分钟的冥想就能够改变注意力</li><li>在不同的时间段集中精力做一件事</li><li>不要尝试消灭感情，要保持中庸</li><li>休息也是自己的责任</li></ul><h2 id="破坏自己工作的人将创建下一个时代">破坏自己工作的人，将创建下一个时代</h2><ul><li>不让AI抢走自己的工作</li><li>分析时代的发展变化</li><li>如何掌握最新的科技</li><li>积极尝试热门应用程序</li><li>就算对技术细节不了解，也要跟上趋势<ul><li>自动化</li><li>就算自己做不到，也可以去找相应领域的工程师或者程序员来帮忙</li></ul></li></ul><p><a href="https://2020.iosdevlog.com/2020/03/02/9787540492908/18.jpg">就连专家也无法准确预测手机市场的发展趋势</a></p><ul><li>不要害怕变化</li><li>你是否成了习惯的奴隶<ul><li>人一旦习惯了每天的行动模式，就会不再思考自己为什么工作以及怎样做才能让工作变得更有效率。</li><li>而一旦停止思考，就不会有新的发现。没有新的发现，当然也不会出现改变。</li><li>利用IT实现自动化，找别人帮忙，将工作分解成许多小任务分派下去，利用外部资源。</li></ul></li><li>工作不能“和昨天一样”</li><li>现在的世界绝对不是理所当然的</li></ul><h3 id="总结-5">总结</h3><ul><li>思考如何用IT代替自己工作</li><li>站在革新的一侧，不能袖手旁观</li><li>就算对技术细节不了解，也要跟上趋势</li><li>工作不能“和昨天一样”</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/02/9787540492908/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Google工作法&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：Google工作法&lt;br /&gt;
作者：[波]彼得·费利克斯·格日瓦奇&lt;br /&gt;
译者：朱悦玮&lt;br /&gt;
出版社：湖南文艺出版社&lt;br /&gt;
出版时间：2019-08&lt;br /&gt;
ISBN：9787540492908&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;明明很努力地工作，但工作总是做不完。&lt;br /&gt;
明明很努力地工作，但工作总是不顺利。&lt;br /&gt;
而且，这样的状态还一直在持续&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;——这本书将彻底解决你的烦恼。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Google" scheme="https://2020.iosdevlog.com/tags/Google/"/>
    
  </entry>
  
  <entry>
    <title>Manim 分析</title>
    <link href="https://2020.iosdevlog.com/2020/03/01/manim-turorial/"/>
    <id>https://2020.iosdevlog.com/2020/03/01/manim-turorial/</id>
    <published>2020-03-01T07:19:30.000Z</published>
    <updated>2020-03-02T12:18:15.401Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/0.png" alt="" /><figcaption>manim</figcaption></figure><p><a href="https://github.com/3b1b/manim" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim</a></p><p>Installation 安装</p><p>Manim runs on <code>Python 3.7</code>. You can install it from PyPI via pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install manimlib</span><br></pre></td></tr></table></figure><p>System requirements are cairo, ffmpeg, sox, latex (optional, if you want to use LaTeX).</p><p>You can now use it via the manim command. For example:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">manim my_project.py MyScene</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="manim">Manim</h2><p>manim 库的大部分功能都分解为功能不同的文件夹。用于编写动画脚本的主要工具是 scene, mobject, camera, 和 animation 文件夹，其中包含它们各自的类。在这四个文件夹中，mobject 文件夹是用户大多数时间与之交互的文件夹。它包含动画中使用的所有几何图形，文本和图形的类。</p><p>程序的实际结构很容易掌握。通过在 python 文件中声明 Scene 类的子类来创建动画或场景。动画的实际代码进入一种称为 “construct 构造” 的方法。这是manim场景的关键字。每当 Scene 类中的对象被初始化时，它都会调用 <code>self.setup()</code> 和 <code>self.construct()</code> 方法。如果未实现后者，则会出现错误。但是，前者是可选的，但在同时处理多个场景时很有用。</p><p>播放和保存动画是从命令行进行的。上面显示了播放动画的基本命令，并将python文件的名称和场景子类传递给 <code>manim.py</code>（实际上是 <code>manimlib/__init__.py</code>）。<code>-pm</code> 标志将预览中等（720p）品质的动画并将其保存在媒体文件夹中。在 <code>config.py</code> 中可以找到更多标志类型，例如裁剪某些帧的标志或导出 <code>.gif</code> 动画的标志。</p><p>当命令行调用其文件时，也会在场景声明之外执行任何 python 代码。这意味着可以删除不明确依赖 <code>manim</code> 功能的代码 <code>construct(self)</code>。这很有用，因为它可以防止结构定义混乱。</p><p>manim 中的大多数类都带有 <code>CONFIG</code> 与之关联的字典。它始终出现在类定义的顶部。这是 <code>Camera</code> 类的 CONFIG：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Camera</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">  CONFIG = &#123;</span><br><span class="line">    <span class="string">"background_image"</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">"pixel_height"</span>: DEFAULT_PIXEL_HEIGHT,</span><br><span class="line">    <span class="string">"pixel_width"</span>: DEFAULT_PIXEL_WIDTH,</span><br><span class="line">    <span class="string">"frame_rate"</span>: DEFAULT_FRAME_RATE,</span><br><span class="line">    <span class="string">"frame_height"</span>: FRAME_HEIGHT,</span><br><span class="line">    <span class="string">"frame_width"</span>: FRAME_WIDTH,</span><br><span class="line">    <span class="string">"frame_center"</span>: ORIGIN,</span><br><span class="line">    <span class="string">"background_color"</span>: BLACK,</span><br><span class="line">    <span class="string">"background_opacity"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">"max_allowable_norm"</span>: FRAME_WIDTH,</span><br><span class="line">    <span class="string">"image_mode"</span>: <span class="string">"RGBA"</span>,</span><br><span class="line">    <span class="string">"n_channels"</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">"pixel_array_dtype"</span>: <span class="string">'uint8'</span>,</span><br><span class="line">    <span class="string">"z_buff_func"</span>: <span class="keyword">lambda</span> m: np.round(m.get_center()[<span class="number">2</span>], <span class="number">2</span>),</span><br><span class="line">    <span class="string">"cairo_line_width_multiple"</span>: <span class="number">0.01</span>,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>初始化对象时，CONFIG 的条目用作要通过 <code>__init__</code> 传递的关键字参数。这对于创建场景非常方便，因为在命令行中将几个关键字参数传递给感兴趣的场景很麻烦。通常，这也是用户与 <code>Camera</code> 类进行交互的地方，因为 <code>camera</code> CONFIG是场景CONFIG中的一个条目。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Scene(Container):</span><br><span class="line"></span><br><span class="line">  CONFIG &#x3D; &#123;</span><br><span class="line">    &quot;camera_class&quot;: Camera,</span><br><span class="line">    &quot;camera_config&quot;: &#123;&#125;,</span><br><span class="line">    &quot;file_writer_config&quot;: &#123;&#125;,</span><br><span class="line">    &quot;skip_animations&quot;: False,</span><br><span class="line">    &quot;always_update_mobjects&quot;: False,</span><br><span class="line">    &quot;random_seed&quot;: 0,</span><br><span class="line">    &quot;start_at_animation_number&quot;: None,</span><br><span class="line">    &quot;end_at_animation_number&quot;: None,</span><br><span class="line">    &quot;leave_progress_bars&quot;: False,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>所有大写变量都来自文件 <code>constants.py</code>，该文件可用作参考，因为许多类和方法都将这些常量用作默认参数。CONFIG 字典尊重类和子类之间的继承，因此 manim 中的许多类具有比其类定义中更大的 CONFIG 参数。这对于大量使用子类化的 mobjects 特别重要。例如，这是的子类结构 <code>mobject/geometry.py</code>。</p><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/1.png" alt="" /><figcaption>manim</figcaption></figure><h2 id="animationswithmanim1">AnimationsWithManim<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></h2><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/2.png" alt="" /><figcaption>Manim</figcaption></figure><p><span class="math display">\[Manim = Python3（核心）+ latex（文字排版） + cairo（生成图形）+ ffmpeg（转码视频）+ sox（音频处理）\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/3.png" alt="" /><figcaption>优点</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/4.png" alt="" /><figcaption>大纲</figcaption></figure><p>具体安装可参考：<a href="https://github.com/Elteoremadebeethoven/AnimationsWithManim/blob/master/English/0_instalation/macOS/INSTRUCTIONS.md" target="_blank" rel="noopener">Installation on MacOS</a></p><h3 id="mactex2">MacTeX<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/5.png" alt="" /><figcaption>MacTeX</figcaption></figure><p>下载 <code>MacTeX.pkg</code> 安装</p><h3 id="homebrew3">Homebrew<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/ruby -e <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></span><br></pre></td></tr></table></figure><h3 id="python34">Python3<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></h3><p>可以直接去官网官下载最新版的 <code>Python3</code></p><p>或者用 <code>brew</code> 安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install python3</span><br></pre></td></tr></table></figure><p><code>python3</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Python 3.7.4 (default, Sep 28 2019, 16:39:19) </span><br><span class="line">[Clang 11.0.0 (clang-1100.0.33.8)] on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><h3 id="下载cairoffmpegsoxlatex和其他的包">下载cairo，ffmpeg，sox，latex和其他的包</h3><p>返回终端的根目录（如果你之前进入了python3，输入exit() 退出，或者重新打开终端），终端输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">brew install cairo</span><br><span class="line">brew install ffmpeg</span><br><span class="line">brew install sox</span><br></pre></td></tr></table></figure><h3 id="manim5">Manim<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></h3><p>Manim is an animation engine for explanatory math videos. It's used to create precise animations programmatically, as seen in the videos at 3Blue1Brown.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/3b1b/manim.git</span><br></pre></td></tr></table></figure><p>Install list requirements.txt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -r requirements.txt</span><br><span class="line">python3 -m pip install pyreadline</span><br><span class="line">python3 -m pip install pydub</span><br></pre></td></tr></table></figure><p>Run Manim</p><p>With the terminal in manim-master directory run this:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m manim example_scenes.py WriteStuff -pl</span><br><span class="line">python3 -m manim example_scenes.py SquareToCircle -pl</span><br></pre></td></tr></table></figure><p>The <code>-p</code> flag in the command above is for <strong>previewing</strong>, meaning the video file will automatically open when it is done rendering.</p><p>The <code>-l</code> flag is for a faster rendering at a <strong>lower quality</strong>.</p><p>Some other useful flags include:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-s to skip to the end and just show the final frame.</span><br><span class="line">-n &lt;number&gt; to skip ahead to the n<span class="string">'th animation of a scene.</span></span><br><span class="line"><span class="string">-f to show the file in finder (for OSX).</span></span><br></pre></td></tr></table></figure><p>Anaconda Install</p><p>Install sox and latex as above.<br />Create a conda environment using</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure><p>Using virtualenv and virtualenvwrapper</p><p>After installing virtualenv and virtualenvwrapper</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip3 install virtualenvwrapper</span><br><span class="line">VIRTUALENVWRAPPER_PYTHON=/usr/<span class="built_in">local</span>/bin/python3</span><br><span class="line"><span class="built_in">source</span> /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">virtualenvwrapper.sh</span><br></pre></td></tr></table></figure><p>mk_manim</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv -r requirements.txt mk_manim</span><br><span class="line">(mk_manim) $ python -m pip install pycairo</span><br><span class="line">(mk_manim) $ python3 -m manim example_scenes.py SquareToCircle -pl</span><br></pre></td></tr></table></figure><h2 id="error">Error</h2><p>Manim ModuleNotFoundError: No module named 'cairo'<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install pycairo</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><section class="footnotes" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>AnimationsWithManim: <a href="https://github.com/Elteoremadebeethoven/AnimationsWithManim" target="_blank" rel="noopener" class="uri">https://github.com/Elteoremadebeethoven/AnimationsWithManim</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn2" role="doc-endnote"><p>MacTex: <a href="https://www.tug.org/mactex/mactex-download.html" target="_blank" rel="noopener" class="uri">https://www.tug.org/mactex/mactex-download.html</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn3" role="doc-endnote"><p>Homebrew: <a href="https://brew.sh" target="_blank" rel="noopener" class="uri">https://brew.sh</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn4" role="doc-endnote"><p>Python: <a href="https://www.python.org/downloads/" target="_blank" rel="noopener" class="uri">https://www.python.org/downloads/</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn5" role="doc-endnote"><p>Manim: <a href="https://github.com/3b1b/manim" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn6" role="doc-endnote"><p><a href="https://github.com/3b1b/manim/issues/392" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim/issues/392</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/01/manim-turorial/0.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;manim&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/3b1b/manim&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://github.com/3b1b/manim&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Installation 安装&lt;/p&gt;
&lt;p&gt;Manim runs on &lt;code&gt;Python 3.7&lt;/code&gt;. You can install it from PyPI via pip:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip3 install manimlib&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;System requirements are cairo, ffmpeg, sox, latex (optional, if you want to use LaTeX).&lt;/p&gt;
&lt;p&gt;You can now use it via the manim command. For example:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;manim my_project.py MyScene&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://2020.iosdevlog.com/categories/math/"/>
    
    
      <category term="manim" scheme="https://2020.iosdevlog.com/tags/manim/"/>
    
  </entry>
  
  <entry>
    <title>《Python神经网络编程》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/29/9787115474810/"/>
    <id>https://2020.iosdevlog.com/2020/02/29/9787115474810/</id>
    <published>2020-02-29T14:47:41.000Z</published>
    <updated>2020-03-02T12:22:46.494Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/1.jpg" alt="" /><figcaption>《Python神经网络编程》</figcaption></figure><p>书名：Python神经网络编程<br />作者：[英]塔里克·拉希德（Tariq Rashid）<br />译者：林赐<br />出版社：人民邮电出版社<br />出版时间：2018-04<br />ISBN：9787115474810</p><p><strong>参照本书，自己可以动手写一个简单的神经网络，还不快来看看。</strong></p><a id="more"></a><h2 id="内容提要">内容提要</h2><p>神经网络是一种模拟人脑的神经网络，以期能够实现类人工智能的机器学习技术。</p><p>本书揭示神经网络背后的概念，并介绍如何通过Python实现神经网络。</p><p>全书分为3章和两个附录。</p><ol type="1"><li>第1章介绍了神经网络中所用到的数学思想。<ul><li>我们将如清风拂面般，一览在简单的神经网络中所用的数学思想。我们有意不介绍任何计算机编程知识，以避免喧宾夺主地干扰了本书的核心思想。</li></ul></li><li>第2章 介绍使用Python实现神经网络，识别手写数字，并测试神经网络的性能。<ul><li>我们将学习足以实现自己的神经网络的Python知识。我们将训练神经网络，识别手写数字，并且会测试神经网络的性能。</li></ul></li><li>第3章 带领读者进一步了解简单的神经网络，观察已受训练的神经网络内部，尝试进一步改善神经网络的性能，并加深对相关知识的理解。<ul><li>我们将进一步了解简单的神经网络，这超出了了解基本神经网络知识的范畴，但是我们这样做只是为了获得一些乐趣。我们将尝试一些想法，进一步改善神经网络的性能，我们将观察已受训练的神经网络内部，看看我们是否理解神经网络所学习到的知识，是否理解神经网络是如何做出决定进行回答的。</li></ul></li></ol><p>附录分别介绍了所需的微积分知识和树莓派知识。</p><h3 id="本书适合">本书适合</h3><ol type="1"><li>想要从事神经网络研究和探索的读者学习参考</li><li>对人工智能、机器学习和深度学习等相关领域感兴趣</li></ol><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/2.jpg" alt="" /><figcaption>国际象棋机器Turkey</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/3.jpg" alt="" /><figcaption>MNIST</figcaption></figure><h2 id="第1章-神经网络如何工作">第1章 神经网络如何工作</h2><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/4.jpg" alt="" /><figcaption>处理图像</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/4.jpg" alt="" /><figcaption>对比</figcaption></figure><blockquote><p>有些任务，对传统的计算机而言很容易，对人类而言却很难。例如，对数百万个数字进行乘法运算。</p><p>另一方面，有些任务对传统的计算机而言很难，对人类而言却很容易。例如，从一群人的照片中识别出面孔。</p></blockquote><h3 id="一台简单的预测机">一台简单的预测机</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/6.jpg" alt="" /><figcaption>机器</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/7.jpg" alt="" /><figcaption>计算</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/8.jpg" alt="" /><figcaption>一组加法</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/9.jpg" alt="" /><figcaption>转化</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/10.jpg" alt="" /><figcaption>真实情况</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/11.jpg" alt="" /><figcaption>常数C</figcaption></figure><p><span class="math display">\[误差值=真实值-计算值=62.137-50=12.137\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/12.jpg" alt="" /><figcaption>误差值</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/13.jpg" alt="" /><figcaption>误差值变小</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/14.jpg" alt="" /><figcaption>超调</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/15.jpg" alt="" /><figcaption>微调C</figcaption></figure><blockquote><p>所有有用的计算机系统都有一个输入和一个输出，并在输入和输出之间进行某种类型的计算。神经网络也是如此。</p><p>当我们不能精确知道一些事情如何运作时，我们可以尝试使用模型来估计其运作方式，在模型中，包括了我们可以调整的参数。</p><p>如果我们不知道如何将千米转换为英里，那么我们可以使用线性函数作为模型，并使用可调节的梯度值作为参数。改进这些模型的一种好方法是，基于模型和已知真实示例之间的比较，得到模型偏移的误差值，调整参数。</p></blockquote><h3 id="分类器与预测器并无太大差别">分类器与预测器并无太大差别</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/16.jpg" alt="" /><figcaption>小虫子的宽度和长度</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/17.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/18.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/19.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/20.jpg" alt="" /><figcaption>未知小虫</figcaption></figure><h3 id="训练简单的分类器">训练简单的分类器</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/21.jpg" alt="" /><figcaption>实例</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/22.jpg" alt="" /><figcaption>可视化数据</figcaption></figure><p><span class="math display">\[y=A x\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/23.jpg" alt="" /><figcaption>斜率</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/24.jpg" alt="" /><figcaption>误差值</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/25.jpg" alt="" /><figcaption>ΔA)</figcaption></figure><p><span class="math display">\[\Delta \mathrm{A}=\mathrm{L}(\mathrm{E} / x)\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/26.jpg" alt="" /><figcaption>最终直线</figcaption></figure><blockquote><p>我们使用简单的数学，理解了线性分类器输出误差值和可调节斜率参数之间的关系。也就是说，我们知道了在何种程度上调整斜率，可以消除输出误差值。</p><p>使用朴素的调整方法会出现一个问题，即改进后的模型只与最后一次训练样本最匹配，“有效地”忽略了所有以前的训练样本。解决这个问题的一种好方法是使用学习率，调节改进速率，这样单一的训练样本就不能主导整个学习过程。</p><p>来自真实世界的训练样本可能充满噪声或包含错误。适度更新有助于限制这些错误样本的影响。</p></blockquote><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/27.jpg" alt="" /><figcaption>27</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/28.jpg" alt="" /><figcaption>28</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/29.jpg" alt="" /><figcaption>29</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/30.jpg" alt="" /><figcaption>30</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/31.jpg" alt="" /><figcaption>31</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/32.jpg" alt="" /><figcaption>32</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/33.jpg" alt="" /><figcaption>33</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/34.jpg" alt="" /><figcaption>34</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/35.jpg" alt="" /><figcaption>35</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/36.jpg" alt="" /><figcaption>36</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/37.jpg" alt="" /><figcaption>37</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/38.jpg" alt="" /><figcaption>38</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/39.jpg" alt="" /><figcaption>39</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/40.jpg" alt="" /><figcaption>40</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/41.jpg" alt="" /><figcaption>41</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/42.jpg" alt="" /><figcaption>42</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/43.jpg" alt="" /><figcaption>43</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/44.jpg" alt="" /><figcaption>44</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/45.jpg" alt="" /><figcaption>45</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/46.jpg" alt="" /><figcaption>46</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/47.jpg" alt="" /><figcaption>47</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/48.jpg" alt="" /><figcaption>48</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/49.jpg" alt="" /><figcaption>49</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/50.jpg" alt="" /><figcaption>50</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/51.jpg" alt="" /><figcaption>51</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/52.jpg" alt="" /><figcaption>52</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/53.jpg" alt="" /><figcaption>53</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/54.jpg" alt="" /><figcaption>54</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/55.jpg" alt="" /><figcaption>55</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/56.jpg" alt="" /><figcaption>56</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/57.jpg" alt="" /><figcaption>57</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/58.jpg" alt="" /><figcaption>58</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/59.jpg" alt="" /><figcaption>59</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/60.jpg" alt="" /><figcaption>60</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/61.jpg" alt="" /><figcaption>61</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/62.jpg" alt="" /><figcaption>62</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/63.jpg" alt="" /><figcaption>63</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/64.jpg" alt="" /><figcaption>64</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/65.jpg" alt="" /><figcaption>65</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/66.jpg" alt="" /><figcaption>66</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/67.jpg" alt="" /><figcaption>67</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/68.jpg" alt="" /><figcaption>68</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/69.jpg" alt="" /><figcaption>69</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/70.jpg" alt="" /><figcaption>70</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/71.jpg" alt="" /><figcaption>71</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/72.jpg" alt="" /><figcaption>72</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/73.jpg" alt="" /><figcaption>73</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/74.jpg" alt="" /><figcaption>74</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/75.jpg" alt="" /><figcaption>75</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/76.jpg" alt="" /><figcaption>76</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/77.jpg" alt="" /><figcaption>77</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/78.jpg" alt="" /><figcaption>78</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/79.jpg" alt="" /><figcaption>79</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/80.jpg" alt="" /><figcaption>80</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/81.jpg" alt="" /><figcaption>81</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/82.jpg" alt="" /><figcaption>82</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/83.jpg" alt="" /><figcaption>83</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/84.jpg" alt="" /><figcaption>84</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/85.jpg" alt="" /><figcaption>85</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/86.jpg" alt="" /><figcaption>86</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/87.jpg" alt="" /><figcaption>87</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/88.jpg" alt="" /><figcaption>88</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/89.png" alt="" /><figcaption>89</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/90.jpg" alt="" /><figcaption>90</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/91.jpg" alt="" /><figcaption>91</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/92.jpg" alt="" /><figcaption>92</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/93.jpg" alt="" /><figcaption>93</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/94.jpg" alt="" /><figcaption>94</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/95.jpg" alt="" /><figcaption>95</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/96.jpg" alt="" /><figcaption>96</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/97.jpg" alt="" /><figcaption>97</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/98.jpg" alt="" /><figcaption>98</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/99.jpg" alt="" /><figcaption>99</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/100.jpg" alt="" /><figcaption>100</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/101.jpg" alt="" /><figcaption>101</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/102.jpg" alt="" /><figcaption>102</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/103.jpg" alt="" /><figcaption>103</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/104.jpg" alt="" /><figcaption>104</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/105.jpg" alt="" /><figcaption>105</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/106.jpg" alt="" /><figcaption>106</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/107.jpg" alt="" /><figcaption>107</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/108.jpg" alt="" /><figcaption>108</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/109.jpg" alt="" /><figcaption>109</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/110.jpg" alt="" /><figcaption>110</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/111.jpg" alt="" /><figcaption>111</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/112.jpg" alt="" /><figcaption>112</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/113.jpg" alt="" /><figcaption>113</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/114.jpg" alt="" /><figcaption>114</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/115.jpg" alt="" /><figcaption>115</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/116.jpg" alt="" /><figcaption>116</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/117.jpg" alt="" /><figcaption>117</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/118.png" alt="" /><figcaption>118</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/119.png" alt="" /><figcaption>119</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/120.png" alt="" /><figcaption>120</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/121.png" alt="" /><figcaption>121</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/122.jpg" alt="" /><figcaption>122</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/123.jpg" alt="" /><figcaption>123</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/124.jpg" alt="" /><figcaption>124</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/125.jpg" alt="" /><figcaption>125</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/126.jpg" alt="" /><figcaption>126</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/127.jpg" alt="" /><figcaption>127</figcaption></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/29/9787115474810/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《Python神经网络编程》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：Python神经网络编程&lt;br /&gt;
作者：[英]塔里克·拉希德（Tariq Rashid）&lt;br /&gt;
译者：林赐&lt;br /&gt;
出版社：人民邮电出版社&lt;br /&gt;
出版时间：2018-04&lt;br /&gt;
ISBN：9787115474810&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参照本书，自己可以动手写一个简单的神经网络，还不快来看看。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="NN" scheme="https://2020.iosdevlog.com/tags/NN/"/>
    
      <category term="Python" scheme="https://2020.iosdevlog.com/tags/Python/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>《神经网络与深度学习》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/28/9787121288692/"/>
    <id>https://2020.iosdevlog.com/2020/02/28/9787121288692/</id>
    <published>2020-02-28T15:02:30.000Z</published>
    <updated>2020-03-02T12:22:46.500Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/1.jpg" alt="" /><figcaption>《神经网络与深度学习》</figcaption></figure><p>书名：神经网络与深度学习<br />作者：吴岸城<br />出版社：电子工业出版社<br />出版时间：2016-06<br />ISBN：9787121288692</p><p>本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。</p><p>对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。</p><a id="more"></a><h2 id="介绍">介绍</h2><p>第0章，介绍机器学习、神经网络的历史，好让大家有基本的了解。<br />第1章，解释大脑的运作结构和如何利用仿生学产生逻辑上的神经元和神经网络。<br />第2章，我们用仿生学的知识试着构造一个神经网络（感知机）并使用它做些事情，解释了XOR问题。在2.6节给出一些例子，让我们能更好地了解神经网络是如何分类学习和预测的。<br />第3章，介绍深度学习的基本概念，深度学习和神经网络的联系。<br />第4章，介绍深度学习的常用方法。<br />第5章，介绍AlphaGo。<br />第6章，两个重要概念，迁移学习和概率图模型PGM。<br />第7章，给出了一些经验以加快大家学习和研究的效率。</p><h2 id="术语">术语</h2><ol type="1"><li><strong>图灵</strong>：全名艾伦·麦席森·图灵，英国人，因性倾向遭到当时的英国政府迫害，职业生涯尽毁。他可以说是人工智能之父，笔者十分佩服其才智。</li><li><strong>决策树</strong>：是一个预测模型；它代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，每个叶节点对应从根节点到该叶节点所经历的路径所表示的对象的值。</li><li><strong>条件概率</strong>：就是事件A在另外一个事件B已经发生的条件下的发生概率。条件概率表示为P（A|B），读作“在B条件下A的概率”。</li><li><strong>树突、轴突</strong>：神经元的输入和输出部分。5. AND/XOR/OR：数学逻辑运算。</li><li><strong>人工神经元</strong>：是一种模仿生物神经元的结构和功能的数学模型或计算模型。</li><li><strong>感知机</strong>：它被视为是一种最简单的前馈神经网络，是一种二元线性分类器。</li><li><strong>前馈神经网络</strong>：最简单的人工神经网络类型。在它的内部，参数从输入层向输出层单向传播。</li><li><strong>特征</strong>：本书中指将现实生活中的事物的部分特点提取并抽象出一种数学或物理模型。</li><li><strong>特征粒度</strong>：提取特征的维度。</li><li><strong>浅层学习/深度学习</strong>：相对概念，深度学习相对浅层学习抽象层级要多。12. BP算法（反向传播算法）：是一种监督学习算法，常被用来训练多层感知机，利用反向传播原理修正权值。</li><li><strong>自动编码器（AE）</strong>：自动编码器就是一个运用了反向传播进行无监督学习的神经网络，学习的目的是为了让输出值和输入值相等。14. RBM（限制波兹曼机）：是一种可通过输入数据集学习概率分布的随机生成神经网络。</li><li><strong>概率模型</strong>：是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。</li><li><strong>能量模型（EBM）</strong>：基于能量的模型，把我们关心的变量的各种组合和一个标量能量联系在一起。我们训练模型的过程就是不断改变标量能量的过程。</li><li><strong>DBN（深度信度网络）</strong>：通过自底向上组合多个RBM可以构建一个DBN，利用非监督贪心逐层训练算法，解决深层结构相关的优化问题。18. CNN（卷积神经网络/ConvNets）：是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</li><li><strong>概率图</strong>：是一种使用图来表达随机变量之间条件独立性的概率模型。</li><li><strong>贝叶斯定理</strong>：事件A在事件B（发生）的条件下的概率。</li><li><strong>SVM（支持向量机）</strong>：监督学习方法，属于一般化线性分类器。这种分类器的特点是它们能够同时最小化经验误差与最大化几何边缘区，因此支持向量机也被称为最大边缘区分类器。</li><li><strong>K-Means</strong>：把n个点（可以是样本的一次观察或一个实例）划分到k个聚类中，使得每个点都属于离它最近的均值（此即聚类中心）对应的聚类。</li><li><strong>Java</strong>：一种面向对象的高级语言。</li><li><strong>Python</strong>：是一种解释型的计算机程序语言，具有近20年的发展历史。它包含了一组功能完备的标准库，能够轻松完成很多常见的任务。</li><li><strong>MATLAB</strong>：是一款由美国TheMathWorks公司出品的商业数学软件。MATLAB是一种用于算法开发、数据可视化、数据分析及数值计算的高级技术计算语言和交互式环境。</li><li><strong>C++</strong>：是一种广泛使用的计算机程序设计语言。</li><li><strong>并行计算</strong>：一般是指许多指令得以同时进行的计算模式。</li><li><strong>NASA</strong>：国家航空航天局（英语：National Aeronautics and SpaceAdministration，缩写为NASA），是美国联邦政府的一个行政机构，负责制定、实施美国的民用太空计划，并开展航空科学暨太空科学的研究。</li></ol><h2 id="写在前面神经网络的历史">0 写在前面：神经网络的历史</h2><p>神经网络，是机器学习的一个分支，学名应该叫人工神经网络，与之相对应的是生物神经网络（Biological Neural Networks, BNN），我们将模拟生物神经网络的数学模型统称为人工神经网络模型，简称人工神经网络或者神经网络。</p><p><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/2.jpg" alt="阿兰·麦席森·图灵" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/3.jpg" alt="约翰·麦卡锡" /></p><p>图灵测试（Turing test，又译图灵试验）是图灵提出的一个关于机器能否思考的著名判断原则。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/4.jpg" alt="" /><figcaption>麦卡洛可</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/5.jpg" alt="" /><figcaption>皮茨</figcaption></figure><p>麦卡洛可: 神经科学</p><p>+</p><p>皮茨: 数学</p><p>=</p><p>《神经活动中思想内在性的逻辑演算》（A LogicalCalculus of Ideas Immanent in Nervous Activity）</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/6.jpg" alt="" /><figcaption>诺伯特·维纳</figcaption></figure><p>诺伯特·维纳：控制论</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/7.jpg" alt="" /><figcaption>迈克尔·阿比卜</figcaption></figure><p>迈克尔·阿比卜：创立麻省理工学院的计算机</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/8.jpg" alt="" /><figcaption>弗兰克·罗森布拉特</figcaption></figure><blockquote><p>“感知器最终将能够学习，做出决策和翻译语言”</p></blockquote><p>弗兰克·罗森布拉特：“感知机”（Perceptron）的神经网络模型</p><p>《神经动力学原理：感知机和大脑机制的理论》（Principles of Neurodynamics: Perceptrons and the Theory ofBrainMechanisms）</p><p>保罗·沃波斯（Paul Werbos）：“反向传播算法”（Backpropagation Algorithm，简称BP算法）</p><p>是一种监督学习算法，常被用来训练多层感知机。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/9.jpg" alt="" /><figcaption>霍普菲尔德</figcaption></figure><p>霍普菲尔德：递归神经网络</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/10.jpg" alt="" /><figcaption>鲁姆哈特（David Rumelhart）</figcaption></figure><p>鲁姆哈特（David Rumelhart）：完整地提出了BP算法，完整的推导。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/11.jpg" alt="" /><figcaption>杰弗里·辛顿（Geoffrey Hinton）</figcaption></figure><p>杰弗里·辛顿（Geoffrey Hinton）：反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者</p><p>吴恩达：识别“猫”，“深度学习”领域的经典案例</p><h2 id="神经网络是个什么东西">1 神经网络是个什么东西</h2><p><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/12.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/13.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/14.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/15.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/16.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/17.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/18.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/19.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/20.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/21.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/22.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/23.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/24.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/25.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/26.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/27.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/28.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/29.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/30.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/31.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/32.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/33.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/34.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/35.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/36.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/37.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/38.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/39.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/40.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/41.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/42.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/43.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/44.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/45.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/46.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/47.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/48.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/49.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/50.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/51.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/52.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/53.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/54.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/55.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/56.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/57.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/58.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/59.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/60.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/61.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/62.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/63.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/64.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/65.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/66.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/67.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/68.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/69.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/70.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/71.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/72.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/73.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/74.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/75.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/76.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/77.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/78.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/79.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/80.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/81.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/82.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/83.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/84.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/85.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/86.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/87.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/88.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/89.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/90.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/91.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/92.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/93.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/94.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/95.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/96.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/97.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/98.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/99.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/100.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/101.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/102.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/103.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/104.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/105.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/106.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/107.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/108.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/109.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/110.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/111.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/112.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/113.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/114.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/115.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/116.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/117.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/118.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/119.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/120.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/121.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/122.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/123.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/124.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/125.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/126.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/127.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/128.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/129.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/130.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/131.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/132.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/133.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/134.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/135.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/136.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/137.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/138.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/139.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/140.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/141.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/142.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/143.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/144.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/145.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/146.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/147.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/148.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/149.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/150.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/151.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/152.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/153.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/154.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/155.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/156.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/157.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/158.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/159.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/160.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/161.jpg" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/28/9787121288692/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《神经网络与深度学习》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：神经网络与深度学习&lt;br /&gt;
作者：吴岸城&lt;br /&gt;
出版社：电子工业出版社&lt;br /&gt;
出版时间：2016-06&lt;br /&gt;
ISBN：9787121288692&lt;/p&gt;
&lt;p&gt;本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。&lt;/p&gt;
&lt;p&gt;对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>《深度学习与图像识别：原理与实践》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/27/9787111630036/"/>
    <id>https://2020.iosdevlog.com/2020/02/27/9787111630036/</id>
    <published>2020-02-27T11:41:38.000Z</published>
    <updated>2020-02-27T15:39:26.676Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/1.jpg" alt="" /><figcaption>《深度学习与图像识别：原理与实践》</figcaption></figure><p>书名：深度学习与图像识别：原理与实践<br />作者：魏溪含，涂铭，张修鹏<br />出版社：机械工业出版社<br />出版时间：2019-06<br />ISBN：9787111630036</p><a id="more"></a><h2 id="介绍">介绍</h2><p>第 1 章 介绍图像识别的一些应用场景，让读者对图像识别有个初步的认识。<br />第 2 章 主要对图像识别的工程背景做简单介绍，同时介绍了本书后续章 节实战案例中会用到的环境，因此该章 是实战的基础。<br />第 3～6 章 是图像识别的技术基础，包括机器学习、神经网络等。该部分的代码主要使用Python实现。没有机器学习基础的同学需要理解这几章 之后再往下看，有机器学习基础的同学可以有选择地学习。<br />第 7 章 是一个过渡章 节，虽然<br />第 6 章 中手动用Python实现了神经网络，但由于本书后面的图像识别部分主要使用PyTorch实现，因此使用该章 作为过渡，介绍如何使用PyTorch来搭建神经网络。<br />第 8～12章 为图像识别的核心。<br />第 8 章 首先介绍了图像中的卷积神经网络与普通神经网络的异同，并给出了常见的卷积神经网络结构。接下来的<br />第 9 ～12章 分别介绍了图像识别中的检测、分割、产生式模型以及可视化的问题，并在每章 后面给出相应的实战案例。<br />第 13 章 简单介绍了图像识别的工业部署模式，以帮助读者构建一个更完整的知识体系。</p><h2 id="第1章-机器视觉在行业中的应用">第1章 机器视觉在行业中的应用</h2><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/2.jpg" alt="" /><figcaption>人工智能相关领域关系图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/3.jpg" alt="" /><figcaption>人工智能的第三个“春天”</figcaption></figure><h3 id="机器视觉的主要应用场景">机器视觉的主要应用场景</h3><h4 id="人脸识别face-recognition">人脸识别（Face Recognition）</h4><p>处理过程</p><p>人脸图像采集及检测<br />人脸图像预处理<br />人脸图像特征提取<br />匹配与识别</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/4.jpg" alt="" /><figcaption>人脸识别的主要应用场景</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/5.jpg" alt="" /><figcaption>人脸识别应用场景</figcaption></figure><h4 id="视频监控分析">视频监控分析</h4><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/6.jpg" alt="视频监控分析的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/7.jpg" alt="交通异常事件监测" /></p><h4 id="工业瑕疵检测">工业瑕疵检测</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/8.jpg" alt="" /><figcaption>工业瑕疵诊断应用场景</figcaption></figure><h4 id="图片识别分析">图片识别分析</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/9.jpg" alt="" /><figcaption>图片识别应用效果</figcaption></figure><h4 id="自动驾驶驾驶辅助">自动驾驶/驾驶辅助</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/10.jpg" alt="" /><figcaption>自动驾驶汽车应用场景</figcaption></figure><p>技术链</p><ul><li>感知阶段<ol type="1"><li>使用机器视觉获取场景中的深度信息，以帮助进行后续的图像语义理解，在自动驾驶中帮助探索可行驶区域和目标障碍物。</li><li>通过视频预估每一个像素的运动方向和运动速度。</li><li>对物体进行检测与追踪。在无人驾驶中，检测与追踪的目标主要是各种车辆、行人、非机动车。</li><li>对于整个场景的理解。最重要的有两点，第一是道路线检测，其次是在道路线检测下更进一步，即将场景中的每一个像素都打成标签，这也称为场景分割或场景解析。</li><li>同步地图构建和定位技术。</li></ol></li><li>规划阶段</li><li>控制阶段</li></ul><h4 id="三维图像视觉">三维图像视觉</h4><h4 id="医疗影像诊断">医疗影像诊断</h4><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/11.jpg" alt="医疗影像诊断的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/12.jpg" alt="肝脏及结节分割技术" /></p><h4 id="文字识别ocr">文字识别（OCR）</h4><p>计算机文字识别，俗称光学字符识别（Optical Character Recognition），是利用光学扫描技术将票据、报刊、书籍、文稿及其他印刷品的文字转化为图像信息，再利用文字识别技术将图像信息转化为可以使用的计算机输入技术。</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/13.jpg" alt="文字识别技术的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/14.jpg" alt="文字识别技术的应用场景" /></p><h4 id="图像视频的生成及设计">图像/视频的生成及设计</h4><h2 id="第2章-图像识别前置技术">第2章 图像识别前置技术</h2><h3 id="深度学习框架">深度学习框架</h3><ul><li>Theano</li><li>Tensorflow</li><li>MXNet</li><li>Keras</li><li>PyTorch</li><li>Caffe</li></ul><h3 id="搭建图像识别开发环境">搭建图像识别开发环境</h3><p>Anaconda</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/16.jpg" alt="Anaconda的下载" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/17.jpg" alt="打开Anaconda进入Jupyter" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/18.jpg" alt="Jupyter notebook界面" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/19.jpg" alt="Anaconda环境测试界面" /></p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/20.jpg" alt="" /><figcaption>通过conda搜索beautifulsoup</figcaption></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第2~7章代码运行的环境：</span></span><br><span class="line">conda create -n basic_env  python=3.7        <span class="comment"># 创建一个名为basic_env的环境</span></span><br><span class="line"><span class="built_in">source</span> activate basic_env                <span class="comment"># 激活这个环境—Linux和macOS代码</span></span><br><span class="line">activate basic_env                        <span class="comment"># 激活这个环境—Windows代码</span></span><br><span class="line"><span class="comment"># 创建第8~12章代码运行的环境：</span></span><br><span class="line">conda create -n imgrecognition_env  python=3.7</span><br><span class="line">                                                <span class="comment"># 创建一个名为imgrecognition _env的环境</span></span><br><span class="line"><span class="built_in">source</span> activate imgrecognition _env        <span class="comment"># 激活这个环境—Linux和macOS代码</span></span><br><span class="line">activate imgrecognition_env                <span class="comment"># 激活这个环境—Windows代码</span></span><br></pre></td></tr></table></figure><p>Pytorch 的下载与安装</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/22.jpg" alt="" /><figcaption>PyTorch安装界面</figcaption></figure><h3 id="numpy">Numpy</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/24.jpg" alt="创建数组" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/25.jpg" alt="创建数组" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/26.jpg" alt="在Notebook中引入Numpy" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/28.jpg" alt="Numpy预置函数及说明" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/31.jpg" alt="KNN例子" /></p><h2 id="第3章-图像分类之knn算法">第3章 图像分类之KNN算法</h2><h3 id="knn的理论基础与实现">KNN的理论基础与实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/33.jpg" alt="KNN例子的散点图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/34.jpg" alt="电脑看到的图片均为0～255的数字" /></p><h3 id="图像分类识别预备知识">图像分类识别预备知识</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/36.jpg" alt="归一化图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/37.jpg" alt="数字5" /></p><h3 id="knn实战">KNN实战</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/38.jpg" alt="两张图片曼哈顿距离的计算方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/39.jpg" alt="数字7" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/40.jpg" alt="Cifar10数据集示例" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/41.jpg" alt="青蛙图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/42.jpg" alt="整个数据集" /></p><h3 id="模型参数调优">模型参数调优</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/43.jpg" alt="整个数据集拆分成训练集和测试集" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/44.jpg" alt="训练集、验证集和测试集" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/45.jpg" alt="交叉验证的数据拆分方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/46.jpg" alt="图像中具体某个像素值的无意义性" /></p><h2 id="第4章-机器学习基础">第4章 机器学习基础</h2><h3 id="线性回归模型">线性回归模型</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/48.jpg" alt="" /><figcaption>线性回归拟合直线</figcaption></figure><h3 id="逻辑回归模型">逻辑回归模型</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/68.jpg" alt="逻辑回归分类示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/69.jpg" alt="Sigmoid函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/73.jpg" alt="Sigmoid函数图像" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/74.jpg" alt="损失函数示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/75.jpg" alt="一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/76.jpg" alt="学习率η=0.01时，一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/77.jpg" alt="学习率η=0.8时，一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/78.jpg" alt="学习率η=1.1时，一元二次损失函数不收敛" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/82.jpg" alt="损失函数if y=1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/84.jpg" alt="损失函数if y=0" /></p><h2 id="第5章-神经网络基础">第5章 神经网络基础</h2><h3 id="神经网络">神经网络</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/95.jpg" alt="神经网络全连接结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/96.jpg" alt="多隐藏层结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/97.jpg" alt="神经元结构图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/98.jpg" alt="简单神经元" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/99.jpg" alt="训练网络" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/100.jpg" alt="神经元个数较少" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/101.jpg" alt="神经元个数较多" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/102.jpg" alt="神经元个数更多" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/103.jpg" alt="线性分类图1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/104.jpg" alt="线性分类图2" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/105.jpg" alt="线性不可分" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/106.jpg" alt="激活函数表达能力" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/108.jpg" alt="Sigmoid函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/110.jpg" alt="Tanh函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/111.jpg" alt="ReLU函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/112.jpg" alt="前向传播 1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/113.jpg" alt="节点1节点2" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/116.jpg" alt="前向传播 2" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/118.jpg" alt="增加bias" /></p><h3 id="输出层">输出层</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/119.jpg" alt="Softmax" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/124.jpg" alt="猫狗小鸡分类" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/127.jpg" alt="输出层的神经元个数" /></p><h3 id="批处理">批处理</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/128.jpg" alt="单个处理" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/129.jpg" alt="批处理" /></p><h3 id="广播原则">广播原则</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/130.jpg" alt="广播原则1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/131.jpg" alt="广播原则2" /></p><h3 id="损失函数">损失函数</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/132.jpg" alt="均方误差" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/136.jpg" alt="交叉熵误差" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/137.jpg" alt="带入Loss函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/138.jpg" alt="Mini-batch" /></p><h3 id="最优化">最优化</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/139.jpg" alt="" /><figcaption>一维函数求导</figcaption></figure><h2 id="第6章-误差反向传播">第6章 误差反向传播</h2><h3 id="激活函数层的实现">激活函数层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/144.jpg" alt="x+y计算图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/145.jpg" alt="（x+y）*z的计算图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/148.jpg" alt="ReLU反向传播实现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/149.jpg" alt="导数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/150.jpg" alt="Sigmoid反向传播实现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/151.jpg" alt="Sigmoid计算图" /></p><h3 id="affine层的实现">Affine层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/152.jpg" alt="152" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/153.jpg" alt="153" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/154.jpg" alt="154" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/155.jpg" alt="155" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/162.jpg" alt="162" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/163.jpg" alt="163" /></p><h3 id="softmaxwithloss层的实现">Softmaxwithloss层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/164.jpg" alt="164" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/165.jpg" alt="165" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/166.jpg" alt="166" /></p><h3 id="正则化惩罚">正则化惩罚</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/167.jpg" alt="167" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/169.jpg" alt="169" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/171.jpg" alt="正则化项在神经网络中的重要作用" /></p><h2 id="第7章-pytorch实现神经网络图像分类">第7章 PyTorch实现神经网络图像分类</h2><h3 id="pytorch的使用">PyTorch的使用</h3><p>Variable</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/172.jpg" alt="" /><figcaption>Variable</figcaption></figure><p>激活函数</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/173.jpg" alt="" /><figcaption>激活函数可视化</figcaption></figure><h3 id="pytorch实战">PyTorch实战</h3><h2 id="第8章-卷积神经网络">第8章 卷积神经网络</h2><p>卷积神经网络（Convolutional Neural Network，CNN）是一种深度前馈神经网络，目前在图片分类、图片检索、目标检测、目标分割、目标跟踪、视频分类、姿态估计等图像视频相关领域中已有很多较为成功的应用。</p><h3 id="卷积神经网络基础">卷积神经网络基础</h3><p>全连接层（Fully Connected Layer）</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/174.jpg" alt="" /><figcaption>全连接示意图</figcaption></figure><p>卷积层（Convolution Layer）</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/175.jpg" alt="一维卷积kernel=1*3，stride=1计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/176.jpg" alt="一维卷积kernel=1*3，stride=2计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/177.jpg" alt="二维卷积，kernel=3*3，stride=1计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/178.jpg" alt="二维卷积，kernel=3*3，stride=2计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/179.jpg" alt="三维卷积kernel=553，stride=1，计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/181.jpg" alt="卷积神经网络示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/182.jpg" alt="kernel=3*3，pad=1示意图" /></p><p>池化层</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/182.jpg" alt="" /><figcaption>池化filter=2*2，stride=2的最大池化（max pooling）操作</figcaption></figure><h3 id="常见卷积神经网络结构">常见卷积神经网络结构</h3><p>AlexNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/187.jpg" alt="AlexNet" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/188.jpg" alt="ReLUs与tanh作为激活函数在4层卷积神经网络中的收敛速度对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/189.jpg" alt="ILSVRC图像识别分类比赛优胜情况" /></p><p>VGGNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/190.jpg" alt="AlexNet和VGGNet网络结构对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/191.jpg" alt="一维卷积中3组33与1组77kernel效果相同的原理解说图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/192.jpg" alt="VGG16Net网络结构" /></p><p>GoogLeNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/193.jpg" alt="矩阵转换方式" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/194.jpg" alt="简单的inception结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/195.jpg" alt="简单inception结构对应计算量" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/196.jpg" alt="降维的inception结构及计算量推导" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/197.jpg" alt="GoogLeNet网络结构图" /></p><p>ResNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/198.jpg" alt="一个20层和56层卷积神经网络中训练和预测过程中的误差情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/201.jpg" alt="普通卷积层与残差卷积层" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/202.jpg" alt="ResNet网络结构缩略图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/203.jpg" alt="不同网络结构性能对比" /></p><p>ResNeXT</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/204.jpg" alt="加宽的残差网络模块" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/205.jpg" alt="ResNeXT网络模块" /></p><p>DenseNet</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/206.jpg" alt="" /><figcaption>DenseNet核心网络结构</figcaption></figure><h3 id="vgg16实现cifar10分类">VGG16实现Cifar10分类</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/207.jpg" alt="" /><figcaption>VGG16训练Cifar10过程输出</figcaption></figure><h2 id="第9章-目标检测">第9章 目标检测</h2><h3 id="定位分类">定位+分类</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/208.jpg" alt="检测问题定义" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/209.jpg" alt="分类问题vs定位问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/210.jpg" alt="分类+定位网络结构设计" /></p><h3 id="目标检测">目标检测</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/211.jpg" alt="使用定位+分类解决目标检测存在的问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/212.jpg" alt="使用滑窗方法做目标检测存在的问题：滑窗的尺寸、大小、位置不同将产生非常大的计算量" /></p><p>R-CNN</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/213.jpg" alt="R-CNN训练过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/214.jpg" alt="不同压缩方法图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/215.jpg" alt="IOU图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/217.jpg" alt="R-CNN中的ROI结果微调" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/218.jpg" alt="Fast R-CNN训练和预测过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/219.jpg" alt="Fast R-CNN中的ROI Pooling" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/220.jpg" alt="R-CNN和Fast R-CNN训练和测试时间对比" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/221.jpg" alt="Faster R-CNN训练流程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/222.jpg" alt="RPN原理" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/223.jpg" alt="RCNN、Fast R-CNN、Faster R-CNN模型耗时对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/224.jpg" alt="RCNN、Fast R-CNN、Faster R-CNN模型对比" /></p><p>YOLO</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/225.jpg" alt="" /><figcaption>基于PASCAL VOC2012目标检测数据集的YOLO示意图</figcaption></figure><p>SSD</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/226.jpg" alt="SSD特征层与anchor示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/227.jpg" alt="SSD结构图" /></p><h3 id="ssd实现voc目标检测">SSD实现VOC目标检测</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/228.jpg" alt="原始图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/229.jpg" alt="语义分割的真实label图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/230.jpg" alt="实例分割的真实label图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/231.jpg" alt="ResNet50训练PASCAL VOC过程部分打印结果展示" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/232.jpg" alt="SSD效果示意图（未完全迭代的结果）" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/233.jpg" alt="SSD作者在VOC2007数据集上达到的效果" /></p><h2 id="第10章-分割">第10章 分割</h2><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/234.jpg" alt="分割问题定义" /></p><p>FCN</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/235.jpg" alt="最简单直观的语义分割方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/236.jpg" alt="改良后的CNN语义分割网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/237.jpg" alt="Unpooling的几种方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/238.jpg" alt="卷积和反卷积图例" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/239.jpg" alt="kernel为3、stride为2的1维反卷积计算过程" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/240.jpg" alt="U-Net结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/241.jpg" alt="CrackForest训练数据展示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/242.jpg" alt="U-Net预测CrackForest结果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/243.jpg" alt="SegNet的网络结构" /></p><p>PSPNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/244.jpg" alt="语义分割容易出现的问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/245.jpg" alt="PSPNet的网络结构" /></p><h3 id="实例分割">实例分割</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/246.jpg" alt="检测、分割任务对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/247.jpg" alt="多任务学习中“head”的设定方法" /></p><p>层叠式</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/248.jpg" alt="" /><figcaption>层叠式实例分割网络结构</figcaption></figure><p>扁平式</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/249.jpg" alt="Mask R-CNN的网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/250.jpg" alt="Mask-RCNN的网络head的设计细节" /></p><h2 id="第11章-产生式模型">第11章 产生式模型</h2><p>机器学习</p><ol type="1"><li>有监督学习</li><li>无监督学习</li><li>强化学习</li></ol><p>数据集</p><ol type="1"><li>数据x</li><li>标签y</li></ol><h3 id="自编码器autoencoder">自编码器（Autoencoder）</h3><h3 id="对抗生成网络">对抗生成网络</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/251.jpg" alt="Autoencoder学习过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/252.jpg" alt="GAN的训练结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/254.jpg" alt="GAN最终使用的产生器" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/255.jpg" alt="产生器生成的一些假图的例子" /></p><h3 id="dcgan及实战">DCGAN及实战</h3><p>DCGAN（Deep Convolutional Generative Adversarial Network）由Radford等人提出，结合了深度卷积神经网络和GAN，并对上述GAN进行了扩展。DCGAN将GAN中的产生器G和判别器D都换成了卷积神经网络，并对其中的卷积做了一些改动以提高收敛速度，具体如下。</p><ol type="1"><li>用不同步长的卷积层替换所有Pooling层。</li><li>在D和G中均使用BatchNorm层。</li><li>在G网络中，除最后一层使用tanh以外，其余层均使用ReLU作为激活函数。</li><li>D网络均使用LeakyRelu作为激活函数。</li></ol><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/256.jpg" alt="DCGAN结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/257.jpg" alt="CelebFaces一些数据的展示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/258.jpg" alt="产生网络和判别网络的Loss变化情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/259.jpg" alt="真假数据对比图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/260.jpg" alt="DCGAN在LSUN上生成的卧室图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/261.jpg" alt="GAN和DCGAN在MNIST上的生成效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/262.jpg" alt="生成向量包含的数学信息" /></p><h3 id="lsgan">LSGAN</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/263.jpg" alt="" /><figcaption>不同Loss差异图示</figcaption></figure><h3 id="wgan">WGAN</h3><h3 id="pg-gan">PG-GAN</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/265.jpg" alt="PG-GAN思想" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/266.jpg" alt="PG-GAN中从1616到3232的转换过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/267.jpg" alt="PG-GAN产生的高清图片" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/268.jpg" alt="各种GAN方法效果对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/269.jpg" alt="一些扩展的GAN可以实现风格转换效果" /></p><h2 id="第12章-神经网络可视化">第12章 神经网络可视化</h2><h3 id="卷积核">卷积核</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/270.jpg" alt="ConvNetJS在Cifar10上训练得到的参数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/271.jpg" alt="几种常见网络结构的第一层卷积" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/272.jpg" alt="特征层表征" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/273.jpg" alt="卷积神经网络特征层可视化工具" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/274.jpg" alt="不同图片在conv5151上的激活情况，每个特征层都是13*13个像素" /></p><p>通过重构观测</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/275.jpg" alt="“逆”卷积神经网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/276.jpg" alt="反向池化" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/278.jpg" alt="Layer3左上角第一张图的重构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/279.jpg" alt="完全训练的AlexNet在1～5个卷积层中选取被激活最强的9个通道复原后的图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/280.jpg" alt="对图12-4a进行重构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/281.jpg" alt="5个特征层经过不同迭代次数的重构效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/282.jpg" alt="末端CNN特征层的激活情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/283.jpg" alt="遮挡不同区域对图片分类的影响" /></p><p>特征层的作用</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/284.jpg" alt="" /><figcaption>利用CNN做特征提取可实现图像搜索功能</figcaption></figure><p>图片风格化</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/285.jpg" alt="图片风格化效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/290.jpg" alt="CNN在不同层上风格和内容重构的表现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/291.jpg" alt="示例中的风格图片和内容图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/292.jpg" alt="输入的内容图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/293.jpg" alt="风格化后的图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/294.jpg" alt="风格和内容权重的比例对生成图片效果的影响" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/295.jpg" alt="通过大量图片训练得到“风格网络”，从而对输入图片进行快速预测的方法" /></p><h2 id="图像识别算法的部署模式">图像识别算法的部署模式</h2><h3 id="图像算法部署模式介绍">图像算法部署模式介绍</h3><p>基于公共云云计算的计算机集群</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/296.jpg" alt="阿里巴巴云计算公司提供的人脸识别服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/297.jpg" alt="百度云计算公司提供的图像审核服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/298.jpg" alt="腾讯云计算公司提供的图像文字识别OCR服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/299.jpg" alt="AWS云计算公司提供的图像识别服务" /></p><p>基于私有云云计算的计算机集群</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/300.jpg" alt="图像识别算法基于云计算架构的系统架构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/301.jpg" alt="图像识别算法基于私有云容器的架构" /></p><p>X86架构单机+备份模式</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/302.jpg" alt="算法文件封装" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/303.jpg" alt="图像识别算法基于普通X86服务器的部署架构" /></p><h3 id="实际应用场景和部署模式的匹配">实际应用场景和部署模式的匹配</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/304.jpg" alt="百度云、阿里云、腾讯云人脸属性识别公有云服务测试响应速度表" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/305.jpg" alt="百度云计算公司在其公有云上提供的图像相关服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/306.jpg" alt="阿里云计算公司在其公有云上提供的图像相关服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/307.jpg" alt="腾讯云计算公司在其公有云上提供的图像相关服务" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/27/9787111630036/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《深度学习与图像识别：原理与实践》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：深度学习与图像识别：原理与实践&lt;br /&gt;
作者：魏溪含，涂铭，张修鹏&lt;br /&gt;
出版社：机械工业出版社&lt;br /&gt;
出版时间：2019-06&lt;br /&gt;
ISBN：9787111630036&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>《深度学习之图像识别：核心技术与案例实战》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/26/9787111624721/"/>
    <id>https://2020.iosdevlog.com/2020/02/26/9787111624721/</id>
    <published>2020-02-26T11:41:38.000Z</published>
    <updated>2020-03-02T12:22:48.947Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/1.jpg" alt="" /><figcaption>《深度学习之图像识别：核心技术与案例实战》</figcaption></figure><p>书名：深度学习之图像识别：核心技术与案例实战<br />作者：言有三<br />出版社：机械工业出版社<br />出版时间：2019-04<br />ISBN：9787111624721</p><a id="more"></a><h2 id="本书读者对象">本书读者对象</h2><ul><li>图像处理技术人员</li><li>深度学习技术人员</li><li>深度学习技术爱好者</li><li>深度学习技术研究人员</li><li>相关院校的学生和老师</li><li>相关培训机构的学生和老师</li></ul><h2 id="介绍">介绍</h2><p>配书资源：<a href="http://www.hzcourse.com/web/refbook/detail/8278/226" target="_blank" rel="noopener" class="uri">http://www.hzcourse.com/web/refbook/detail/8278/226</a></p><p>机器学习、深度学习、人工智能，这些关键词在最近几年“声名鹊起”。以深度学习为代表的无监督机器学习技术在图像处理、语音识别和自然语言处理等领域里频频取得新的突破。但深度学习其实并不是一门全新的学科，其历史可以追溯到20世纪40年代。</p><p>深度学习背后的核心技术包括神经网络的结构设计和最优化方法等，其理论体系虽然有一定进展但是尚不完备。可以说，当前的主流深度学习技术是一门应用性极强的工程技术，这种尚不完备的理论加上具有较高门槛的应用工程特点，对于初学者来说具有一定的困难。如何系统性地了解理论知识，又能够紧随理论进行全面的实践，成为一名合格的图像处理领域的深度学习算法工程师，这是本书所要解决的问题。</p><p>本书内容由浅入深，讲解图文并茂，紧随工业界和学术界的最新发展，理论和实践紧密结合，给出了大量的图表与案例分析。本书抛开了过多的数学理论，完整地剖析了深度学习在图像处理领域中各个维度的重要技术，而不是只停留于理论的阐述和简单的结果展示，更是从夯实理论到完成实战一气呵成。相信读者跟随着本书进行学习，将会对深度学习领域的图像处理技术和其在实际开发中的应用有更深的理解。</p><h2 id="本书特色">本书特色</h2><ol type="1"><li>内容全面，紧跟最新技术<br />发展本书内容涵盖了深度学习的理论知识、数据获取与增强，以及深度学习在图像分类、分割和检测这三大基础研究领域中的发展、数据与模型的可视化、优化目标、模型压缩与部署等相关知识，基本上囊括了深度学习在图像开发中所必须要掌握的大部分基础知识。</li><li>深度与广度兼具<br />本书在讲解每个知识点时力求详尽，而且紧密结合了学术界与工业界相关技术的最新发展。这样的安排既注重知识的广度，也兼具知识的深度，可以为图像处理领域中的从业者提供系统性的学习指导。</li><li>理论与实践案例紧密结合<br />本书不仅对理论知识进行了阐述，而且还给出了大量的实践内容，以帮助读者提高实际的动手能力。除了第 1、2章 主要介绍了深度学习的基础理论外，后续章节则大多采用了先系统介绍该章涉及知识的发展现状，然后有针对性地设计了一到两个实践案例带领读者学习，有较好的学习效果。</li><li>参考了不同层次学习者的意见<br />本书若干内容的简化版本已在笔者运营的公众号平台上接受了不同层次读者的反馈，力求知识的完备性和准确性；另外，本书有多位编写者参与，他们或理论见长，或善于动手，让本书从不同层面得到了广泛的意见，可以满足不同人群的学习需求。</li></ol><h2 id="本书内容">本书内容</h2><p>第1章 神经网络基础</p><p>首先介绍了神经网络的生物基础与数学模型，然后介绍了卷积神经网络的基础知识，这也是当前深度学习模型的基础。</p><p>第2章 深度学习优化基础</p><p>首先介绍了深度学习主流开源框架，如Caffe、TensorFlow、Pytorch和Theano等，并对其特点与性能做了对比；然后介绍了网络优化参数，包括激活函数、正则化方法和归一化方法等。本章旨在让大家对深度卷积神经网络有一个较为全面的认识，给后续章节的学习打好基础。</p><p>第3章 深度学习中的数据</p><p>首先介绍了深度学习发展过程中的几个数据集，给读者展示了数据集对深度学习的重要性；然后介绍了几大重要发展方向中的数据集；接着讲述了数据增强的方法；最后讲述了数据的收集、整理及标注等相关问题。</p><p>第4章 图像分类</p><p>首先介绍了图像分类的基础、基于深度学习的图像分类研究方法及发展现状，以及图像分类任务中的挑战；然后以一个移动端的基准模型为例，展示了图像分类任务的实践流程；最后介绍了一个细粒度级别的图像分类任务，以一个较高的基准模型，展示了较难的图像分类任务训练参数的调试技巧。</p><p>第5章 图像分割</p><p>首先介绍了从阈值法到活动轮廓模型的传统图像分割方法；然后介绍了基于深度学习的图像分割方法的基本原理与核心技术；接着讲述了一个移动端的实时图像分割任务，该任务以MobileNet为基准模型，展示了图像硬分割任务实践的完整流程；最后介绍了一个更加复杂的肖像换背景的任务，展示了图像软分割任务的基本流程和应用场景。</p><p>第6章 目标检测</p><p>首先介绍了目标检测的基础和基本流程，并讲述了一个经典的V-J目标检测框架；然后介绍了基于深度学习的目标检测任务的研究方法与发展现状，并分析了目标检测中的核心技术；最后给出了一个目标检测任务实例，通过分析faster rcnn的源代码，使用该框架自带的VGG CNN 1024网络完成训练和测试，并总结目标检测中的难点。</p><p>第7章 数据与模型可视化</p><p>首先对包括低维与高维数据的可视化做了简单介绍；然后对深度学习中的模型可视化做了详细介绍，包括模型的结构和权重可视化；最后介绍了一个基于Tensorflow和Tensorboard的完整案例。</p><p>第8章 模型压缩</p><p>首先详细介绍了模型压缩的方法，然后以一个典型的模型压缩实战案例来阐述项目中的模型压缩上线。</p><p>第9章 损失函数</p><p>首先介绍了分类任务的损失函数；然后介绍了回归任务的损失函数；最后介绍了这些损失函数在几大经典图像任务中的使用。</p><p>第10章 模型部署与上线</p><p>依托微信小程序平台从3个方面介绍了模型部署的问题。首先介绍了微信小程序的前端开发，然后介绍了微信小程序的服务端开发，最后介绍了Caffe的环境配置。</p><h2 id="第1章-神经网络基础">第1章 神经网络基础</h2><p>神经元</p><p>神经元人工神经网络（Artificial Neural Network）简称神经网络（Neural Network,NN），是人类模拟生物神经网络的结构和功能提出的数学模型，广泛应用于计算机视觉等领域。</p><p>感知机</p><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/2.jpg" alt="" /><figcaption>感知机（Perceptron）</figcaption></figure><p>假设我们有一个 <span class="math inline">\(n\)</span> 维输入的单层感知机，<span class="math inline">\(x_{1}\)</span> 至 <span class="math inline">\(x_{n}\)</span> 为 <span class="math inline">\(n\)</span> 维输入向量的各个分量，<span class="math inline">\(w_{1}\)</span> 至 <span class="math inline">\(w_{n}\)</span> 为各个输入分量连接到感知机的权量（或称权值）, <span class="math inline">\(θ\)</span> 为阈值，<span class="math inline">\(f\)</span> 为激活函数（又称为激励函数或传递函数）,<span class="math inline">\(y\)</span> 为标量输出。理想的激活函数 <span class="math inline">\(f(·)\)</span> 通常为阶跃函数或者 <span class="math inline">\(sigmoid\)</span> 函数。感知机的输出是输入向量 <span class="math inline">\(X\)</span> 与权重向量 <span class="math inline">\(W\)</span> 求得内积后，经激活函数 <span class="math inline">\(f\)</span> 所得到的标量：</p><p><span class="math display">\[y=f\left(\sum_{i=1}^{n} w_{i} x_{i}-\theta\right)\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/3.jpg" alt="" /><figcaption>公式</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">n = <span class="number">0</span>  <span class="comment"># 迭代次数</span></span><br><span class="line">lr = <span class="number">0.10</span>  <span class="comment"># 学习速率</span></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 标签</span></span><br><span class="line">Y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">-1</span>])</span><br><span class="line"><span class="comment"># 权重初始化，取值范围-1到1</span></span><br><span class="line">W = (np.random.random(X.shape[<span class="number">1</span>])<span class="number">-0.5</span>)*<span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_show</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 正样本</span></span><br><span class="line">    all_x = X[:, <span class="number">2</span>]</span><br><span class="line">    all_y = X[:, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 负样本</span></span><br><span class="line">    all_negative_x = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    all_negative_y = [<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算分界线斜率与截距</span></span><br><span class="line">    k = -W[<span class="number">2</span>] / W[<span class="number">3</span>]</span><br><span class="line">    b = -(W[<span class="number">0</span>] + W[<span class="number">1</span>]) / W[<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 生成x刻度</span></span><br><span class="line">    xdata = np.linspace(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(xdata, xdata*k+b, <span class="string">'r'</span>)</span><br><span class="line">    plt.plot(all_x, all_y, <span class="string">'bo'</span>)</span><br><span class="line">    plt.plot(all_negative_x, all_negative_y, <span class="string">'yo'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新权值函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_update</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 定义所有全局变量</span></span><br><span class="line">    <span class="keyword">global</span> X, Y, W, lr, n</span><br><span class="line">    n += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算符号函数输出</span></span><br><span class="line">    new_output = np.sign(np.dot(X, W.T))</span><br><span class="line">    <span class="comment"># 更新权重</span></span><br><span class="line">    new_W = W + lr*((Y-new_output.T).dot(X))/int(X.shape[<span class="number">0</span>])</span><br><span class="line">    W = new_W</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        get_update()</span><br><span class="line">        new_output = np.sign(np.dot(X, W.T))</span><br><span class="line">        <span class="keyword">if</span> (new_output == Y.T).all():</span><br><span class="line">            print(<span class="string">"迭代次数："</span>, n)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    get_show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/4.jpg" alt="" /><figcaption>感知机模型分割结果示意图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/5.jpg" alt="" /><figcaption>单隐层前馈网络示意图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/6.jpg" alt="" /><figcaption>多层前馈网络示意图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/7.png" alt="" /><figcaption>BP算法公式</figcaption></figure><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/8.png" alt="BP算法公式" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/9.png" alt="9" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/10.png" alt="10" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/11.jpg" alt="11" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/12.jpg" alt="12" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/13.jpg" alt="13" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/14.png" alt="14" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/15.jpg" alt="15" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/16.jpg" alt="16" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/17.jpg" alt="17" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/18.png" alt="18" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/19.png" alt="19" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/20.jpg" alt="20" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/21.png" alt="21" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/22.jpg" alt="22" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/23.jpg" alt="23" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/24.jpg" alt="24" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/25.jpg" alt="25" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/26.jpg" alt="26" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/27.jpg" alt="27" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/28.jpg" alt="28" /></p><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/29.jpg" alt="" /><figcaption>感知机模型解决NOR问题结果示意图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/30.jpg" alt="" /><figcaption>不同风格的手写字符示意图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/31.jpg" alt="" /><figcaption>31</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/32.jpg" alt="" /><figcaption>32</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/33.jpg" alt="" /><figcaption>33</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/34.jpg" alt="" /><figcaption>二维卷积的实例</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/35.jpg" alt="" /><figcaption>感受野示例图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/36.jpg" alt="" /><figcaption>最大池化操作示意图</figcaption></figure><h2 id="第2章-深度学习优化基础">第2章 深度学习优化基础</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/37.jpg" alt="深度学习主流框架参数对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/38.jpg" alt="Sigmoid" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/39.jpg" alt="tanh" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/40.jpg" alt="tanh函数示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/41.jpg" alt="ReLU" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/42.jpg" alt="ReLU函数示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/43.jpg" alt="Leaky ReLU" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/44.jpg" alt="Leaky ReLU函数示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/45.jpg" alt="指数线性单元ELU" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/46.jpg" alt="SELU" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/47.jpg" alt="Softmax" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/48.jpg" alt="48" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/49.png" alt="49" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/50.png" alt="50" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/51.jpg" alt="51" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/52.jpg" alt="基于动量项的SGD示意图" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/53.jpg" alt="Nesterov加速梯度下降法（Nesterov Accelerated Gradient, NAG）" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/54.jpg" alt="NAG" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/55.jpg" alt="Adagrad" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/56.jpg" alt="Adagrad" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/57.jpg" alt="57" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/58.jpg" alt="58" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/59.jpg" alt="Adam" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/60.jpg" alt="60" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/61.jpg" alt="61" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/62.jpg" alt="62" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/63.jpg" alt="63" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/64.jpg" alt="64" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/65.jpg" alt="65" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/66.jpg" alt="66" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/67.png" alt="67" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/68.png" alt="68" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/69.png" alt="69" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/70.jpg" alt="70" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/71.jpg" alt="71" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/72.jpg" alt="72" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/73.jpg" alt="73" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/74.jpg" alt="74" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/75.jpg" alt="75" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/76.jpg" alt="76" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/77.jpg" alt="77" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/78.jpg" alt="78" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/79.jpg" alt="79" /></p><h2 id="第3章-深度学习中的数据">第3章 深度学习中的数据</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/80.jpg" alt="人脸检测结果" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/81.jpg" alt="人脸检测提取出的脸部和关键点信息" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/82.png" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/83.jpg" alt="原图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/84.jpg" alt="数据增强示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/85.jpg" alt="水平翻转和垂直翻转图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/86.jpg" alt="随机旋转图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/87.jpg" alt="随机裁剪图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/88.jpg" alt="竖直方向与水平方向缩放变形图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/89.jpg" alt="原图与添加随机高斯噪声图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/90.jpg" alt="Coarse Dropout添加噪声图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/91.jpg" alt="随机擦除法添加噪声图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/92.jpg" alt="不同程度的高斯模糊图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/93.jpg" alt="颜色扰动图" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/94.jpg" alt="SMOTE方法" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/95.jpg" alt="mixup方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/96.jpg" alt="生成对抗网络GAN" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/97.jpg" alt="DCGAN生成的嘟嘴嘴唇样本图" /></p><h2 id="第4章-图像分类">第4章 图像分类</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/98.jpg" alt="LeNet5网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/99.jpg" alt="单标签分类" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/100.jpg" alt="100" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/101.jpg" alt="101" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/102.jpg" alt="多标签分类 平均分类准确度" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/103.jpg" alt="汉明距离" /></p><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/104.jpg" alt="原图（左）, laplacian of gaussian边缘检测结果（右）" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/105.jpg" alt="不同表情的图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/106.jpg" alt="百度AI小程序识别结果" /></p><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/107.jpg" alt="" /><figcaption>表情样本</figcaption></figure><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/108.jpg" alt="MobileNet基本组成单元Depthwise Separable Convolutions" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/109.jpg" alt="训练损失" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/110.jpg" alt="训练精度" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/111.jpg" alt="双线性网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/112.jpg" alt="共享部分权重和共享全部权重" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/113.jpg" alt="双线性部分网络示意图" /></p><figure><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/114.jpg" alt="" /><figcaption>Signed_sqrt_layer是进行带符号的归一化操作</figcaption></figure><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/115.jpg" alt="准确率曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/116.jpg" alt="损失曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/117.jpg" alt="损失曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/118.jpg" alt="准确率曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/119.jpg" alt="损失曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/120.jpg" alt="精度曲线" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/121.jpg" alt="测试不同batch size的对精度的影响" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/122.jpg" alt="测试不同分辨率的影响" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/123.jpg" alt="测试不同正则化因子的影响" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/124.jpg" alt="损失曲线" /></p><h2 id="第5章-图像分割">第5章 图像分割</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/125.png" alt="125" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/126.png" alt="126" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/127.png" alt="127" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/128.png" alt="128" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/129.jpg" alt="129" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/130.jpg" alt="130" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/131.jpg" alt="131" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/132.jpg" alt="132" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/133.jpg" alt="133" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/134.jpg" alt="134" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/135.jpg" alt="135" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/136.jpg" alt="136" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/137.jpg" alt="137" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/138.jpg" alt="138" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/139.jpg" alt="139" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/140.jpg" alt="140" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/141.jpg" alt="141" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/142.jpg" alt="142" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/143.jpg" alt="143" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/144.jpg" alt="144" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/145.jpg" alt="145" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/146.jpg" alt="146" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/147.jpg" alt="147" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/148.jpg" alt="148" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/149.jpg" alt="149" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/150.jpg" alt="150" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/151.jpg" alt="151" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/152.jpg" alt="152" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/153.jpg" alt="153" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/154.jpg" alt="154" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/155.jpg" alt="155" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/156.jpg" alt="156" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/157.jpg" alt="157" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/158.jpg" alt="158" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/159.jpg" alt="159" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/160.jpg" alt="160" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/161.jpg" alt="161" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/162.jpg" alt="162" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/163.jpg" alt="163" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/164.jpg" alt="164" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/165.jpg" alt="165" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/166.jpg" alt="166" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/167.jpg" alt="167" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/168.jpg" alt="168" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/169.jpg" alt="169" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/170.jpg" alt="170" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/171.jpg" alt="171" /></p><h2 id="第6章-目标检测">第6章 目标检测</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/172.jpg" alt="172" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/173.jpg" alt="173" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/174.jpg" alt="174" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/175.jpg" alt="175" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/176.jpg" alt="176" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/177.jpg" alt="177" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/178.jpg" alt="178" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/179.jpg" alt="179" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/180.jpg" alt="180" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/181.jpg" alt="181" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/182.jpg" alt="182" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/183.jpg" alt="183" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/184.jpg" alt="184" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/185.jpg" alt="185" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/186.jpg" alt="186" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/187.jpg" alt="187" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/188.jpg" alt="188" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/189.jpg" alt="189" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/190.jpg" alt="190" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/191.jpg" alt="191" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/192.jpg" alt="192" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/193.jpg" alt="193" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/194.jpg" alt="194" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/195.jpg" alt="195" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/196.jpg" alt="196" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/197.jpg" alt="197" /></p><h2 id="第7章-数据与模型可视化">第7章 数据与模型可视化</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/198.jpg" alt="198" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/199.jpg" alt="199" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/200.jpg" alt="200" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/201.jpg" alt="201" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/202.jpg" alt="202" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/203.jpg" alt="203" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/204.jpg" alt="204" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/205.jpg" alt="205" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/206.jpg" alt="206" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/207.jpg" alt="207" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/208.jpg" alt="208" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/209.jpg" alt="209" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/210.jpg" alt="210" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/211.jpg" alt="211" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/212.jpg" alt="212" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/213.jpg" alt="213" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/214.jpg" alt="214" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/215.jpg" alt="215" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/216.jpg" alt="216" /></p><h2 id="第8章-模型压缩">第8章 模型压缩</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/217.jpg" alt="217" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/218.jpg" alt="218" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/219.jpg" alt="219" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/220.png" alt="220" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/221.jpg" alt="221" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/222.jpg" alt="222" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/223.png" alt="223" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/224.jpg" alt="224" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/225.jpg" alt="225" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/226.jpg" alt="226" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/227.jpg" alt="227" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/228.jpg" alt="228" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/229.jpg" alt="229" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/230.jpg" alt="230" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/231.jpg" alt="231" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/232.jpg" alt="232" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/233.jpg" alt="233" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/234.jpg" alt="234" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/235.jpg" alt="235" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/236.jpg" alt="236" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/237.jpg" alt="237" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/238.jpg" alt="238" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/239.jpg" alt="239" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/240.jpg" alt="240" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/241.jpg" alt="241" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/242.jpg" alt="242" /></p><h2 id="第9章-损失函数">第9章 损失函数</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/243.jpg" alt="243" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/244.jpg" alt="244" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/245.jpg" alt="245" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/246.jpg" alt="246" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/247.jpg" alt="247" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/248.jpg" alt="248" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/249.jpg" alt="249" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/250.jpg" alt="250" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/251.jpg" alt="251" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/252.jpg" alt="252" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/253.jpg" alt="253" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/254.jpg" alt="254" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/255.png" alt="255" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/256.png" alt="256" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/257.jpg" alt="257" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/258.jpg" alt="258" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/259.jpg" alt="259" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/260.jpg" alt="260" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/261.jpg" alt="261" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/262.jpg" alt="262" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/263.jpg" alt="263" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/264.jpg" alt="264" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/265.jpg" alt="265" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/266.jpg" alt="266" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/267.jpg" alt="267" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/268.jpg" alt="268" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/269.jpg" alt="269" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/270.jpg" alt="270" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/271.jpg" alt="271" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/272.jpg" alt="272" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/273.jpg" alt="273" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/274.png" alt="274" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/275.jpg" alt="275" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/276.jpg" alt="276" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/277.jpg" alt="277" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/278.jpg" alt="278" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/279.jpg" alt="279" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/280.jpg" alt="280" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/281.jpg" alt="281" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/282.jpg" alt="282" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/283.jpg" alt="283" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/284.jpg" alt="284" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/285.jpg" alt="285" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/286.jpg" alt="286" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/287.jpg" alt="287" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/288.jpg" alt="288" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/289.png" alt="289" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/290.png" alt="290" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/291.jpg" alt="291" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/292.jpg" alt="292" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/293.jpg" alt="293" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/294.jpg" alt="294" /></p><h2 id="第10章-模型部署与上线">第10章 模型部署与上线</h2><p><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/295.jpg" alt="295" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/296.jpg" alt="296" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/297.jpg" alt="297" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/298.jpg" alt="298" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/299.jpg" alt="299" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/300.jpg" alt="300" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/301.jpg" alt="301" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/302.jpg" alt="302" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/303.jpg" alt="303" /><br /><img src="https://2020.iosdevlog.com/2020/02/26/9787111624721/304.jpg" alt="304" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/26/9787111624721/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《深度学习之图像识别：核心技术与案例实战》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：深度学习之图像识别：核心技术与案例实战&lt;br /&gt;
作者：言有三&lt;br /&gt;
出版社：机械工业出版社&lt;br /&gt;
出版时间：2019-04&lt;br /&gt;
ISBN：9787111624721&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>AI 及 NLP 基础</title>
    <link href="https://2020.iosdevlog.com/2020/02/25/nlp/"/>
    <id>https://2020.iosdevlog.com/2020/02/25/nlp/</id>
    <published>2020-02-25T10:30:44.000Z</published>
    <updated>2020-02-25T15:22:05.446Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/0.png" alt="" /><figcaption>AI</figcaption></figure><a id="more"></a><h3 id="ai-概览宣传片外的人工智能">AI 概览：宣传片外的人工智能</h3><p>内容概述</p><ul><li><p>人工智能是什么</p></li><li><p>人工智能的发展历史</p></li><li><p>人工智能的现状和展望</p></li></ul><p>人工智能之父？</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000105.jpg" alt="" /><figcaption>Fallece John McCathy</figcaption></figure><p>Fallece John McCathy</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000178.jpg" alt="" /><figcaption>达特茅斯参会者合影</figcaption></figure><p>达特茅斯参会者合影</p><p>人工智能 Artificial Intelligence</p><p>人工智能的复兴</p><ul><li><p>人工智能的复兴 ≈ 神经网络的复兴</p></li><li><p>神经网络的概念很早就已经出现，但是在 2000 年左右，由于 SVM 的出现，</p></li></ul><p>使得神经网络没落了一段时间。</p><ul><li>神经网络的再次兴起，主要源于 2013 年深度学习的出现。</li></ul><p>人工智能的本质是什么</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000102.jpg" alt="" /><figcaption>媒体眼中的人工智能</figcaption></figure><p>媒体眼中的人工智能</p><p>我们要讲到的人工智能</p><ul><li>预测性建模</li><li>优化问题</li></ul><p>预测性建模</p><ul><li><p>主要目的：在给定数据的基础上提升预测模型的准确率</p></li><li><p>绝大多数人工智能的应用在很大程度上均可以认为是预测性建模的范畴</p></li></ul><p>预测性建模 VS 统计学</p><ul><li><p>预测性建模：只关注模型的预测准确性</p></li><li><p>统计学模型：主要关注模型的可解释性</p></li></ul><p>优化问题</p><ul><li><p>优化问题是指如何根据已有的数学模型求出最优解的过程</p></li><li><p>近年来取得主要进展的优化问题主要在于增强学习领域</p></li></ul><p>增强学习</p><ul><li><p>解决的问题：如何在动态环境下做出正确的决定</p></li><li><p>主要应用：游戏 AI</p></li><li><p>其他应用：内容推荐、搜索排名、智能化定价</p></li></ul><h3 id="人工智能的另外一种分类">人工智能的另外一种分类</h3><ul><li><p>结构化数据</p></li><li><p>文本数据</p></li><li><p>图像、视频数据</p></li><li><p>语音数据</p></li></ul><p>被媒体夸大的人工智能</p><p>人工智能的真实发展</p><p>最小二乘法和牛顿法</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000100.jpg" alt="" /><figcaption>牛顿</figcaption></figure><p>牛顿</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000065.jpg" alt="" /><figcaption>高斯</figcaption></figure><p>高斯</p><h3 id="人工智能常常以不同面目出现">人工智能常常以不同面目出现</h3><p>机器智能</p><p>统计学</p><p>……</p><p>决策智能</p><p>运筹学</p><p>人工智能</p><p>深度学习</p><p>数据挖掘</p><p>模式识别</p><p>神经网络</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/0.png" alt="" /><figcaption>人工智能</figcaption></figure><h3 id="人工智能的现状">人工智能的现状</h3><p>学术</p><table><thead><tr class="header"><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>很多领域的准确性可以替代人类</td><td>可以替代人类准确性的只占很少部分</td></tr><tr class="even"><td>一些领域可以做到击败人类最好的决策者</td><td>这没有实际应用；并且要耗费很多的资源</td></tr><tr class="odd"><td>发展极为迅速</td><td>很多文章复现性很差</td></tr><tr class="even"><td>覆盖领域越来越多</td><td>很多领域都是哗众取宠</td></tr><tr class="odd"><td>所需要标注样本越来越少</td><td>标注仍然劳民伤财</td></tr><tr class="even"><td>开源代码越来越多</td><td>大部分人还是只会调包</td></tr><tr class="odd"><td>……</td><td>……</td></tr></tbody></table><p>业界</p><table><thead><tr class="header"><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>大量的公司涌现</td><td>实干企业较少</td></tr><tr class="even"><td>大量的热点出现</td><td>大热之后大扑街</td></tr><tr class="odd"><td>大量的新概念出现</td><td>大部分难以实现落地</td></tr><tr class="even"><td>大量的公司花大价钱投入研发</td><td>形式主义，研究难以实现落地</td></tr><tr class="odd"><td>大量的高薪就业机会</td><td>一旦生意失败，只能卷铺盖走人</td></tr><tr class="even"><td>大量的媒体创造热度</td><td>过于夸张的宣传，引起反感</td></tr><tr class="odd"><td>……</td><td>……</td></tr></tbody></table><h3 id="那我们该怎么做">那我们该怎么做</h3><ul><li>钻<ul><li>将一项任务做到极致</li><li>不要到处转换方向</li></ul></li><li>快<ul><li>快速学习新的领域</li><li>紧追热点，会读英文资料</li></ul></li><li>深<ul><li>夯实基础</li><li>数学和编程</li></ul></li><li>广<ul><li>广泛涉猎</li><li>抓住本质</li></ul></li></ul><h2 id="ai-项目流程">AI 项目流程</h2><p>内容概述</p><ul><li><p>如何判断是否要做一个 AI 项目</p></li><li><p>如何做前期的调研</p></li><li><p>如何做开发的计划</p></li><li><p>如何对结果进行验证</p></li><li><p>如何进行部署</p></li></ul><p>如何判断是否要做一个 AI 项目</p><ol type="1"><li><p>技术的成熟度</p></li><li><p>需求的可控程度</p></li><li><p>项目投入的周期和成本</p></li><li><p>项目最终的交付流程</p></li></ol><p>技术的成熟度</p><ol type="1"><li><p>底线：人工是否可以解决这个问题</p></li><li><p>Paper 中技术的复现性 VS 领先厂商当前的水平</p></li><li><p>初期通过小 Demo 测试准确率</p></li><li><p>团队的时间和能力</p></li><li><p>项目部署问题</p></li><li><p>保守估计项目的交付时间</p></li></ol><p>需求的可控程度</p><ul><li><p>销售导向 OR 技术导向</p></li><li><p>客户管理能力</p></li><li><p>团队整体的需求控制能力</p></li></ul><p>项目投入的周期和成本</p><ul><li><p>大多数时候，人们会低估项目投入的周期和成本。</p></li><li><p>项目周期和成本不可控的原因主要来源于需求的变更。</p></li><li><p>其他可能出现的问题：</p></li><li><p>标注的不可控性</p></li><li><p>模型效果调优所需要的时间</p></li><li><p>推断速度提升所需要的时间</p></li><li><p>环境部署所需要的时间</p></li><li><p>运行模型所需要的算力成本</p></li></ul><p>项目最终的交付流程</p><ul><li><p>明确项目目标</p></li><li><p>不要忽略交付流程中的额外投入</p></li><li><p>组织的项目交付的流水化能力：</p></li><li><p>是否有明确的交付流程</p></li><li><p>人员职责安排是否清晰</p></li><li><p>是否严格遵循时间规范</p></li><li><p>项目是否有烂尾的风险</p></li></ul><p>项目的一般流程</p><ul><li><p>前期调研和方案确定</p></li><li><p>数据标注和开发</p></li><li><p>效果调优（包括准确性和速度）</p></li><li><p>代码部署</p></li></ul><p>前期调研和方案确定</p><p>容易被忽略的问题：</p><ul><li><p>很多时候，学术结果难以复现。</p></li><li><p>很多方法在某些数据上可能会非常好用，但是在另一些数据上则会失效。</p></li><li><p>很多方法的成功取决于一些细节，而这些细节只有真正做过的人才会知道。</p></li><li><p>很多时候人们会过于关注方法的效果，而忽略了整体的运行实效。</p></li><li><p>在绝大多数的时候，人们都会低估整个项目的难度。</p></li></ul><p>数据标注</p><ul><li><p>前期一定要制定充分的标注规则</p></li><li><p>数据的采集一定要具有代表性</p></li><li><p>非常不建议采用自动标注的方式</p></li><li><p>先训练一个初步模型，然后只让相关人员进行校对，可以保证标注效率并减少标注成本</p></li></ul><p>算法开发</p><ul><li><p>千万不要采用规则的方式进行开发</p></li><li><p>初期就要引导客户使用和购买能够支持深度学习框架的硬件</p></li><li><p>算法开发的过程中，一定要有量化的指标并记录下来</p></li><li><p>开发的过程中，多分解问题</p></li><li><p>前端对接的时候一定要去引导何为“智能”</p></li></ul><p>效果优化</p><ul><li><p>初期要充分考虑到效果优化所需要的时间和成本</p></li><li><p>客户并不知道通过什么标准来评估一个系统的好坏</p></li><li><p>一定要从数据的角度出发进行优化</p></li><li><p>学会止损</p></li><li><p>出了准确性的优化，还要注重代码运算效率的优化</p></li><li><p>算法开发和效果优化常常是需要反复进行的工作</p></li></ul><p>算法部署</p><ul><li><p>如果客户的系统比较奇怪，或者难以满足一些要求，要提前让客户知晓这些风险。</p></li><li><p>即使再小的项目，我也强烈建议用微服务架构进行部署。</p></li><li><p>不要把算法部署在本地，尽量采用云端部署。</p></li></ul><h2 id="nlp-基本任务及研究方向">NLP 基本任务及研究方向</h2><p>内容概述</p><ul><li><p>基础性研究</p></li><li><p>专属 NLP 领域的研究</p></li><li><p>交叉领域的研究</p></li></ul><p>基础性研究：网络架构</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000101.png" alt="" /><figcaption>网络架构</figcaption></figure><p>基础性研究：优化理论</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000131.png" alt="" /><figcaption>优化理论</figcaption></figure><p>基础性研究：对抗训练</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000123.png" alt="" /><figcaption>对抗训练</figcaption></figure><p>基础性研究：数据增强</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000045.png" alt="" /><figcaption>数据增强</figcaption></figure><p>基础性研究：半监督学习</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000016.png" alt="" /><figcaption>半监督学习</figcaption></figure><p>基础性研究：域迁移</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000002.png" alt="" /><figcaption>域迁移</figcaption></figure><p>基础性研究：Meta Learning</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000078.png" alt="" /><figcaption>Meta Learning</figcaption></figure><p>基础性研究：Auto ML</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000112.png" alt="" /><figcaption>Auto ML</figcaption></figure><p>基础性研究：多任务学习</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000093.png" alt="" /><figcaption>多任务学习</figcaption></figure><p>基础性研究：集成学习</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000080.png" alt="" /><figcaption>集成学习</figcaption></figure><p>基础性研究：图网络</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000037.png" alt="" /><figcaption>图网络</figcaption></figure><p>基础性研究：知识图谱</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000176.jpg" alt="" /><figcaption>知识图谱</figcaption></figure><p>图片来源： <a href="https://lod-cloud.net" target="_blank" rel="noopener" class="uri">https://lod-cloud.net</a></p><p>基础性研究：多模态学习</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/1.png" alt="" /><figcaption>多模态学习</figcaption></figure><p>基础性研究：机器推理</p><p><img src="https://2020.iosdevlog.com/2020/02/25/nlp/1.png" alt="机器推理" /><br />000158</p><p>NLP 研究：预训练语言模型</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000050.png" alt="" /><figcaption>预训练语言模型</figcaption></figure><p>NLP 研究：文本分类</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000012.jpg" alt="" /><figcaption>文本分类</figcaption></figure><p>NLP 研究：序列标注</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000079.png" alt="" /><figcaption>序列标注</figcaption></figure><p>NLP 研究：关系提取</p><ul><li><p>Queen Elizabeth</p></li><li><p>Prince Charles</p></li><li><p>PER-PARENTS</p></li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/2.png" alt="" /><figcaption>关系提取</figcaption></figure><p>NLP 研究：Dependency Parsing</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000122.png" alt="" /><figcaption>Dependency Parsing</figcaption></figure><p>NLP 研究：Semantic Parsing</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000001.png" alt="" /><figcaption>Semantic Parsing</figcaption></figure><p>NLP 研究：Seq2Seq</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000117.png" alt="" /><figcaption>Seq2Seq</figcaption></figure><p>NLP 研究：文本生成</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000092.png" alt="" /><figcaption>文本生成</figcaption></figure><p>NLP 研究：文本推荐</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000159.png" alt="" /><figcaption>文本推荐</figcaption></figure><p>NLP 研究：翻译</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000064.png" alt="" /><figcaption>翻译</figcaption></figure><p>NLP 研究：指代消解</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000007.png" alt="" /><figcaption>指代消解</figcaption></figure><p>NLP 综合性研究</p><ul><li><p>智能对话机器人</p></li><li><p>文本校对</p></li><li><p>文本检索</p></li><li><p>开源情报系统</p></li><li><p>Smart BI</p></li></ul><h2 id="nlp-应用智能问答系统">NLP 应用：智能问答系统</h2><p>内容概述</p><ul><li><p>智能问答系统产品简介</p></li><li><p>如何构建智能问答产品</p></li><li><p>智能问答产品的一些挑战</p></li></ul><p>目的</p><ul><li><p>A Taste of Reality</p></li><li><p>很多系统是由多个组件组成的</p></li><li><p>很多系统是存在很多挑战的</p></li><li><p>很多系统落地是存在问题的</p></li><li><p><strong>但是，很多时候有些问题也是可以解决的…</strong></p></li></ul><p>一些智能问答产品</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000157.jpg" alt="" /><figcaption>Google Assistant</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000146.jpg" alt="" /><figcaption>amazon alexa</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000006.png" alt="" /><figcaption>Hey Cortana</figcaption></figure><p>如何构建一个智能问答系统</p><p>智能对话系统的挑战</p><ul><li><p>技术困难</p></li><li><p>投入巨大</p></li><li><p>落地困难</p></li></ul><p>如何把一个机器人问成弱智</p><ul><li><p>省略回复</p></li><li><p>知识推理</p></li><li><p>错别字</p></li><li><p>状态切换</p></li><li><p>延续话题</p></li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000130.jpg" alt="" /><figcaption>机器人问成弱智</figcaption></figure><p>对话机器人的实践</p><ul><li><p>我曾经生不如死地开发过一个对话机器人（类似于百度 UNIT ）</p></li><li><p>挑战：</p></li><li><p>技术复杂（次要）</p></li><li><p>客户关系（主要）</p></li></ul><p>总结</p><ul><li><p>目标分解</p></li><li><p>创新并非那么困难</p></li><li><p>综合考虑技术因素和人的因素</p></li></ul><h2 id="nlp-应用文本校对系统">NLP 应用：文本校对系统</h2><p>从 Grammarly 出发</p><p>理想很丰满，现实很骨感</p><ul><li><p>理论模型：Seq2Seq</p></li><li><p>实际模型：</p></li><li><p>？</p></li><li><p>？？</p></li><li><p>？？？</p></li></ul><p>为什么中文校对会比英文校对要难？</p><ul><li>本质：一旦错误，传统的模型会崩溃</li></ul><p>如何解决</p><ul><li><p>目标分解</p></li><li><p>逆向思维</p></li></ul><p>其他可以尝试的</p><ul><li><p>语法错误校对</p></li><li><p>常识校对</p></li></ul><h2 id="nlp-的学习方法如何在-ai-爆炸时代快速上手学习">NLP 的学习方法：如何在 AI 爆炸时代快速上手学习？</h2><p>AI 时代的学习</p><ul><li><p>为什么要学习</p></li><li><p>学习的误区</p></li><li><p>如何有效地进行学习</p></li></ul><p>为什么要学习</p><ul><li><p>迁移学习的出现使得技术不再是数据标注的衬托</p></li><li><p>AI 一直在迅速发展</p></li><li><p>AI 本身还不成熟，有大量的创新空间</p></li></ul><p>学习上的误区</p><ul><li><p>“大佬（同事）带带我”；</p></li><li><p>夯实基础，拿下西瓜书；</p></li><li><p>一切要从结果出发，要务实；</p></li><li><p>创新是给巨佬的，跟我没关系；</p></li><li><p>不要造轮子；</p></li><li><p>三个月内从零到 Kaggle Master；</p></li><li><p>Andrew Ng 说一切本质一定是过拟合和欠拟合；</p></li><li><p>看英文太费劲，国内有很多公众号不错；</p></li></ul><p>学习路线建议</p><ul><li><p>基础 = 数学 + 编程 +（英语）</p></li><li><p>积极寻找对 AI 有情怀的人</p></li><li><p>上来就是干</p></li><li><p>考虑其它维度</p></li><li><p>兼听则明，AI 届没有上帝</p></li><li><p>怀疑一切</p></li><li><p>人们将如此多的时间花在走捷径之上，以至于正常走远路的人反倒是首先到终点的</p></li><li><p>做深一点，扩展多点</p></li></ul><h2 id="深度学习框架简介如何选择合适的深度学习框架">深度学习框架简介：如何选择合适的深度学习框架？</h2><p>内容概述</p><ul><li><p>深度学习框架包括什么</p></li><li><p>选择深度学习框架的准则</p></li><li><p>TensorFlow 和 PyTorch 简介</p></li></ul><p>深度学习框架包括什么</p><ul><li><p>GPU 为基础的 Tensor 运算</p></li><li><p>构建网络后自动求解梯度的方法</p></li><li><p>模型训练体系</p></li><li><p>模型推断体系</p></li></ul><p>选择深度学习框架的准则</p><ul><li><p>生态圈</p></li><li><p>易用性（不要光看 Demo 来判断）</p></li><li><p>功能是否完整</p></li><li><p>API 是否稳定</p></li><li><p>效率</p></li></ul><h3 id="tensorflow">TensorFlow</h3><table><thead><tr class="header"><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>谷歌爸爸一撑腰，研究代码两丰收</td><td>API 不稳定</td></tr><tr class="even"><td>新版 TensorFlow API 较简洁</td><td>学习成本高</td></tr><tr class="odd"><td>天生和谷歌云兼容</td><td>开发成本高</td></tr><tr class="even"><td>有良好的推断支持</td><td></td></tr><tr class="odd"><td>功能十分强大</td><td></td></tr></tbody></table><p>PyTorch</p><table><thead><tr class="header"><th>优点</th><th>缺点</th></tr></thead><tbody><tr class="odd"><td>上手容易</td><td>没有 Keras API 那样简洁</td></tr><tr class="even"><td>代码简洁</td><td>一些功能比较难以实现</td></tr><tr class="odd"><td>发展快速，现在已经支持 TPU</td><td></td></tr><tr class="even"><td>API 相对稳定</td><td></td></tr></tbody></table><h3 id="深度学习与硬件cpu-篇">深度学习与硬件：CPU 篇</h3><p>内容概述</p><ul><li><p>为何关注深度学习硬件</p></li><li><p>CPU 硬件基础</p></li><li><p>CPU 与深度学习</p></li></ul><p>为何关注硬件</p><ul><li><p>关注硬件不等于所有都要重新写</p></li><li><p>加速训练</p></li><li><p>避免部署出现问题</p></li></ul><p>CPU 基础架构（白板演示）</p><p>CPU 在训练时候的注意事项</p><ul><li><p>一般不用 CPU 训练深度学习模型。</p></li><li><p>很多 if…else 出现时，CPU 会比 GPU 快。</p></li><li><p>如果需要加速，可以通过 Cython 访问 C++，这在实际业务性应用时很有用。</p></li><li><p>对于大部分硬件（GPU，TPU，FPGA），CPU会负责数据的读写 -&gt; 在进行训练时，</p></li></ul><p>有时为了加速需要选择更多核的机器。</p><p>CPU 在部署时候的注意事项</p><ul><li><p>避免 Cache Miss</p></li><li><p>有时需要使用足够多的核来支持读写</p></li></ul><h3 id="深度学习与硬件gpu-篇">深度学习与硬件：GPU 篇</h3><p>内容概述</p><ul><li><p>GPU 产品举例</p></li><li><p>GPU 硬件特点</p></li><li><p>GPU 与深度学习</p></li></ul><p>GPU 的主要厂商</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000145.png" alt="" /><figcaption>Nvidia</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/amd.svg" alt="" /><figcaption>AMD</figcaption></figure><p>一些 Nvidia 的产品</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000034.png" alt="" /><figcaption>Nvidia V100</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000172.jpg" alt="" /><figcaption>Nvidia P1000</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000167.jpg" alt="" /><figcaption>Nvidia P1000</figcaption></figure><p>Nvidia P1000</p><p>GPU 硬件的其他特点</p><ul><li><p>显存独立于内存，内存和显存的读取可能会成为问题。</p></li><li><p>对于显存的处理，multi-stream processer 并不如 CPU 一样强大。</p></li><li><p>GPU 是非常复杂的处理器。</p></li></ul><p>GPU 训练注意事项</p><ul><li><p>GPU 训练效率可以被 DeepSpeed 显著提升。</p></li><li><p>很少出现 GPU 多线程训练。</p></li><li><p>GPU 训练有时可能会被一些其他因素影响，如CPU，GPU 之间沟通速度（多</p></li></ul><p>GPU或多节点）。</p><ul><li>传统来说，NLP 的训练一般来说不会耗尽 GPU的资源，但是深度迁移模型出现后，</li></ul><p>GPU 常常出现算力不足或显存资源不足的情况。</p><ul><li>GPU 可处理动态的网络。</li></ul><p>GPU 部署的注意事项</p><ul><li><p>GPU 部署的最大问题：显存污染。</p></li><li><p>GPU 部署经常被内存与显存之间的带宽影响。</p></li><li><p>部署时需要对参数做详细调整，最重要参数为 Batch Size。</p></li></ul><h3 id="深度学习与硬件tpu-篇">深度学习与硬件：TPU 篇</h3><p>内容概述</p><ul><li><p>TPU 概述</p></li><li><p>TPU 与深度学习</p></li><li><p>GCP 使用教程</p></li></ul><p>TPU</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000047.png" alt="" /><figcaption>TPU</figcaption></figure><p>TPU 集群</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/000103.png" alt="" /><figcaption>TPU 集群</figcaption></figure><p>TPU 的特点</p><ul><li><p>用于训练神经网络的 TPU 只能通过 GCP 获得</p></li><li><p>TPU 本质上来说是矩阵/向量相乘的机器，构造远比 GPU 简单，所以：</p></li><li><p>TPU 十分便宜</p></li><li><p>TPU 很容易预测其表现</p></li><li><p>TPU 很擅长基于 Transformer 架构的训练和预测</p></li><li><p>TPU 不能处理动态网络</p></li></ul><p>TPU 与深度学习</p><ul><li><p>原生 Tensorflow 对 TPU 支持最好，PyTorch 目前通过 XLA 的引进也部分支持 TPU。</p></li><li><p>TPU 的主要运算瓶颈在于 IO 支持。</p></li><li><p>建议采用 TPU V3 多线程的方式，这种方式性价比最高。</p></li></ul><p>AI 项目部署：基本原则</p><p>内容概述</p><ul><li><p>AI 项目部署的难点</p></li><li><p>AI 项目部署的目标</p></li><li><p>AI 项目部署的基本原则</p></li></ul><p>AI 项目部署的难点</p><ul><li><p>AI 项目整体结构复杂，模块繁多。</p></li><li><p>AI 很多时候需要大量的算力，需要使用 GPU，TPU 或者 FPGA。</p></li><li><p>深度学习框架依赖十分复杂，配置环境困难。</p></li></ul><p>AI 项目部署目标</p><ul><li><p>不要崩，不要崩，不要崩</p></li><li><p>保证不出大的问题</p></li><li><p>保证合适的效率</p></li><li><p>保证尽可能少的侵入性</p></li></ul><p>AI 项目部署基本原则</p><ul><li><p>采用微服务框架（方便、稳定）。</p></li><li><p>采用合适硬件，注意 CPU 选型和 GPU 选型。</p></li><li><p>以 Profiler 为导向进行优化。</p></li><li><p>推断服务应该用同一个框架和一个线程，TPU 除外。</p></li><li><p>部署应该是在项目初期就考虑的，要制定完善的项目计划，并注意和客户的沟通。</p></li></ul><p>AI 项目部署：框架</p><p>内容概述</p><ul><li><p>深度学习推断框架的任务</p></li><li><p>选择深度学习推断框架的主要根据</p></li><li><p>TF Serving 简介</p></li></ul><p>深度学习推断框架的任务</p><ul><li><p>读取模型，提供 REST 接口。</p></li><li><p>调用不同的硬件资源。</p></li><li><p>对推断过程做一定处理，其中最重要的是批处理。</p></li></ul><p>选择深度学习推断框架的主要根据</p><ul><li><p>生态圈</p></li><li><p>易用性和文档完整性</p></li><li><p>对不同硬件的支持程度</p></li><li><p>功能是否强大</p></li><li><p>推断速度</p></li></ul><p>TF Serving 简介</p><p>AI 项目部署：微服务简介</p><p>内容概述</p><ul><li><p>微服务基本介绍</p></li><li><p>为何选择微服务</p></li><li><p>微服务部署 AI 的一些基本原则</p></li></ul><p>微服务基本介绍</p><p>微服务是一个概念，而不是一个严谨的定义</p><p>微服务的主要原件</p><p>Docker</p><p>Kubernetes</p><p>Istio</p><p>为何选择微服务</p><ul><li><p>入侵性小</p></li><li><p>稳定性高</p></li><li><p>功能强大</p></li></ul><p>微服务部署 AI 的一些基本原则</p><ul><li><p>对于推断，一个节点只部署一个 Docker！（TPU 除外）</p></li><li><p>如果没时间，起码选择 Kubernetes 和 Docker，因为 Docker 很容易崩溃。</p></li><li><p>一些其他的考虑：</p></li><li><p>错误恢复</p></li><li><p>灰度上线</p></li><li><p>Kafka</p></li><li><p>Actor</p></li><li><p>其他功能</p></li></ul><p>内容来自《NLP 实战高手课》</p><figure><img src="https://2020.iosdevlog.com/2020/02/25/nlp/nlp.jpg" alt="" /><figcaption>《NLP 实战高手课》</figcaption></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/25/nlp/0.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;AI&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="nlp" scheme="https://2020.iosdevlog.com/tags/nlp/"/>
    
      <category term="geektime" scheme="https://2020.iosdevlog.com/tags/geektime/"/>
    
  </entry>
  
  <entry>
    <title>Coursera 课程免费旁听与下载</title>
    <link href="https://2020.iosdevlog.com/2020/02/24/coursera/"/>
    <id>https://2020.iosdevlog.com/2020/02/24/coursera/</id>
    <published>2020-02-23T18:36:14.000Z</published>
    <updated>2020-02-24T13:58:22.812Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/24/coursera/4.png" alt="" /><figcaption>Coursera 课程</figcaption></figure><a id="more"></a><p>Coursera（/kɔːrsˈɛrə/）是由斯坦福大学的计算机科学教授吴恩达和达芙妮·科勒联合创建的一个营利性的教育科技公司。</p><p>Coursera 与多家大学合作，给大众带来一些在线免费课堂。在Knowledge@Wharton 座谈会上，Daphne Koller 在采访中说道，截至到 2012年11月，Coursera 上有来自 196 国家的超过 190万人。他们至少注册过一门课堂，尽管有数百万人注册过课堂，但完成率仅是 7-9%。</p><p>Coursera 成立于加州山景城，它的启动稍晚于由斯坦福大学教授 Sebastian Thrun 投资的盈利性在线教育网站 Udacity、但稍早于一个由麻省理工学院、哈佛大学和加州大学柏克莱分校所初创的非盈利性在线教育网站 edX。</p><p>更多信息请访问 <a href="https://zh.wikipedia.org/zh-cn/Coursera" target="_blank" rel="noopener">维基百科</a>。</p><h2 id="旁听-coursera">旁听 Coursera</h2><h3 id="打开-coursera-上的课程-tensorflow-data-and-deployment-专项课程">打开 Coursera 上的课程 <a href="ttps://www.coursera.org/specializations/tensorflow-data-and-deployment">TensorFlow: Data and Deployment 专项课程</a></h3><p><a href="https://www.coursera.org/specializations/tensorflow-data-and-deployment" target="_blank" rel="noopener" class="uri">https://www.coursera.org/specializations/tensorflow-data-and-deployment</a></p><figure><img src="https://2020.iosdevlog.com/2020/02/24/coursera/1.png" alt="" /><figcaption>课程</figcaption></figure><h3 id="点击里面的-课程-4-advanced-deployment-scenarios-with-tensorflow">点击里面的 <a href="https://www.coursera.org/learn/advanced-deployment-scenarios-tensorflow" target="_blank" rel="noopener">课程 4 Advanced Deployment Scenarios with TensorFlow</a></h3><p><a href="https://www.coursera.org/learn/advanced-deployment-scenarios-tensorflow" target="_blank" rel="noopener" class="uri">https://www.coursera.org/learn/advanced-deployment-scenarios-tensorflow</a></p><figure><img src="https://2020.iosdevlog.com/2020/02/24/coursera/2.png" alt="" /><figcaption>免费注册</figcaption></figure><h3 id="点击-免费注册">点击 <strong>免费注册</strong></h3><figure><img src="https://2020.iosdevlog.com/2020/02/24/coursera/3.png" alt="" /><figcaption>旁听</figcaption></figure><h3 id="点击-旁听">点击 <strong>旁听</strong></h3><figure><img src="https://2020.iosdevlog.com/2020/02/24/coursera/4.png" alt="" /><figcaption>完成</figcaption></figure><h2 id="下载视频和字幕">下载视频和字幕</h2><p>dl-coursera 0.1.2</p><p><a href="https://pypi.org/project/dl-coursera/" target="_blank" rel="noopener" class="uri">https://pypi.org/project/dl-coursera/</a></p><p><code>Chrome</code> 导出 <code>cookies.txt</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install -U dl_coursera</span><br><span class="line">dl_coursera --version</span><br><span class="line">dl_coursera --cookies path/to/cookies.txt --slug advanced-deployment-scenarios-tensorflow --how <span class="built_in">builtin</span></span><br></pre></td></tr></table></figure><p><code>tree advanced-deployment-scenarios-tensorflow</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">advanced-deployment-scenarios-tensorflow&#x2F;</span><br><span class="line">├── 01@tensorflow-extended</span><br><span class="line">│   ├── 01@tf-serving-as-another-deployment-option-</span><br><span class="line">│   │   ├── 01@introduction-a-conversation-with-andrew-</span><br><span class="line">│   │   │   ├── 01@.mp4</span><br><span class="line">│   │   │   └── 01@.srt</span><br><span class="line">│   │   ├── 02@introduction</span><br><span class="line">│   │   │   ├── 01@.mp4</span><br><span class="line">│   │   │   └── 01@.srt</span><br><span class="line">│   │   ├── 03@downloading-the-coding-examples-and-exer</span><br><span class="line">│   │   │   ├── 01@downloading-the-coding-examples-and-exer.html</span><br><span class="line">│   │   │   ├── 1.png</span><br><span class="line">│   │   │   └── github_screenshot.png</span><br><span class="line">│   │   ├── 04@serving</span><br><span class="line">│   │   │   ├── 01@.mp4</span><br><span class="line">│   │   │   └── 01@.srt</span><br><span class="line">│   │   ├── 05@installing-tf-serving</span><br><span class="line">│   │   │   ├── 01@.mp4</span><br><span class="line">│   │   │   └── 01@.srt</span><br><span class="line">│   │   ├── 06@installation-link</span><br><span class="line">│   │   │   └── 01@installation-link.html</span><br><span class="line">│   │   └── 07@tensorflow-serving-summary</span><br><span class="line">│   │       ├── 01@.mp4</span><br></pre></td></tr></table></figure><h2 id="上传百度网盘">上传百度网盘</h2><p>BaiduPCS-Go</p><p><a href="https://github.com/iikira/BaiduPCS-Go" target="_blank" rel="noopener" class="uri">https://github.com/iikira/BaiduPCS-Go</a></p><p>后台上传</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohub /xxx/BaiduPCS-Go u XXX . &amp;</span><br></pre></td></tr></table></figure><p>查看进程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep Baidu</span><br><span class="line">iosdevl+ 16986     1  0 14:46 ?        00:00:01 BaiduPCS-Go-v3.6.1-linux-amd64/BaiduPCS-Go u xx/ .</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/24/coursera/4.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Coursera 课程&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="学习" scheme="https://2020.iosdevlog.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Coursera" scheme="https://2020.iosdevlog.com/tags/Coursera/"/>
    
      <category term="download" scheme="https://2020.iosdevlog.com/tags/download/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow-Data-and-Deployment</title>
    <link href="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/"/>
    <id>https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/</id>
    <published>2020-02-23T03:01:43.000Z</published>
    <updated>2020-02-23T12:14:47.699Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/1.png" alt="" /><figcaption>Layer</figcaption></figure><p>GitHub 源码：<a href="https://github.com/GameDevLog/TensorFlow-Data-and-Deployment-Specialization" target="_blank" rel="noopener" class="uri">https://github.com/GameDevLog/TensorFlow-Data-and-Deployment-Specialization</a></p><a id="more"></a><h2 id="使用tensorflow.js的基于浏览器的模型browser-based-models-with-tensorflow.js">1. 使用TensorFlow.js的基于浏览器的模型(Browser-based Models with TensorFlow.js)</h2><p>将机器学习模型带入现实世界不仅仅涉及建模。本专业知识将教您如何导航各种部署方案并更有效地使用数据来训练模型。在第一门课程中，您将使用TensorFlow.js在任何浏览器中训练和运行机器学习模型。您将学习在浏览器中处理数据的技术，最后将建立一个计算机视觉项目，该项目可以识别和分类来自网络摄像头的对象。该专业化基于我们的TensorFlow实践专业化。如果您不熟悉TensorFlow，我们建议您首先参加TensorFlow实践专业化课程。为了深入了解神经网络的工作原理，我们建议您参加“​​深度学习专业化”课程。</p><h3 id="building-the-model">Building the Model</h3><h3 id="first-html-page">First HTML Page</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>First HTML Page.<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="tfjs-script">tfjs script</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -1,6 +1,7 @@</span></span><br><span class="line"> &lt;html&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;head&gt;&lt;/head&gt;</span><br><span class="line"><span class="addition">+&lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"&gt;&lt;/script&gt;</span></span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br><span class="line">     &lt;h1&gt;First HTML Page.&lt;/h1&gt;</span><br></pre></td></tr></table></figure><h3 id="model">model</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -1,7 +1,17 @@</span></span><br><span class="line"> &lt;html&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;head&gt;&lt;/head&gt;</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"&gt;&lt;/script&gt;</span><br><span class="line"><span class="addition">+&lt;script lang="js"&gt;</span></span><br><span class="line"><span class="addition">+    const model = tf.sequential();</span></span><br><span class="line"><span class="addition">+    model.add(tf.layers.dense(&#123; units: 1, inputShape: [1] &#125;));</span></span><br><span class="line"><span class="addition">+    model.compile(&#123;</span></span><br><span class="line"><span class="addition">+        loss: 'meanSquaredError',</span></span><br><span class="line"><span class="addition">+        optimizer: 'sgd'</span></span><br><span class="line"><span class="addition">+    &#125;);</span></span><br><span class="line"><span class="addition">+    model.summary();</span></span><br><span class="line"><span class="addition">+&lt;/script&gt;</span></span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br><span class="line">     &lt;h1&gt;First HTML Page.&lt;/h1&gt;</span><br></pre></td></tr></table></figure><h3 id="data">data</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -11,6 +11,9 @@</span></span><br><span class="line">         optimizer: 'sgd'</span><br><span class="line">     &#125;);</span><br><span class="line">     model.summary();</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    const xs = tf.tensor2d([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], [6, 1]);</span></span><br><span class="line"><span class="addition">+    const ys = tf.tensor2d([-3.0, -1.0, 2.0, 3.0, 5.0, 7.0], [6, 1]);</span></span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br></pre></td></tr></table></figure><h3 id="train">train</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -11,6 +11,13 @@</span></span><br><span class="line">         optimizer: 'sgd'</span><br><span class="line">     &#125;);</span><br><span class="line">     model.summary();</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    const xs = tf.tensor2d([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], [6, 1]);</span></span><br><span class="line"><span class="addition">+    const ys = tf.tensor2d([-3.0, -1.0, 2.0, 3.0, 5.0, 7.0], [6, 1]);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    doTraining(model).then(() =&gt; &#123;</span></span><br><span class="line"><span class="addition">+        alert(model.predict(tf.tensor2d([10], [1, 1])));</span></span><br><span class="line"><span class="addition">+    &#125;);</span></span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br></pre></td></tr></table></figure><h3 id="dotraining">doTraining</h3><p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> @@ -4,6 +4,23 @@</span><br><span class="line"> </span><br><span class="line"> &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"&gt;&lt;/script&gt;</span><br><span class="line"> &lt;script lang="js"&gt;</span><br><span class="line"><span class="addition">+    async function doTraining(model) &#123;</span></span><br><span class="line"><span class="addition">+        const history =</span></span><br><span class="line"><span class="addition">+            await model.fit(xs, ys,</span></span><br><span class="line"><span class="addition">+                &#123;</span></span><br><span class="line"><span class="addition">+                    epochs: 500,</span></span><br><span class="line"><span class="addition">+                    callbacks: &#123;</span></span><br><span class="line"><span class="addition">+                        onEpochEnd: async (epoch, logs) =&gt; &#123;</span></span><br><span class="line"><span class="addition">+                            console.log("Epoch:"</span></span><br><span class="line"><span class="addition">+                                + epoch</span></span><br><span class="line"><span class="addition">+                                + " Loss:"</span></span><br><span class="line"><span class="addition">+                                + logs.loss);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+                        &#125;</span></span><br><span class="line"><span class="addition">+                    &#125;</span></span><br><span class="line"><span class="addition">+                &#125;);</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     const model = tf.sequential();</span><br><span class="line">     model.add(tf.layers.dense(&#123; units: 1, inputShape: [1] &#125;));</span><br><span class="line">     model.compile(&#123;</span><br></pre></td></tr></table></figure></p><h3 id="test">test</h3><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/2.png" alt="" /><figcaption>Safari</figcaption></figure><h3 id="iris">Iris</h3><p><a href="https://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" rel="noopener" class="uri">https://archive.ics.uci.edu/ml/datasets/Iris</a></p><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/3.png" alt="" /><figcaption>Iris</figcaption></figure><p><a href="https://commons.wikimedia.org/w/index.php?curid=46257808" target="_blank" rel="noopener" class="uri">https://commons.wikimedia.org/w/index.php?curid=46257808</a></p><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/Iris_dataset_scatterplot.svg" alt="" /><figcaption>Iris_dataset_scatterplot</figcaption></figure><h3 id="iris.csv">iris.csv</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sepal_length,sepal_width,petal_length,petal_width,species</span><br><span class="line">5.1,3.5,1.4,0.2,setosa</span><br><span class="line">4.9,3,1.4,0.2,setosa</span><br><span class="line">4.7,3.2,1.3,0.2,setosa</span><br><span class="line">4.6,3.1,1.5,0.2,setosa</span><br><span class="line">5,3.6,1.4,0.2,setosa</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="async">async</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -3,6 +3,8 @@</span></span><br><span class="line"> &lt;head&gt;&lt;/head&gt;</span><br><span class="line"> &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"&gt;&lt;/script&gt;</span><br><span class="line"> &lt;script lang="js"&gt;</span><br><span class="line"><span class="addition">+    async function run() &#123;</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br></pre></td></tr></table></figure><p>### load iris.csv</p><p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> @@ -3,6 +3,16 @@</span><br><span class="line"> &lt;head&gt;&lt;/head&gt;</span><br><span class="line"> &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"&gt;&lt;/script&gt;</span><br><span class="line"> &lt;script lang="js"&gt;</span><br><span class="line"><span class="addition">+    async function run() &#123;</span></span><br><span class="line"><span class="addition">+        const csvUrl = 'iris.csv';</span></span><br><span class="line"><span class="addition">+        const trainingData = tf.data.csv(csvUrl, &#123;</span></span><br><span class="line"><span class="addition">+            columnConfigs: &#123;</span></span><br><span class="line"><span class="addition">+                species: &#123;</span></span><br><span class="line"><span class="addition">+                    isLabel: true</span></span><br><span class="line"><span class="addition">+                &#125;</span></span><br><span class="line"><span class="addition">+            &#125;</span></span><br><span class="line"><span class="addition">+        &#125;);</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br></pre></td></tr></table></figure></p><h3 id="one-hot-encoder">One-Hot encoder</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -12,6 +12,18 @@</span></span><br><span class="line">                 &#125;</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        const numOfFeatures = (await trainingData.columnNames()).length - 1;</span></span><br><span class="line"><span class="addition">+        const numOfSamples = 150;</span></span><br><span class="line"><span class="addition">+        const convertedData =</span></span><br><span class="line"><span class="addition">+            trainingData.map((&#123; xs, ys &#125;) =&gt; &#123;</span></span><br><span class="line"><span class="addition">+                const labels = [</span></span><br><span class="line"><span class="addition">+                    ys.species == "setosa" ? 1 : 0,</span></span><br><span class="line"><span class="addition">+                    ys.species == "virginica" ? 1 : 0,</span></span><br><span class="line"><span class="addition">+                    ys.species == "versicolor" ? 1 : 0</span></span><br><span class="line"><span class="addition">+                ]</span></span><br><span class="line"><span class="addition">+                return &#123; xs: Object.values(xs), ys: Object.values(labels) &#125;;</span></span><br><span class="line"><span class="addition">+            &#125;).batch(10);</span></span><br><span class="line">     &#125;</span><br><span class="line"> &lt;/script&gt;</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/4.png" alt="" /><figcaption>One-Hot Encoder</figcaption></figure><h2 id="nn">NN</h2><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/5.png" alt="" /><figcaption>NN</figcaption></figure><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -24,6 +24,14 @@</span></span><br><span class="line">                 ]</span><br><span class="line">                 return &#123; xs: Object.values(xs), ys: Object.values(labels) &#125;;</span><br><span class="line">             &#125;).batch(10);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        const model = tf.sequential();</span></span><br><span class="line"><span class="addition">+        model.add(tf.layers.dense(&#123;</span></span><br><span class="line"><span class="addition">+            inputShape: [numOfFeatures],</span></span><br><span class="line"><span class="addition">+            activation: "sigmoid", units: 5</span></span><br><span class="line"><span class="addition">+        &#125;))</span></span><br><span class="line"><span class="addition">+        model.add(tf.layers.dense(&#123; activation: "softmax", units: 3 &#125;));</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     &#125;</span><br><span class="line"> &lt;/script&gt;</span><br></pre></td></tr></table></figure><h3 id="compile">compile</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -32,6 +32,10 @@</span></span><br><span class="line">         &#125;))</span><br><span class="line">         model.add(tf.layers.dense(&#123; activation: "softmax", units: 3 &#125;));</span><br><span class="line"> </span><br><span class="line"><span class="addition">+        model.compile(&#123;</span></span><br><span class="line"><span class="addition">+            loss: "categoricalCrossentropy",</span></span><br><span class="line"><span class="addition">+            optimizer: tf.train.adam(0.06)</span></span><br><span class="line"><span class="addition">+        &#125;);</span></span><br><span class="line">     &#125;</span><br><span class="line"> &lt;/script&gt;</span><br></pre></td></tr></table></figure><h3 id="fit">fit</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -36,6 +36,15 @@</span></span><br><span class="line">             loss: "categoricalCrossentropy",</span><br><span class="line">             optimizer: tf.train.adam(0.06)</span><br><span class="line">         &#125;);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        await model.fitDataset(convertedData, &#123;</span></span><br><span class="line"><span class="addition">+            epochs: 100,</span></span><br><span class="line"><span class="addition">+            callbacks: &#123;</span></span><br><span class="line"><span class="addition">+                onEpochEnd: async (epoch, logs) =&gt; &#123;</span></span><br><span class="line"><span class="addition">+                    console.log("Epoch: " + epoch + " Loss: " + logs.loss);</span></span><br><span class="line"><span class="addition">+                &#125;</span></span><br><span class="line"><span class="addition">+            &#125;</span></span><br><span class="line"><span class="addition">+        &#125;);</span></span><br><span class="line">     &#125;</span><br><span class="line"> &lt;/script&gt;</span><br></pre></td></tr></table></figure><p>### predict</p><p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -45,6 +45,10 @@</span></span><br><span class="line">                 &#125;</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        const testVal = tf.tensor2d([5.8, 2.7, 5.1, 1.9], [1, 4]);</span></span><br><span class="line"><span class="addition">+        const prediction = model.predict(testVal);</span></span><br><span class="line"><span class="addition">+        alert(prediction)</span></span><br><span class="line">     &#125;</span><br><span class="line"> &lt;/script&gt;</span><br></pre></td></tr></table></figure></p><h3 id="run">run</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -50,6 +50,8 @@</span></span><br><span class="line">         const prediction = model.predict(testVal);</span><br><span class="line">         alert(prediction)</span><br><span class="line">     &#125;</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    run();</span></span><br><span class="line"> &lt;/script&gt;</span><br><span class="line"> </span><br><span class="line"> &lt;body&gt;</span><br></pre></td></tr></table></figure><p>HTTP Server</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python2 -m SimpleHTTPServer</span><br></pre></td></tr></table></figure></p><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/6.png" alt="" /><figcaption>run</figcaption></figure><p>第 2 种概率最高</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor</span><br><span class="line">     [[0.0000663, 0.8690438, 0.1308898],]</span><br></pre></td></tr></table></figure><h3 id="classname">className</h3><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@@ -46,9 +46,20 @@</span></span><br><span class="line">             &#125;</span><br><span class="line">         &#125;);</span><br><span class="line"> </span><br><span class="line"><span class="addition">+        // Setosa</span></span><br><span class="line"><span class="addition">+        // const testVal = tf.tensor2d([4.4, 2.9, 1.4, 0.2], [1, 4]);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        // Versicolor</span></span><br><span class="line"><span class="addition">+        // const testVal = tf.tensor2d([6.4, 3.2, 4.5, 1.5], [1, 4]);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        // Virginica</span></span><br><span class="line">         const testVal = tf.tensor2d([5.8, 2.7, 5.1, 1.9], [1, 4]);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line">         const prediction = model.predict(testVal);</span><br><span class="line"><span class="deletion">-        alert(prediction)</span></span><br><span class="line"><span class="addition">+        const pIndex = tf.argMax(prediction, axis = 1).dataSync();</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        const classNames = ["Setosa", "Virginica", "Versicolor"];</span></span><br><span class="line"><span class="addition">+        alert(classNames[pIndex])</span></span><br><span class="line">     &#125;</span><br><span class="line"> </span><br><span class="line">     run();</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/7.png" alt="" /><figcaption>className</figcaption></figure><h2 id="使用tensorflow-lite的基于设备的模型device-based-models-with-tensorflow-lite">2. 使用TensorFlow Lite的基于设备的模型(Device-based Models with TensorFlow Lite)</h2><p>将机器学习模型带入现实世界不仅仅涉及建模。本专业知识将教您如何导航各种部署方案并更有效地使用数据来训练模型。第二门课程教您如何在移动应用程序中运行机器学习模型。您将学习如何为低功耗，电池供电的设备准备模型，然后在Android和iOS平台上执行模型。最后，您将探索如何在Raspberry Pi和微控制器上使用TensorFlow在嵌入式系统上进行部署。该专业化基于我们的TensorFlow实践专业化。如果您不熟悉TensorFlow，我们建议您首先参加TensorFlow实践专业化课程。为了深入了解神经网络的工作原理，</p><h2 id="使用tensorflow数据服务的数据管道data-pipelines-with-tensorflow-data-services">3. 使用TensorFlow数据服务的数据管道(Data Pipelines with TensorFlow Data Services)</h2><p>将机器学习模型带入现实世界不仅仅涉及建模。本专业知识将教您如何导航各种部署方案并更有效地使用数据来训练模型。在这第三门课程中，您将在TensorFlow中使用一套工具来更有效地利用数据和训练模型。您将学习如何仅用几行代码就可以利用内置数据集，如何使用API​​控制如何拆分数据以及如何处理所有类型的非结构化数据。该专业化基于我们的TensorFlow实践专业化。如果您不熟悉TensorFlow，我们建议您首先参加TensorFlow实践专业化课程。为了深入了解神经网络的工作原理，我们建议您参加“​​深度学习专业化”课程。</p><h2 id="使用tensorflow的高级部署方案advanced-deployment-scenarios-with-tensorflow">4. 使用TensorFlow的高级部署方案(Advanced Deployment Scenarios with TensorFlow)</h2><p>将机器学习模型带入现实世界不仅仅涉及建模。本专业知识将教您如何导航各种部署方案并更有效地使用数据来训练模型。在这最后的课程中，您将探索在部署模型时会遇到的四种不同情况。将向您介绍TensorFlow Serving，该技术可让您通过Web进行推理。您将继续使用TensorFlow Hub，该模型库可用于转移学习。然后，您将使用TensorBoard评估并了解模型的工作方式，并与他人共享模型元数据。最后，您将探索联合学习，以及如何在保持数据隐私的同时使用用户数据重新训练已部署的模型。该专业化基于我们的TensorFlow实践专业化。如果您不熟悉TensorFlow，我们建议您首先参加TensorFlow实践专业化课程。为了深入了解神经网络的工作原理，我们建议您参加“​​深度学习专业化”课程。</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/23/TensorFlow-Data-and-Deployment/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Layer&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;GitHub 源码：&lt;a href=&quot;https://github.com/GameDevLog/TensorFlow-Data-and-Deployment-Specialization&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://github.com/GameDevLog/TensorFlow-Data-and-Deployment-Specialization&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="TensorFlow" scheme="https://2020.iosdevlog.com/tags/TensorFlow/"/>
    
      <category term="Android" scheme="https://2020.iosdevlog.com/tags/Android/"/>
    
      <category term="iOS" scheme="https://2020.iosdevlog.com/tags/iOS/"/>
    
      <category term="Deployment" scheme="https://2020.iosdevlog.com/tags/Deployment/"/>
    
      <category term="js" scheme="https://2020.iosdevlog.com/tags/js/"/>
    
      <category term="mobile" scheme="https://2020.iosdevlog.com/tags/mobile/"/>
    
  </entry>
  
  <entry>
    <title>《极简算法史：从数学到机器的故事》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/22/9787115500809/"/>
    <id>https://2020.iosdevlog.com/2020/02/22/9787115500809/</id>
    <published>2020-02-22T15:00:26.000Z</published>
    <updated>2020-02-22T17:44:16.115Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/1.jpg" alt="" /><figcaption>《极简算法史：从数学到机器的故事》</figcaption></figure><p>书名：极简算法史：从数学到机器的故事<br />作者：[法]吕克·德·布拉班迪尔<br />译者：任轶<br />出版社：人民邮电出版社<br />出版时间：2018-12<br />ISBN：9787115500809</p><p>一位工程师、一位数学家、一位逻辑学家和一位哲学家一起在苏格兰旅行。他们走在一条路上，栖息在悬岩上的一只黑山羊看着他们路过。</p><p>“你们看到了吗？”工程师说，“在苏格兰，山羊都是黑色的！”</p><p>数学家反驳道：“可能你想说的是：有些苏格兰山羊是黑色的。”</p><p>逻辑学家补充道：“先不要妄下结论。我们只能说：苏格兰至少有一只黑山羊！”</p><p>最后，哲学家总结道：“我们唯一能真正确定的是：在这个地方的这只山羊是黑色的！”</p><a id="more"></a><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/2.jpg" alt="" /><figcaption>序</figcaption></figure><p><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/3.jpg" alt="柏拉图" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/4.jpg" alt="亚里士多德" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/6.jpg" alt="阿尔·花拉子米" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/9.jpg" alt="笛卡儿" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/11.jpg" alt="伽利略" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/13.jpg" alt="布莱士·帕斯卡" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/15.jpg" alt="托马斯·贝叶斯" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/16.jpg" alt="莱布尼茨" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/19.jpg" alt="欧拉" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/23.jpg" alt="康德" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/24.jpg" alt="乔治·布尔" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/25.jpg" alt="库尔特·哥德尔" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/27.jpg" alt="伯特兰·罗素" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/28.jpg" alt="路德维希·维特根斯坦" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/29.jpg" alt="克劳德·香农" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/31.jpg" alt="诺伯特·维纳" /><br /><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/32.jpg" alt="阿兰·图灵" /></p><h2 id="第一部分-莱布尼茨之梦">第一部分 莱布尼茨之梦</h2><p>三次“抽象运动”的硕果</p><ul><li>算术</li><li>几何</li><li>代数</li></ul><p>第四次抽象运动</p><ul><li>逻辑学<ul><li>演绎法<ul><li>这条街上的所有房子都很漂亮。</li><li>这座房子在这条街上。</li><li>这座房子很漂亮。</li></ul></li><li>归纳法<ul><li>这座房子在这条街上。</li><li>这座房子很漂亮。</li><li>在这条街上所有的房子都很漂亮。</li></ul></li><li>溯因法<ul><li>这座房子很漂亮。</li><li>在这条街上所有的房子都很漂亮。</li><li>这座房子在这条街上。</li></ul></li></ul></li></ul><blockquote><p>数学与语言无关，逻辑却并非如此。</p></blockquote><h3 id="哥德尔证明罗素是在浪费时间">哥德尔证明，罗素是在浪费时间</h3><ol type="1"><li>三角形内角和为180°；</li><li>正方形的内角和为270°。</li><li>1 是正确的。</li><li>2 是错误的。</li><li>在定理中无法对 5 加以证明。</li></ol><p>于是有两种可能的情况：</p><ol type="1"><li>要么可以证明 5，但是，由于语句说明的情况与此相反，因而定理不具有逻辑的严密性；</li><li>要么无法证明 5，因而语句为真，但这意味着，定理不具有完备性。</li></ol><p><strong>悖论</strong>：“所有克里特人都是骗子”的现代版——</p><blockquote><p>埃庇米尼得斯虽然这么宣布了，但他自己就是克里特人，如果他说的是真的，那么既然他也是克里特人，那说明他也是个骗子，他的话就不可信；而如果他说谎了，那么就印证了“所有克里特人都是骗子”这句话，那说明他所言为真……</p></blockquote><h2 id="第二部分-三座丰碑">第二部分 三座丰碑</h2><h3 id="贝叶斯">贝叶斯</h3><p>《关于如何在机会论的框架下解决问题》（Anessay towards solving a problem in thedoctrine of Chance</p><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/59.jpg" alt="" /><figcaption>罐子</figcaption></figure><p>每个罐子里装有40颗石子。1号罐子里装了30颗白色石子和10颗黑色石子，2号罐子里装有黑白石子各20颗。假设随机拿起一个罐子，并从这个罐子里随机取出一颗石子，且这颗石子是白色的，那么这颗白色石子来自1号罐子的概率是多少？</p><ol type="1"><li>已知被选中的石子是白色的，用获得白色石子的概率乘以选择1号罐子的概率；</li><li>已知白色石子来自1号罐子，用选择1号罐子的概率乘以获得白色石子的概率。</li></ol><p>A：1号罐子的假设<br />B：白色石子的假设</p><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/60.jpg" alt="" /><figcaption>相同的答案</figcaption></figure><p><span class="math display">\[p(\mathrm{B}). p(\mathrm{A} / 已知 \mathrm{B})=p(\mathrm{A}). p(\mathrm{B} / 已知 \mathrm{A})\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/61.jpg" alt="" /><figcaption>贝叶斯公式</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/62.jpg" alt="" /><figcaption>答案</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/63.jpg" alt="" /><figcaption>贝叶斯网络</figcaption></figure><h3 id="香农证明如何计算11">香农证明，如何计算1+1</h3><p>信息动力学，两个定理分别探讨的是 <strong>信息量</strong> 和信息的 <strong>质量</strong>。</p><ul><li>第一个定理涉及信息的压缩<ul><li>编码一条信息所需的最少符号数量是多少？</li></ul></li><li>第二个定理涉及信息的传输<ul><li>为了在终点处获取从起点处发出的准确信息，需要哪些必要条件？</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/65.jpg" alt="" /><figcaption>通信的环境进行建模</figcaption></figure><p>测量单位。就像卡路里可以量化热交换一样，香农提出的“比特”（bit，也叫位）的概念用于测量信息量。</p><p>比特是一个二进制数字，可以取0或1的值。</p><p>信息的测量应该满足一个苛刻的关系</p><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/66.jpg" alt="" /><figcaption>对数函数</figcaption></figure><p>其中，<span class="math inline">\(f\)</span> 只能是对数函数，因为根据定义，同一底数的两个正数的对数之和等于这两个数的积的对数。</p><p>香农的公式能让我们借助经验计算出摩尔斯电码的效率为85%！我们不得不佩服公式发明者出色的直觉。</p><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/68.jpg" alt="" /><figcaption>形式逻辑</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/69.jpg" alt="" /><figcaption>与或非门</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/70.jpg" alt="" /><figcaption>逻辑电路</figcaption></figure><p>香农数：国际象棋棋局的理论数目，结果是 <span class="math inline">\(10^{120}\)</span></p><h3 id="诺伯特维纳与控制论cybernetics">诺伯特·维纳与控制论（cybernetics）</h3><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/73.jpg" alt="" /><figcaption>控制</figcaption></figure><h2 id="第三部分-自动化理性批判">第三部分 自动化理性批判</h2><blockquote><p>科学是父亲教给儿子。<br />技术是儿子教给父亲。<br />——米歇尔·塞尔</p></blockquote><h3 id="算法algorithm">算法（algorithm）</h3><p>三种不确定性</p><ol type="1"><li>圣诞节是在什么时候？你不知道，我也不知道。</li><li>谁将在2022年当选法国总统？你不知道，我也不知道。</li><li>因为我们甚至不知道“我们不知道”。</li></ol><p>第三类不确定性涉及了“没人提出的问题”。在这种情况下，超级计算机也没有用了……因为没有什么可以计算的！</p><p>这类事件通常被称为 <strong>“黑天鹅”</strong>。</p><p>这一说法是用来纪念一位18世纪的英国探险家，这位探险家曾确信所有天鹅都是白色的，然而，他在澳大利亚逗留期间，惊讶地看到了一只黑天鹅——没有一个欧洲人曾对这类水禽的颜色提出过疑问。于是，黑天鹅成为第三类不确定性的象征。</p><h3 id="全球化管理的重要性">全球化管理的重要性</h3><ul><li>互联网并非公共空间。</li><li>互联网并非全球性的。</li><li>互联网并非环保。</li><li>互联网既不是虚拟的，也不是非物质的。</li><li>互联网并非透明。（大数据）</li><li>互联网并非中立。（算法）</li><li>互联网在其运作过程中并没有完全被理解。</li><li>互联网并非市场经济的保障。</li><li>互联网并非民主的保障。</li><li>互联网并非掌握真相。</li><li>互联网积累的信息正在变得无用。</li><li>互联网并非友善。（暴力）</li><li>互联网是脆弱的。（Bug）</li><li>互联网并非自动。（参数）</li><li>互联网并非自由。（surf，原意是冲浪）</li><li>互联网只有部分是可访问的。（暗网）</li><li>互联网并非优质教育的保障。</li><li>互联网并非公平。</li><li>互联网并非免费。</li><li>互联网是我们的工具，而我们也是互联网的工具。（测试）</li><li>互联网不好也不坏。</li><li>互联网，尤其对民主国家来说，是空前的挑战。</li></ul><h3 id="死亡电脑社">死亡电脑社</h3><p>互联网上的预言大师名为 <strong>奇点</strong>。</p><p>奇点指的是机器与人类彻底融合的时刻，这种情况注定会在某一天发生。</p><h3 id="人工智能许多问题之一">人工智能：许多问题之一</h3><p>智商（IQ）</p><ul><li>音乐智力，这种智力体现为对声音和节奏的感知度。它寻找音符的含义，并想象改编为其他乐曲的可能性。</li><li>运动智力，这种智力能释放身体各个部位的潜能。它组织了用来解决特定问题的最佳动作序列。</li><li>人际关系智力（或情感智力），这种智力能识别他人的感受和意图。它能感知到对于谈判、合作和互动等行为来说，什么是重要的因素。</li><li>视觉智力，这种智力可以从三个维度进行思考。它能让我们在建模之前、在空间内移动物体之前、在看到被要求思考的东西之前，就先进行想象。</li><li>语言智力，这种智力是利用语言反应的能力。如果有必要，这种智力甚至能够催生新的语言。</li></ul><h2 id="答案">答案</h2><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/89.jpg" alt="" /><figcaption>89</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/22/9787115500809/90.jpg" alt="" /><figcaption>90</figcaption></figure><p>从古希腊哲学到数学，从逻辑推理到“无所不能”的计算机。柏拉图、莱布尼茨、罗素、香农、图灵……一个个伟大的思想家试图从数学公式中证明推理的合理性。</p><p>他们是凭借天赋制胜，还是在鲁莽地大胆一搏？</p><p>如何将逻辑赋予数学意义？</p><p>如何从简单运算，走向复杂智慧？</p><p>一场人类探索数学、算法与逻辑思维，并最终走向人工智能的梦想之旅，展现了哲学家、逻辑学家与数学家独特的思维方式，探讨了算法与人工智能对科学和社会的巨大影响。</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/22/9787115500809/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《极简算法史：从数学到机器的故事》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：极简算法史：从数学到机器的故事&lt;br /&gt;
作者：[法]吕克·德·布拉班迪尔&lt;br /&gt;
译者：任轶&lt;br /&gt;
出版社：人民邮电出版社&lt;br /&gt;
出版时间：2018-12&lt;br /&gt;
ISBN：9787115500809&lt;/p&gt;
&lt;p&gt;一位工程师、一位数学家、一位逻辑学家和一位哲学家一起在苏格兰旅行。他们走在一条路上，栖息在悬岩上的一只黑山羊看着他们路过。&lt;/p&gt;
&lt;p&gt;“你们看到了吗？”工程师说，“在苏格兰，山羊都是黑色的！”&lt;/p&gt;
&lt;p&gt;数学家反驳道：“可能你想说的是：有些苏格兰山羊是黑色的。”&lt;/p&gt;
&lt;p&gt;逻辑学家补充道：“先不要妄下结论。我们只能说：苏格兰至少有一只黑山羊！”&lt;/p&gt;
&lt;p&gt;最后，哲学家总结道：“我们唯一能真正确定的是：在这个地方的这只山羊是黑色的！”&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Math" scheme="https://2020.iosdevlog.com/tags/Math/"/>
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Concepts</title>
    <link href="https://2020.iosdevlog.com/2020/02/22/ds/"/>
    <id>https://2020.iosdevlog.com/2020/02/22/ds/</id>
    <published>2020-02-22T11:10:39.000Z</published>
    <updated>2020-02-22T11:19:03.548Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/22/ds/Process.png" alt="" /><figcaption>Process</figcaption></figure><a id="more"></a><h2 id="types">Types</h2><h3 id="regression">Regression</h3><ul><li>A supervised problem, the outputs are continuous rather than discrete.</li></ul><h3 id="classification">Classification</h3><ul><li>Inputs are divided into two or more classes, and the learner must produce a model that assigns unseen inputs to one or more (multi-label classification) of these classes. This is typically tackled in a supervised way.</li></ul><h3 id="clustering">Clustering</h3><ul><li>A set of inputs is to be divided into groups. Unlike in classification, the groups are not known beforehand, making this typically an unsupervised task.</li></ul><h3 id="density-estimation">Density Estimation</h3><ul><li>Finds the distribution of inputs in some space.</li></ul><h3 id="dimensionality-reduction">Dimensionality Reduction</h3><ul><li>Simplifies inputs by mapping them into a lower-dimensional space.</li></ul><h2 id="kind">Kind</h2><h3 id="parametric">Parametric</h3><ul><li><p>Step 1: Making an assumption about the functional form or shape of our function (f), i.e.: f is linear, thus we will select a linear model.</p></li><li><p>Step 2: Selecting a procedure to fit or train our model. This means estimating the Beta parameters in the linear function. A common approach is the (ordinary) least squares, amongst others.</p></li></ul><h3 id="non-parametric">Non-Parametric</h3><ul><li>When we do not make assumptions about the form of our function (f). However, since these methods do not reduce the problem of estimating f to a small number of parameters, a large number of observations is required in order to obtain an accurate estimate for f. An example would be the thin-plate spline model.</li></ul><h2 id="categories">Categories</h2><h3 id="supervised">Supervised</h3><ul><li>The computer is presented with example inputs and their desired outputs, given by a "teacher", and the goal is to learn a general rule that maps inputs to outputs.</li></ul><h3 id="unsupervised">Unsupervised</h3><ul><li>No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).</li></ul><h3 id="reinforcement-learning">Reinforcement Learning</h3><ul><li>A computer program interacts with a dynamic environment in which it must perform a certain goal (such as <a href="https://en.wikipedia.org/wiki/Autonomous_car" target="_blank" rel="noopener">driving a vehicle</a> or playing a game against an opponent). The program is provided feedback in terms of rewards and punishments as it navigates its problem space.</li></ul><h2 id="approaches">Approaches</h2><h3 id="decision-tree-learning">Decision tree learning</h3><h3 id="association-rule-learning">Association rule learning</h3><h3 id="artificial-neural-networks">Artificial neural networks</h3><h3 id="deep-learning">Deep learning</h3><h3 id="inductive-logic-programming">Inductive logic programming</h3><h3 id="support-vector-machines">Support vector machines</h3><h3 id="clustering-1">Clustering</h3><h3 id="bayesian-networks">Bayesian networks</h3><h3 id="reinforcement-learning-1">Reinforcement learning</h3><h3 id="representation-learning">Representation learning</h3><h3 id="similarity-and-metric-learning">Similarity and metric learning</h3><h3 id="sparse-dictionary-learning">Sparse dictionary learning</h3><h3 id="genetic-algorithms">Genetic algorithms</h3><h3 id="rule-based-machine-learning">Rule-based machine learning</h3><h3 id="learning-classifier-systems">Learning classifier systems</h3><h2 id="taxonomy">Taxonomy</h2><h3 id="generative-methods">Generative Methods</h3><ul><li><p>Popular models</p><ul><li><p>Mixtures of Gaussians, Mixtures of experts, Hidden Markov Models (HMM)</p></li><li><p>Gaussians, Naïve Bayes, Mixtures of multinomials</p></li><li><p>Sigmoidal belief networks, Bayesian networks, Markov random fields</p></li></ul></li><li><p>Model class-conditional pdfs and prior probabilities. “Generative” since sampling can generate synthetic data points.</p></li></ul><h3 id="discriminative-methods">Discriminative Methods</h3><ul><li><p>Directly estimate posterior probabilities. No attempt to model underlying probability distributions. Focus computational resources on given task– better performance</p></li><li><p>Popular Models</p><ul><li><p>Logistic regression, SVMs</p></li><li><p>Traditional neural networks, Nearest neighbor</p></li><li><p>Conditional Random Fields (CRF)</p></li></ul></li></ul><h2 id="selection-criteria">Selection Criteria</h2><h3 id="prediction-accuracy-vs-model-interpretability">Prediction Accuracy vs Model Interpretability</h3><ul><li>There is an inherent tradeoff between Prediction Accuracy and Model Interpretability, that is to say that as the model get more flexible in the way the function (f) is selected, they get obscured, and are hard to interpret. Flexible methods are better for inference, and inflexible methods are preferable for prediction.</li></ul><h2 id="libraries">Libraries</h2><h3 id="python">Python</h3><ul><li><p>Numpy</p><ul><li>Adds support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays</li></ul></li><li><p>Pandas</p><ul><li>Offers data structures and operations for manipulating numerical tables and time series</li></ul></li><li><p>Scikit-Learn</p><ul><li>It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.</li></ul></li><li><p>Tensorflow</p><ul><li><p>Components<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/708342AF-41CC-4702-B41B-08DE83166234.png" /></p><ul><li><p>Does lazy evaluation. Need to build the graph, and then run it in a session.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/B19BDBEE-22D5-4A3E-8861-4790CDDE01E0.png" /></p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/FC3EF1F8-AC76-4D03-9E45-036D76C4E216.png" /></p></li><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/AA360355-4A67-41ED-8475-81391BD62DB3.png" /></p></li></ul></li></ul></li></ul></li><li><p>MXNet</p><ul><li>Is an modern open-source deep learning framework used to train, and deploy deep neural networks. MXNet library is portable and can scale to multiple GPUs and multiple machines. MXNet is supported by major Public Cloud providers including AWS and Azure. Amazon has chosen MXNet as its deep learning framework of choice at AWS.</li></ul></li><li><p>Keras</p><ul><li>Is an open source neural network library written in Python. It is capable of running on top of MXNet, Deeplearning4j, Tensorflow, CNTK or Theano. Designed to enable fast experimentation with deep neural networks, it focuses on being minimal, modular and extensible.</li></ul></li><li><p>Torch</p><ul><li>Torch is an open source machine learning library, a scientific computing framework, and a script language based on the Lua programming language. It provides a wide range of algorithms for deep machine learning, and uses the scripting language LuaJIT, and an underlying C implementation.</li></ul></li><li><p>Microsoft Cognitive Toolkit</p><ul><li>Previously known as CNTK and sometimes styled as The Microsoft Cognitive Toolkit, is a deep learning framework developed by Microsoft Research. Microsoft Cognitive Toolkit describes neural networks as a series of computational steps via a directed graph.</li></ul></li></ul><h2 id="tuning">Tuning</h2><h3 id="cross-validation">Cross-validation</h3><ul><li><p>One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/8EAF745C-496E-45EA-B94F-FEC16E431FAD.png" /></li></ul></li><li><p>Methods</p><ul><li><p>Leave-p-out cross-validation</p></li><li><p>Leave-one-out cross-validation</p></li><li><p>k-fold cross-validation</p></li><li><p>Holdout method</p></li><li><p>Repeated random sub-sampling validation</p></li></ul></li></ul><h3 id="hyperparameters">Hyperparameters</h3><ul><li><p>Grid Search</p><ul><li>The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set.</li></ul></li><li><p>Random Search</p><ul><li>Since grid searching is an exhaustive and therefore potentially expensive method, several alternatives have been proposed. In particular, a randomized search that simply samples parameter settings a fixed number of times has been found to be more effective in high-dimensional spaces than exhaustive search.</li></ul></li><li><p>Gradient-based optimization</p><ul><li>For specific learning algorithms, it is possible to compute the gradient with respect to hyperparameters and then optimize the hyperparameters using gradient descent. The first usage of these techniques was focused on neural networks. Since then, these methods have been extended to other models such as support vector machines or logistic regression.</li></ul></li></ul><h3 id="early-stopping-regularization">Early Stopping (Regularization)</h3><ul><li>Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit, and stop the algorithm then.</li></ul><h3 id="overfitting">Overfitting</h3><ul><li>When a given method yields a small training MSE (or cost), but a large test MSE (or cost), we are said to be overfitting the data. This happens because our statistical learning procedure is trying too hard to find pattens in the data, that might be due to random chance, rather than a property of our function. In other words, the algorithms may be learning the training data too well. If model overfits, try removing some features, decreasing degrees of freedom, or adding more data.</li></ul><h3 id="underfitting">Underfitting</h3><ul><li>Opposite of Overfitting. Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It occurs when the model or algorithm does not fit the data enough. Underfitting occurs if the model or algorithm shows low variance but high bias (to contrast the opposite, overfitting from high variance and low bias). It is often a result of an excessively simple model.</li></ul><h3 id="bootstrap">Bootstrap</h3><ul><li>Test that applies Random Sampling with Replacement of the available data, and assigns measures of accuracy (bias, variance, etc.) to sample estimates.</li></ul><h3 id="bagging">Bagging</h3><ul><li>An approach to ensemble learning that is based on bootstrapping. Shortly, given a training set, we produce multiple different training sets (called bootstrap samples), by sampling with replacement from the original dataset. Then, for each bootstrap sample, we build a model. The results in an ensemble of models, where each model votes with the equal weight. Typically, the goal of this procedure is to reduce the variance of the model of interest (e.g. decision trees).</li></ul><h2 id="performance-analysis">Performance Analysis</h2><h3 id="confusion-matrix">Confusion Matrix</h3><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/1F3239B7-A891-4326-831C-0F01A7ACFA00.png" /></li></ul><h3 id="accuracy">Accuracy</h3><ul><li>Fraction of correct predictions, not reliable as skewed when the data set is unbalanced (that is, when the number of samples in different classes vary greatly)</li></ul><h3 id="f1-score">f1 score</h3><ul><li><p>Precision</p><ul><li>Out of all the examples the classifier labeled as positive, what fraction were correct?<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/7B2111F9-6BF0-43B2-B130-C24CAAC39365.png" /></li></ul></li><li><p>Recall</p><ul><li>Out of all the positive examples there were, what fraction did the classifier pick up?<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/77C64150-2B24-41B5-8F70-AD154A20EC66.png" /></li></ul></li><li><p>Harmonic Mean of Precision and Recall: (2 * p * r / (p + r))</p></li></ul><h3 id="roc-curve---receiver-operating-characteristics">ROC Curve - Receiver Operating Characteristics</h3><ul><li>True Positive Rate (Recall / Sensitivity) vs False Positive Rate (1-Specificity)<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/33911326-3EBD-4DF9-9875-B75F287E30D0.png" /></li></ul><h3 id="bias-variance-tradeoff">Bias-Variance Tradeoff</h3><ul><li><p>Bias refers to the amount of error that is introduced by approximating a real-life problem, which may be extremely complicated, by a simple model. If Bias is high, and/or if the algorithm performs poorly even on your training data, try adding more features, or a more flexible model.</p></li><li><p>Variance is the amount our model’s prediction would change when using a different training data set. High: Remove features, or obtain more data.</p></li></ul><h3 id="goodness-of-fit-r2">Goodness of Fit = R^2</h3><ul><li>1.0 - sum_of_squared_errors / total_sum_of_squares(y)</li></ul><h3 id="mean-squared-error-mse">Mean Squared Error (MSE)</h3><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/06091448-C605-4DEA-9650-D71A77C710C8.png" /></p><ul><li>The mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors or deviations—that is, the difference between the estimator and what is estimated.</li></ul></li></ul><h3 id="error-rate">Error Rate</h3><ul><li><p>The proportion of mistakes made if we apply out estimate model function the the training observations in a classification setting.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/6D6D7323-715D-42F8-9B71-39BE839F2C4B.png" /></li></ul></li></ul><h2 id="motivation">Motivation</h2><h3 id="prediction">Prediction</h3><ul><li>When we are interested mainly in the predicted variable as a result of the inputs, but not on the each way of the inputs affect the prediction. In a real estate example, Prediction would answer the question of: Is my house over or under valued? Non-linear models are very good at these sort of predictions, but not great for inference because the models are much less interpretable.</li></ul><h3 id="inference">Inference</h3><ul><li>When we are interested in the way each one of the inputs affect the prediction. In a real estate example, Inference would answer the question of: How much would my house cost if it had a view of the sea? Linear models are more suited for inference because the models themselves are easier to understand than their non-linear counterparts.</li></ul><h1 id="machine-learning-process">Machine Learning Process</h1><h2 id="data">Data</h2><h3 id="find">Find</h3><h3 id="collect">Collect</h3><h3 id="explore">Explore</h3><h3 id="clean-features">Clean Features</h3><h3 id="impute-features">Impute Features</h3><h3 id="engineer-features">Engineer Features</h3><h3 id="select-features">Select Features</h3><h3 id="encode-features">Encode Features</h3><h3 id="build-datasets">Build Datasets</h3><ul><li>Machine Learning is math. In specific, performing Linear Algebra on Matrices. Our data values must be numeric.</li></ul><h2 id="model">Model</h2><h3 id="select-algorithm-based-on-question-and-data-available">Select Algorithm based on question and data available</h3><h2 id="cost-function">Cost Function</h2><h3 id="the-cost-function-will-provide-a-measure-of-how-far-my-algorithm-and-its-parameters-are-from-accurately-representing-my-training-data.">The cost function will provide a measure of how far my algorithm and its parameters are from accurately representing my training data.</h3><h3 id="sometimes-referred-to-as-cost-or-loss-function-when-the-goal-is-to-minimise-it-or-objective-function-when-the-goal-is-to-maximise-it.">Sometimes referred to as Cost or Loss function when the goal is to minimise it, or Objective function when the goal is to maximise it.</h3><h2 id="optimization">Optimization</h2><h3 id="having-selected-a-cost-function-we-need-a-method-to-minimise-the-cost-function-or-maximise-the-objective-function.-typically-this-is-done-by-gradient-descent-or-stochastic-gradient-descent.">Having selected a cost function, we need a method to minimise the Cost function, or maximise the Objective function. Typically this is done by Gradient Descent or Stochastic Gradient Descent.</h3><h2 id="tuning-1">Tuning</h2><h3 id="different-algorithms-have-different-hyperparameters-which-will-affect-the-algorithms-performance.-there-are-multiple-methods-for-hyperparameter-tuning-such-as-grid-and-random-search.">Different Algorithms have different Hyperparameters, which will affect the algorithms performance. There are multiple methods for Hyperparameter Tuning, such as Grid and Random search.</h3><h2 id="results-and-benchmarking">Results and Benchmarking</h2><h3 id="analyse-the-performance-of-each-algorithms-and-discuss-results.">Analyse the performance of each algorithms and discuss results.</h3><h3 id="are-the-results-good-enough-for-production">Are the results good enough for production?</h3><h3 id="is-the-ml-algorithm-training-and-inference-completing-in-a-reasonable-timeframe">Is the ML algorithm training and inference completing in a reasonable timeframe?</h3><h2 id="scaling">Scaling</h2><h3 id="how-does-my-algorithm-scale-for-both-training-and-inference">How does my algorithm scale for both training and inference?</h3><h2 id="deployment-and-operationalisation">Deployment and Operationalisation</h2><h3 id="how-can-feature-manipulation-be-done-for-training-and-inference-in-real-time">How can feature manipulation be done for training and inference in real-time?</h3><h3 id="how-to-make-sure-that-the-algorithm-is-retrained-periodically-and-deployed-into-production">How to make sure that the algorithm is retrained periodically and deployed into production?</h3><h3 id="how-will-the-ml-algorithms-be-integrated-with-other-systems">How will the ML algorithms be integrated with other systems?</h3><h2 id="infrastructure">Infrastructure</h2><h3 id="can-the-infrastructure-running-the-machine-learning-process-scale">Can the infrastructure running the machine learning process scale?</h3><h3 id="how-is-access-to-the-ml-algorithm-provided-rest-api-sdk">How is access to the ML algorithm provided? REST API? SDK?</h3><h3 id="is-the-infrastructure-appropriate-for-the-algorithm-we-are-running-cpus-or-gpus">Is the infrastructure appropriate for the algorithm we are running? CPU's or GPU's?</h3><h2 id="direction">Direction</h2><h3 id="saas---pre-built-machine-learning-models">SaaS - Pre-built Machine Learning models</h3><ul><li><p>Google Cloud</p><ul><li><p>Vision API</p></li><li><p>Speech API</p></li><li><p>Jobs API</p></li><li><p>Video Intelligence API</p></li><li><p>Language API</p></li><li><p>Translation API</p></li></ul></li><li><p>AWS</p><ul><li><p>Rekognition</p></li><li><p>Lex</p></li><li><p>Polly</p></li></ul></li><li><p>… many others</p></li></ul><h3 id="data-science-and-applied-machine-learning">Data Science and Applied Machine Learning</h3><ul><li><p>Google Cloud</p><ul><li>ML Engine</li></ul></li><li><p>AWS</p><ul><li>Amazon Machine Learning</li></ul></li><li><p>Tools: Jupiter / Datalab / Zeppelin</p></li><li><p>… many others</p></li></ul><h3 id="machine-learning-research">Machine Learning Research</h3><ul><li><p>Tensorflow</p></li><li><p>MXNet</p></li><li><p>Torch</p></li><li><p>… many others</p></li></ul><h2 id="question">Question</h2><h3 id="is-this-a-or-b">Is this A or B?</h3><ul><li>Classification</li></ul><h3 id="how-much-or-how-many-of-these">How much, or how many of these?</h3><ul><li>Regression</li></ul><h3 id="is-this-anomalous">Is this anomalous?</h3><ul><li>Anomaly Detection</li></ul><h3 id="how-can-these-elements-be-grouped">How can these elements be grouped?</h3><ul><li>Clustering</li></ul><h3 id="what-should-i-do-now">What should I do now?</h3><ul><li>Reinforcement Learning</li></ul><h1 id="machine-learning-mathematics">Machine Learning Mathematics</h1><h2 id="costlossmin-objectivemax-functions">Cost/Loss(Min) Objective(Max) Functions</h2><h3 id="intuition">Intuition</h3><ul><li><p>The cost function will tell us how right the predictions of our model and weight matrix are, and the choice of cost function will drive how much we care about how wrong each prediction is. For instance, a hinge loss will assume the difference between each incorrect prediction value is linear. Were we to square the hinge loss and use that as our cost function, we would be telling the system that being very wrong gets exponentially worse as we get away from the right prediction. Cross Entropy would offer a probabilistic approach.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/AAAF1D3A-8184-4843-A1E3-AC53E43315FC.png" /></li></ul></li></ul><h3 id="maximum-likelihood-estimation-mle">Maximum Likelihood Estimation (MLE)</h3><ul><li><p>Many cost functions are the result of applying Maximum Likelihood. For instance, the Least Squares cost function can be obtained via Maximum Likelihood. Cross-Entropy is another example.</p></li><li><p>The likelihood of a parameter value (or vector of parameter values), θ, given outcomes x, is equal to the probability (density) assumed for those observed outcomes given those parameter values, that is</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/A37BBE5F-E77F-411E-BA91-5A2D475063D0.png" /></li></ul></li><li><p>The natural logarithm of the likelihood function, called the log-likelihood, is more convenient to work with. Because the logarithm is a monotonically increasing function, the logarithm of a function achieves its maximum value at the same points as the function itself, and hence the log-likelihood can be used in place of the likelihood in maximum likelihood estimation and related techniques.</p></li><li><p>In general, for a fixed set of data and underlying statistical model, the method of maximum likelihood selects the set of values of the model parameters that maximizes the <a href="https://en.wikipedia.org/wiki/Likelihood_function" target="_blank" rel="noopener">likelihood function</a>. Intuitively, this maximizes the "agreement" of the selected model with the observed data, and for discrete random variables it indeed maximizes the probability of the observed data under the resulting distribution. Maximum-likelihood estimation gives a unified approach to estimation, which is <a href="https://en.wikipedia.org/wiki/Well_defined" target="_blank" rel="noopener">well-defined</a> in the case of the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noopener">normal distribution</a> and many other problems.</p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/396DE3E5-85C2-487D-9324-FB83FCC7F8FD.png" /></p></li><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/690903C2-BC9F-400F-877E-7B625F2A20BD.png" /></p></li><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/B8AA9D14-192E-4C93-A166-A429A293990C.png" /></p></li><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/2EE71F38-3B82-48E7-A8B8-44FC8B2A5805.png" /></p></li><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/B7F5DF41-7571-412D-81AD-4B683CC1812B.png" /></p></li></ul></li></ul><h3 id="cross-entropy">Cross-Entropy</h3><ul><li><p>Cross entropy can be used to define the loss function in machine learning and optimization. The true probability pi is the true label, and the given distribution qi is the predicted value of the current model.</p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/9E271C6A-6FBB-41FC-960B-4AA394E6EEA5.png" /></p></li><li><p>Cross-entropy error function and logistic regression<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/0397888B-C44B-4178-B1D5-F7FB2ED1F3EC.png" /></p></li></ul></li></ul><h3 id="logistic">Logistic</h3><ul><li><p>The logistic loss function is defined as:</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/8942D559-DDAA-4EE2-AD81-3D6DE9C1540C.png" /></li></ul></li></ul><h3 id="quadratic">Quadratic</h3><ul><li><p>The use of a quadratic loss function is common, for example when using least squares techniques. It is often more mathematically tractable than other loss functions because of the properties of variances, as well as being symmetric: an error above the target causes the same loss as the same magnitude of error below the target. If the target is t, then a quadratic loss function is:</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C2D73C61-1BAC-4146-B59C-2C6D75CAFCF6.png" /></li></ul></li></ul><h3 id="loss">0-1 Loss</h3><ul><li><ul><li><p>In <a href="https://en.wikipedia.org/wiki/Statistics" target="_blank" rel="noopener">statistics</a> and <a href="https://en.wikipedia.org/wiki/Decision_theory" target="_blank" rel="noopener">decision theory</a>, a frequently used loss function is the 0-1 loss function</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/4597CE60-7571-403E-98C5-B3087805A418.png" /></li></ul></li></ul></li></ul><h3 id="hinge-loss">Hinge Loss</h3><ul><li><p>The hinge loss is a loss function used for training classifiers. For an intended output t = ±1 and a classifier score y, the hinge loss of the prediction y is defined as:</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/B96B2BB2-CF51-4989-8BE7-1A825082D2D6.png" /></li></ul></li></ul><h3 id="exponential">Exponential</h3><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/329F57B1-378D-47B7-B536-0AD0F626A708.png" /></li></ul><h3 id="hellinger-distance">Hellinger Distance</h3><ul><li><p>It is used to quantify the similarity between two probability distributions. It is a type of f-divergence.</p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/A9DC5C23-CACF-429F-83B2-F432DA3B3F1A.png" /></p></li><li><p>To define the Hellinger distance in terms of <a href="https://en.wikipedia.org/wiki/Measure_theory" target="_blank" rel="noopener">measure theory</a>, let P and Q denote two <a href="https://en.wikipedia.org/wiki/Probability_measure" target="_blank" rel="noopener">probability measures</a> that are <a href="https://en.wikipedia.org/wiki/Absolute_continuity" target="_blank" rel="noopener">absolutely continuous</a> with respect to a third probability measure λ. The square of the Hellinger distance between P and Q is defined as the quantity</p></li></ul></li></ul><h3 id="kullback-leibler-divengence">Kullback-Leibler Divengence</h3><ul><li><p>Is a measure of how one probability distribution diverges from a second expected probability distribution. Applications include characterizing the relative (Shannon) entropy in information systems, randomness in continuous time-series, and information gain when comparing statistical models of inference.</p><ul><li><p>Discrete<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/FC311DB8-C4BD-4D96-A9B0-786CF4091DE7.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/19746786-7A83-4A0A-B8C2-38F7E7189DFE.png" /></li></ul></li></ul></li></ul><h3 id="itakurasaito-distance">Itakura–Saito distance</h3><ul><li><p>is a measure of the difference between an original spectrum P(ω) and an approximation<br />P^(ω) of that spectrum. Although it is not a perceptual measure, it is intended to reflect perceptual (dis)similarity.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/55037B97-44EC-4173-9D7E-2755F6648E9C.png" /></li></ul></li></ul><h3 id="httpsstats.stackexchange.comquestions154879a-list-of-cost-functions-used-in-neural-networks-alongside-applications">https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications</h3><h3 id="httpsen.wikipedia.orgwikiloss_functions_for_classification">https://en.wikipedia.org/wiki/Loss_functions_for_classification</h3><h2 id="probability">Probability</h2><h3 id="concepts">Concepts</h3><ul><li><p>Frequentist vs Bayesian Probability</p><ul><li><p>Frequentist</p><ul><li>Basic notion of probability: # Results / # Attempts</li></ul></li><li><p>Bayesian</p><ul><li>The probability is not a number, but a distribution itself.</li></ul></li><li><p>http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html</p></li></ul></li><li><p>Random Variable</p><ul><li><p>In <a href="https://en.wikipedia.org/wiki/Probability_and_statistics" target="_blank" rel="noopener">probability and statistics</a>, a random variable, random quantity, aleatory variable or stochastic variable is a <a href="https://en.wikipedia.org/wiki/Variable_(mathematics)" target="_blank" rel="noopener">variable</a> whose value is subject to variations due to chance (i.e. <a href="https://en.wikipedia.org/wiki/Randomness" target="_blank" rel="noopener">randomness</a>, in a mathematical sense). A random variable can take on a set of possible different values (similarly to other mathematical variables), each with an associated probability, in contrast to other mathematical variables.</p><ul><li><p>Expectation (Expected Value) of a Random Variable<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/2956137E-E540-471C-A34B-66BBE0507483.png" /></p><ul><li>Same, for continuous variables<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/54388388-46D3-4E97-A228-23669D4E1E88.png" /></li></ul></li></ul></li></ul></li><li><p>Independence</p><ul><li><p>Two <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)" target="_blank" rel="noopener">events</a> are independent, statistically independent, or stochastically independent if the occurrence of one does not affect the probability of the other.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/FE866A04-B684-4395-92EB-E73593004643.png" /></li></ul></li></ul></li><li><p>Conditionality</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/E07D7B09-0747-48C9-ADC6-87AA26B8D3BF.png" /></li></ul></li><li><p>Bayes Theorem (rule, law)</p><ul><li><p>Simple Form<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/870B8130-69C4-4DBD-9BCF-D8D96D3C7D77.png" /></p><ul><li>With Law of Total probability<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/E90A57EE-85B2-4601-BF52-1F71E557A13F.png" /></li></ul></li></ul></li><li><p>Marginalisation</p><ul><li><p>The marginal distribution of a <a href="https://en.wikipedia.org/wiki/Subset" target="_blank" rel="noopener">subset</a> of a collection of <a href="https://en.wikipedia.org/wiki/Random_variable" target="_blank" rel="noopener">random variables</a> is the <a href="https://en.wikipedia.org/wiki/Probability_distribution" target="_blank" rel="noopener">probability distribution</a> of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.</p><ul><li><p>Continuous<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/4D1F3F76-3341-47A5-96C1-9097E5C87A38.png" /></p><ul><li><p>Discrete<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/860CED1C-EA17-44D3-A99E-B696A87A92BF.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/7E9DE18D-616C-45BB-A0C2-02C7E469F034.png" /></li></ul></li></ul></li></ul></li></ul></li><li><p>Law of Total Probability</p><ul><li><p>Is a fundamental rule relating <a href="https://en.wikipedia.org/wiki/Marginal_probability" target="_blank" rel="noopener">marginal probabilities</a> to <a href="https://en.wikipedia.org/wiki/Conditional_probabilities" target="_blank" rel="noopener">conditional probabilities</a>. It expresses the total probability of an outcome which can be realized via several distinct events - hence the name.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/5F52537E-8AF1-42FA-8CB4-2B2549F3FDA7.png" /></li></ul></li></ul></li><li><p>Chain Rule</p><ul><li>Permits the calculation of any member of the <a href="https://en.wikipedia.org/wiki/Joint_distribution" target="_blank" rel="noopener">joint distribution</a> of a set of <a href="https://en.wikipedia.org/wiki/Random_variables" target="_blank" rel="noopener">random variables</a> using only <a href="https://en.wikipedia.org/wiki/Conditional_probabilities" target="_blank" rel="noopener">conditional probabilities</a>.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/4739C552-28D0-4FAB-80B1-10DC7BBE1014.png" /></li></ul></li><li><p>Bayesian Inference</p><ul><li>Bayesian inference derives the <a href="https://en.m.wikipedia.org/wiki/Posterior_probability" target="_blank" rel="noopener">posterior probability</a> as a <a href="https://en.m.wikipedia.org/wiki/Consequence_relation" target="_blank" rel="noopener">consequence</a> of two <a href="https://en.m.wikipedia.org/wiki/Antecedent_(logic)" target="_blank" rel="noopener">antecedents</a>, a <a href="https://en.m.wikipedia.org/wiki/Prior_probability" target="_blank" rel="noopener">prior probability</a> and a "<a href="https://en.m.wikipedia.org/wiki/Likelihood_function" target="_blank" rel="noopener">likelihood function</a>" derived from a <a href="https://en.m.wikipedia.org/wiki/Statistical_model" target="_blank" rel="noopener">statistical model</a> for the observed data. Bayesian inference computes the posterior probability according to <a href="https://en.m.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="noopener">Bayes' theorem</a>. It can be applied iteratively so to update the confidence on out hypothesis.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/5EFA0B04-EB55-4414-8DFF-69C42072527A.png" /></li></ul></li></ul><h2 id="distributions">Distributions</h2><h3 id="definition">Definition</h3><ul><li>Is a table or an equation that links each outcome of a statistical experiment with the probability of occurence. When Continuous, is is described by the Probability Density Function</li></ul><h3 id="types-density-function">Types (Density Function)</h3><ul><li><p>Normal (Gaussian)<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/6BAD212C-E812-4D94-887E-B8FC28594153.png" /></p><ul><li><p>Poisson<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/B3457C07-7876-49F4-9FDA-5516DECF2E65.png" /></p><ul><li>Uniform<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/CFF452C6-1F11-465E-BDE8-EA3B3D55251D.png" /></li></ul></li></ul></li><li><p>Bernoulli<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/8F02DF2E-0723-4EDA-83E1-04DEBB0A222F.png" /></p><ul><li><p>Gamma<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/F2C3B775-C53A-4AA9-A398-120FBDFF6EF3.png" /></p><ul><li>Binomial<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/FF9BC15A-3117-4FA4-B59D-9EBD6E46F3A6.png" /></li></ul></li></ul></li></ul><h3 id="cumulative-distribution-function-cdf">Cumulative Distribution Function (CDF)</h3><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/D6AD4AEC-161F-4A81-A996-50C936E3752B.png" /></li></ul><h2 id="information-theory">Information Theory</h2><h3 id="entropy">Entropy</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/E0EC20FC-0906-4B7C-A75F-27338A35CB48.png" /></p><ul><li><p>Entropy is a measure of unpredictability of information content.</p><ul><li>To evaluate a language model, we should measure how much surprise it gives us for real sequences in that language. For each real word encountered, the language model will give a probability p. And we use -log(p) to quantify the surprise. And we average the total surprise over a long enough sequence. So, in case of a 1000-letter sequence with 500 A and 500 B, the surprise given by the 1/3-2/3 model will be:<br />[-500<em>log(1/3) - 500</em>log(2/3)]/1000 = 1/2 * Log(9/2)<br />While the correct 1/2-1/2 model will give:<br />[-500<em>log(1/2) - 500</em>log(1/2)]/1000 = 1/2 * Log(8/2)<br />So, we can see, the 1/3, 2/3 model gives more surprise, which indicates it is worse than the correct model.<br />Only when the sequence is long enough, the average effect will mimic the expectation over the 1/2-1/2 distribution. If the sequence is short, it won't give a convincing result.</li></ul></li></ul><h3 id="cross-entropy-1">Cross Entropy</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/BCFC979D-F514-45F2-8543-8AFC4539CD08.png" /></p><ul><li>Cross entropy between two probability distributions p and q over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an "unnatural" probability distribution q, rather than the "true" distribution p.</li></ul><h3 id="joint-entropy">Joint Entropy</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/250ECB8A-F48D-4814-B542-2C3FC45B2127.png" /></p><h3 id="conditional-entropy">Conditional Entropy</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/97F11D13-2F43-499D-9E53-5CE038479F74.png" /></p><h3 id="mutual-information">Mutual Information</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/B0FFBB3D-70E6-4C13-AFEC-4E1E4F133926.png" /></p><h3 id="kullback-leibler-divergence">Kullback-Leibler Divergence</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/F669FC47-9F7C-45BB-9311-148E23624F68.png" /></p><h2 id="density-estimation-1">Density Estimation</h2><h3 id="mostly-non-parametric.-parametric-makes-assumptions-on-my-datarandom-variables-for-instance-that-they-are-normally-distributed.-non-parametric-does-not.">Mostly Non-Parametric. Parametric makes assumptions on my data/random-variables, for instance, that they are normally distributed. Non-parametric does not.</h3><h3 id="the-methods-are-generally-intended-for-description-rather-than-formal-inference">The methods are generally intended for description rather than formal inference</h3><h3 id="methods">Methods</h3><ul><li><p>Kernel Density Estimation<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/7886A650-E942-414E-B9C1-FF657BFA8738.png" /></p><ul><li><p>non-negative</p></li><li><p>it’s a type of PDF that it is symmetric</p></li><li><p>real-valued</p></li><li><p>symmetric</p></li><li><p>integral over function is equal to 1</p></li><li><p>non-parametric</p></li><li><p>calculates kernel distributions for every sample point, and then adds all the distributions</p></li><li><p>Uniform, Triangle, Quartic, Triweight, Gaussian, Cosine, others...</p></li></ul></li><li><p>Cubic Spline</p><ul><li>A cubic spline is a function created from cubic polynomials on each between-knot interval by pasting them together twice continuously differentiable at the knots.</li></ul></li></ul><h2 id="regularization">Regularization</h2><h3 id="l1-norm">L1 norm</h3><ul><li><p>Manhattan Distance</p><ul><li><p>L1-norm is also known as least absolute deviations (LAD), least absolute errors (LAE). It is basically minimizing the sum of the absolute differences (S) between the target value and the estimated values.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C8581E8F-5C6B-424E-839D-9A01C3BEAE53.png" /></li></ul></li><li><p>Intuitively, the L1 norm prefers a weight matrix which contains the larger number of zeros.</p></li></ul></li></ul><h3 id="l2-norm">L2 norm</h3><ul><li><p>Euclidean Distance</p><ul><li><p>L2-norm is also known as least squares. It is basically minimizing the sum of the square of the differences (S) between the target value and the estimated values:</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/7839524D-1CE8-4634-A5D3-8B493ADBF0CE.png" /></li></ul></li><li><p>Intuitively, the L2 norm prefers a weight matrix where the norm is distributed across all weight matrix entries.</p></li></ul></li></ul><h3 id="early-stopping">Early Stopping</h3><ul><li>Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit, and stop the algorithm then.</li></ul><h3 id="dropout">Dropout</h3><ul><li>Is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks. The term "dropout" refers to dropping out units (both hidden and visible) in a neural network</li></ul><h3 id="sparse-regularizer-on-columns">Sparse regularizer on columns</h3><ul><li><p>This regularizer defines an L2 norm on each column and an L1 norm over all columns. It can be solved by proximal methods.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/DF7A3A69-3945-4222-86DA-EF91B8FF6740.png" /></li></ul></li></ul><h3 id="nuclear-norm-regularization">Nuclear norm regularization</h3><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/5D348DC1-B376-4FCA-9FA5-F2C2E4697D84.png" /></li></ul><h3 id="mean-constrained-regularization">Mean-constrained regularization</h3><ul><li><p>This regularizer constrains the functions learned for each task to be similar to the overall average of the functions across all tasks. This is useful for expressing prior information that each task is expected to share similarities with each other task. An example is predicting blood iron levels measured at different times of the day, where each task represents a different person.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/AED450B9-7864-4B51-8554-0B9A8CBB92BE.png" /></li></ul></li></ul><h3 id="clustered-mean-constrained-regularization">Clustered mean-constrained regularization</h3><ul><li><p>This regularizer is similar to the mean-constrained regularizer, but instead enforces similarity between tasks within the same cluster. This can capture more complex prior information. This technique has been used to predict Netflix recommendations.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/4427EABD-9457-44F5-AE53-47D654CA898C.png" /></li></ul></li></ul><h3 id="graph-based-similarity">Graph-based similarity</h3><ul><li><p>More general than above, similarity between tasks can be defined by a function. The regularizer encourages the model to learn similar functions for similar tasks.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/B26E5AA5-905F-49BB-A492-F0D34378ACC2.png" /></li></ul></li></ul><h2 id="optimization-1">Optimization</h2><h3 id="gradient-descent">Gradient Descent</h3><ul><li>Is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point. If instead one takes steps proportional to the positive of the gradient, one approaches a local maximum of that function; the procedure is then known as gradient ascent.</li></ul><h3 id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h3><ul><li><p>Gradient descent uses total gradient over all examples per update, SGD updates after only 1 or few examples:</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/187B983B-A9BE-4B1C-8ACF-ACB40B0E5725.png" /></li></ul></li></ul><h3 id="mini-batch-stochastic-gradient-descent-sgd">Mini-batch Stochastic Gradient Descent (SGD)</h3><ul><li>Gradient descent uses total gradient over all examples per update, SGD updates after only 1 example</li></ul><h3 id="momentum">Momentum</h3><ul><li>Idea: Add a fraction v of previous update to current one. When the gradient keeps pointing in the same direction, this will<br />increase the size of the steps taken towards the minimum.</li></ul><h3 id="adagrad">Adagrad</h3><ul><li>Adaptive learning rates for each parameter</li></ul><h2 id="statistics">Statistics</h2><h3 id="measures-of-central-tendency">Measures of Central Tendency</h3><ul><li><p>Mean</p></li><li><p>Median</p><ul><li>Value in the middle or an ordered list, or average of two in middle.</li></ul></li><li><p>Mode</p><ul><li>Most Frequent Value</li></ul></li><li><p>Quantile</p><ul><li>Division of probability distributions based on contiguous intervals with equal probabilities. In short: Dividing observations numbers in a sample list equally.</li></ul></li></ul><h3 id="dispersion">Dispersion</h3><ul><li><p>Range</p></li><li><p>Medium Absolute Deviation (MAD)</p><ul><li>The average of the absolute value of the deviation of each value from the mean</li></ul></li><li><p>Inter-quartile Range (IQR)</p><ul><li>Three quartiles divide the data in approximately four equally divided parts</li></ul></li><li><p>Variance</p><ul><li><p>Definition</p><ul><li>The average of the squared differences from the Mean. Formally, is the expectation of the squared deviation of a random variable from its mean, and it informally measures how far a set of (random) numbers are spread out from their mean.</li></ul></li><li><p>Types</p><ul><li><p>Continuous<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/19DB13EA-7024-46CD-9404-64E8EA2850A4.png" /></p><ul><li>Discrete<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/C416473F-2CEC-4F12-8E9D-B0D7D1C686A6.png" /></li></ul></li></ul></li></ul></li><li><p>Standard Deviation</p><ul><li><p>sqrt(variance)<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/15CD2CF7-B982-4C9C-B69F-33D20657E7A2.png" /></p><ul><li><p>z-score/value/factor</p><ul><li>The signed number of <a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener">standard deviations</a> an observation or <a href="https://en.wikipedia.org/wiki/Data" target="_blank" rel="noopener">datum</a> is above the <a href="https://en.wikipedia.org/wiki/Mean" target="_blank" rel="noopener">mean</a>.</li></ul></li></ul></li></ul></li></ul><h3 id="relationship">Relationship</h3><ul><li><p>Covariance</p><ul><li><p>dot(de_mean(x), de_mean(y)) / (n - 1)<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/0C8FD4CE-AC05-4975-ABDD-B54BD11F8312.png" /></p><ul><li>A measure of how much two random variables change together. http://stats.stackexchange.com/questions/18058/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean</li></ul></li></ul></li><li><p>Correlation</p><ul><li><p>Pearson</p><ul><li>Benchmarks linear relationship, most appropriate for measurements taken from an interval scale, is a measure of the linear dependence between two variables<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/65EE6640-3536-4A5D-8935-020FDEA6FCDB.png" /></li></ul></li><li><p>Spearman</p><ul><li>Benchmarks monotonic relationship (whether linear or not), Spearman's coefficient is appropriate for both continuous and discrete variables, including ordinal variables.</li></ul></li><li><p>Kendall</p><ul><li><p>Is a <a href="https://en.wikipedia.org/wiki/Statistic" target="_blank" rel="noopener">statistic</a> used to measure the <a href="https://en.wikipedia.org/wiki/Ordinal_association" target="_blank" rel="noopener">ordinal association</a> between two measured quantities.</p></li><li><p>Contrary to the <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" target="_blank" rel="noopener">Spearman correlation</a>, the Kendall correlation is not affected by how far from each other ranks are but only by whether the ranks between observations are equal or not, and is thus only appropriate for <a href="https://en.wikipedia.org/wiki/Discrete_variable" target="_blank" rel="noopener">discrete variables</a> but not defined for <a href="https://en.wikipedia.org/wiki/Continuous_variable" target="_blank" rel="noopener">continuous variables</a>.</p></li></ul></li><li><p>Summary: Pearson’s r for two normally distributed variables // Spearman’s rho for ratio data, ordinal data, etc (rank-order correlation) // Kendall’s tau for ordinal variables</p></li></ul></li><li><p>Co-occurrence</p><ul><li>The results are presented in a matrix format, where the cross tabulation of two fields is a cell value. The cell value represents the percentage of times that the two fields exist in the same events.</li></ul></li></ul><h3 id="techniques">Techniques</h3><ul><li><p>Null Hypothesis</p><ul><li>Is a general statement or default position that there is no relationship between two measured phenomena, or no association among groups. The null hypothesis is generally assumed to be true until evidence indicates otherwise.</li></ul></li><li><p>p-value</p><ul><li><p>Five heads in a row Example</p><ul><li><p>This demonstrates that specifying a direction (on a symmetric test statistic) halves the p-value (increases the significance) and can mean the difference between data being considered significant or not.</p></li><li><p>Suppose a researcher flips a coin five times in a row and assumes a null hypothesis that the coin is fair. The test statistic of "total number of heads" can be one-tailed or two-tailed: a one-tailed test corresponds to seeing if the coin is biased towards heads, but a two-tailed test corresponds to seeing if the coin is biased either way. The researcher flips the coin five times and observes heads each time (HHHHH), yielding a test statistic of 5. In a one-tailed test, this is the upper extreme of all possible outcomes, and yields a p-value of (1/2)5 = 1/32 ≈ 0.03. If the researcher assumed a significance level of 0.05, this result would be deemed significant and the hypothesis that the coin is fair would be rejected. In a two-tailed test, a test statistic of zero heads (TTTTT) is just as extreme and thus the data of HHHHH would yield a p-value of 2×(1/2)5 = 1/16 ≈ 0.06, which is not significant at the 0.05 level.</p></li></ul></li><li><p>In this method, as part of experimental design, before performing the experiment, one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% and denoted as α. If the p-value is less than the chosen significance level (α), that suggests that the observed data is sufficiently inconsistent with the null hypothesis that the null hypothesis may be rejected. However, that does not prove that the tested hypothesis is true. For typical analysis, using the standard α = 0.05 cutoff, the null hypothesis is rejected when p &lt; .05 and not rejected when p &gt; .05. The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/031EBE1C-F064-4DB0-9DE7-CABBA8D17668.png" /></li></ul></li></ul></li><li><p>p-hacking</p><ul><li>The process of data mining involves automatically testing huge numbers of hypotheses about a single <a href="https://en.wikipedia.org/wiki/Data_set" target="_blank" rel="noopener">data set</a> by exhaustively searching for combinations of variables that might show a correlation. Conventional tests of <a href="https://en.wikipedia.org/wiki/Statistical_significance" target="_blank" rel="noopener">statistical significance</a> are based on the probability that an observation arose by chance, and necessarily accept some risk of mistaken test results, called the <a href="https://en.wikipedia.org/wiki/Statistical_significance" target="_blank" rel="noopener">significance</a>.</li></ul></li></ul><h3 id="central-limit-theorem">Central Limit Theorem</h3><ul><li><p>States that a random variable defined as the average of a large number of independent and identically distributed random variables is itself approximately normally distributed.</p><ul><li>http://blog.vctr.me/posts/central-limit-theorem.html</li></ul></li></ul><h3 id="experiments-and-tests">Experiments and Tests</h3><ul><li><p>Flow Chart of Commonly Used Stat Tests<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/0DDFCAD3-A0C9-4978-A0F1-B47872AC82B2.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/45D4572F-11EE-4280-A978-384D0E1D872A.png" /></li></ul></li><li><p>Research Question</p><ul><li><p>Research question (Q):</p><ul><li>Asks whether the independent variable has an effect: “If there is a change in the independent variable, will there also be a change in the dependent variable?”</li></ul></li><li><p>Null hypothesis (Ho):</p><ul><li>The assumption that there is no effect: “There is no change in the dependent variable when the independent variable changes.”</li></ul></li></ul></li><li><p>Types of variables</p><ul><li><p>Dependent variable is the measure of interest</p></li><li><p>Independent variable is manipulated to observe the effect on dependent variable</p></li><li><p>Controlled variables are materials, measurements and methods that don’t change</p></li></ul></li><li><p>Experiment design</p><ul><li><p>Between subjects: Each subject sees one and only one condition</p></li><li><p>Within subjects: Subjects see more than one or all conditions</p></li></ul></li><li><p>Testing reliability with p-values</p><ul><li><p>Most tests calculate a p-value measuring observation extremity</p></li><li><p>Compare to significance level threshold α</p></li><li><p>α is the probability of rejecting H0 given that it is true</p></li><li><p>Commonly use α of 5% or 1%</p></li></ul></li></ul><h2 id="linear-algebra">Linear Algebra</h2><h3 id="matrices">Matrices</h3><ul><li><p>Almost all Machine Learning algorithms use Matrix algebra in one way or another. This is a broad subject, too large to be included here in it’s full length. Here’s a start: https://en.wikipedia.org/wiki/Matrix_(mathematics)</p><ul><li><p>Basic Operations: Addition, Multiplication, Transposition</p></li><li><p>Transformations</p></li><li><p>Trace, Rank, Determinante, Inverse</p></li></ul></li></ul><h3 id="eigenvectors-and-eigenvalues">Eigenvectors and Eigenvalues</h3><ul><li><p>In <a href="https://en.wikipedia.org/wiki/Linear_algebra" target="_blank" rel="noopener">linear algebra</a>, an eigenvector or characteristic vector of a <a href="https://en.wikipedia.org/wiki/Linear_map" target="_blank" rel="noopener">linear transformation</a> T from a <a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" rel="noopener">vector space</a> V over a <a href="https://en.wikipedia.org/wiki/Field_(mathematics)" target="_blank" rel="noopener">field</a> F into itself is a non-zero <a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" rel="noopener">vector</a> that does not change its direction when that linear transformation is applied to it.</p><ul><li>http://setosa.io/ev/eigenvectors-and-eigenvalues/<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/877F41BA-7063-48C3-AA8C-26173DDA8DE4.png" /></li></ul></li></ul><h3 id="derivatives-chain-rule">Derivatives Chain Rule</h3><ul><li><p>Rule<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/A416F2D4-5106-41F7-8E5B-40B5E73EA434.png" /></p><ul><li>Leibniz Notation<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/D2FA6B8A-FA31-4015-87B8-5FDCC70A63F4.png" /></li></ul></li></ul><h3 id="jacobian-matrix">Jacobian Matrix</h3><ul><li><p>The <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" target="_blank" rel="noopener">matrix</a> of all first-order <a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" rel="noopener">partial derivatives</a> of a <a href="https://en.wikipedia.org/wiki/Vector-valued_function" target="_blank" rel="noopener">vector-valued function</a>. When the matrix is a <a href="https://en.wikipedia.org/wiki/Square_matrix" target="_blank" rel="noopener">square matrix</a>, both the matrix and its <a href="https://en.wikipedia.org/wiki/Determinant" target="_blank" rel="noopener">determinant</a> are referred to as the Jacobian in literature</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/4E2AA87B-6A9A-42C7-8C3E-C2B25E198D30.png" /></li></ul></li></ul><h3 id="gradient">Gradient</h3><ul><li><p>The gradient is a multi-variable generalization of the derivative. The gradient is a vector-valued function, as opposed to a derivative, which is scalar-valued.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/695F6632-0CA9-4AE7-9058-6F7E6DC780B4.png" /></li></ul></li></ul><h3 id="tensors">Tensors</h3><ul><li><p>For Machine Learning purposes, a Tensor can be described as a Multidimentional Matrix Matrix. Depending on the dimensions, the Tensor can be a Scalar, a Vector, a Matrix, or a Multidimentional Matrix.</p><ul><li><p>When measuring the forces applied to an infinitesimal cube, one can store the force values in a multidimensional matrix.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/1F2AE40B-6E5E-4501-AEB1-FFCAF145B311.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/7E0FE9AC-605D-4FB4-8790-DE3B05336F1F.png" /></li></ul></li></ul></li></ul><h3 id="curse-of-dimensionality">Curse of Dimensionality</h3><ul><li>When the dimensionality increases, the volume of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires statistical significance. In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality.</li></ul><h1 id="machine-learning-data-processing">Machine Learning Data Processing</h1><h2 id="feature-selection">Feature Selection</h2><h3 id="correlation">Correlation</h3><ul><li><p>Features should be uncorrelated with each other and highly correlated to the feature we’re trying to predict.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/87F7C9A2-8634-4E57-85E2-9B3C4B9D33F8.png" /></p><ul><li><p>Covariance</p><ul><li>A measure of how much two random variables change together. Math: dot(de_mean(x), de_mean(y)) / (n - 1)<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/0C8FD4CE-AC05-4975-ABDD-B54BD11F8312.png" /></li></ul></li></ul></li></ul><h3 id="dimensionality-reduction-1">Dimensionality Reduction</h3><ul><li><p>Principal Component Analysis (PCA)</p><ul><li><p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.</p><ul><li>Plot the variance per feature and select the features with the largest variance.</li></ul></li></ul></li><li><p>Singular Value Decomposition (SVD)</p><ul><li><p>SVD is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix (for example, a symmetric matrix with positive eigenvalues) to any m×n matrix via an extension of the polar decomposition. It has many useful applications in signal processing and statistics.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/53B97C2C-8826-477D-BC26-41CABEC4A42E.png" /></li></ul></li></ul></li></ul><h3 id="importance">Importance</h3><ul><li><p>Filter Methods</p><ul><li><p>Filter type methods select features based only on general metrics like the correlation with the variable to predict. Filter methods suppress the least interesting variables. The other variables will be part of a classification or a regression model used to classify or to predict data. These methods are particularly effective in computation time and robust to overfitting.</p><ul><li><p>Correlation</p></li><li><p>Linear Discriminant Analysis</p></li><li><p>ANOVA: Analysis of Variance</p></li><li><p>Chi-Square</p></li></ul></li></ul></li><li><p>Wrapper Methods</p><ul><li><p>Wrapper methods evaluate subsets of variables which allows, unlike filter approaches, to detect the possible interactions between variables. The two main disadvantages of these methods are : The increasing overfitting risk when the number of observations is insufficient. AND. The significant computation time when the number of variables is large.</p><ul><li><p>Forward Selection</p></li><li><p>Backward Elimination</p></li><li><p>Recursive Feature Ellimination</p></li><li><p>Genetic Algorithms</p></li></ul></li></ul></li><li><p>Embedded Methods</p><ul><li><p>Embedded methods try to combine the advantages of both previous methods. A learning algorithm takes advantage of its own variable selection process and performs feature selection and classification simultaneously.</p><ul><li><p>Lasso regression performs L1 regularization which adds penalty equivalent to absolute value of the magnitude of coefficients.</p></li><li><p>Ridge regression performs L2 regularization which adds penalty equivalent to square of the magnitude of coefficients.</p></li></ul></li></ul></li></ul><h2 id="feature-encoding">Feature Encoding</h2><h3 id="machine-learning-algorithms-perform-linear-algebra-on-matrices-which-means-all-features-must-be-numeric.-encoding-helps-us-do-this.">Machine Learning algorithms perform Linear Algebra on Matrices, which means all features must be numeric. Encoding helps us do this.</h3><h3 id="label-encoding">Label Encoding</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/397D4FCF-04A7-4D68-927F-D6414FA747FE.png" /></p><ul><li><p>One Hot Encoding<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/8F75FD12-E83A-4DE5-94ED-CDDD231E3E14.png" /></p><ul><li>In One Hot Encoding, make sure the encodings are done in a way that all features are linearly independent.</li></ul></li></ul><h2 id="feature-normalisation-or-scaling">Feature Normalisation or Scaling</h2><h3 id="section"></h3><ul><li><p>Since the range of values of raw data varies widely, in some <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener">machine learning</a> algorithms, objective functions will not work properly without <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)" target="_blank" rel="noopener">normalization</a>. Another reason why feature scaling is applied is that <a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="noopener">gradient descent</a> converges much faster with feature scaling than without it.</p></li><li><p>Methods</p><ul><li><p>Rescaling</p><ul><li><p>The simplest method is rescaling the range of features to scale the range in [0, 1] or [−1, 1].</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/044BC9F5-9D15-4A64-9529-63403036B623.png" /></li></ul></li></ul></li><li><p>Standardization</p><ul><li><p>Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C228CF35-C057-4DF4-BEC2-6A7CB7D1C92F.png" /></li></ul></li></ul></li><li><p>Scaling to unit length</p><ul><li><p>To scale the components of a feature vector such that the complete vector has length one.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/1452F430-91D5-4E1A-8021-3BA21B90AD83.png" /></li></ul></li></ul></li></ul></li></ul><h2 id="dataset-construction">Dataset Construction</h2><h3 id="training-dataset">Training Dataset</h3><ul><li><p>A set of examples used for learning</p><ul><li><ul><li>To fit the parameters of the classifier in the Multilayer Perceptron, for instance, we would use the training set to find the “optimal” weights when using back-progapation.</li></ul></li></ul></li></ul><h3 id="test-dataset">Test Dataset</h3><ul><li><p>A set of examples used only to assess the performance of a fully-trained classifier</p><ul><li>In the Multilayer Perceptron case, we would use the test to estimate the error rate after we have chosen the final model (MLP size and actual weights) After assessing the final model on the test set, YOU MUST NOT tune the model any further.</li></ul></li></ul><h3 id="validation-dataset">Validation Dataset</h3><ul><li><p>A set of examples used to tune the parameters of a classifier</p><ul><li>In the Multilayer Perceptron case, we would use the validation set to find the “optimal” number of hidden units or determine a stopping point for the back-propagation algorithm</li></ul></li></ul><h3 id="cross-validation-1">Cross Validation</h3><ul><li>One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.</li></ul><h2 id="feature-engineering">Feature Engineering</h2><h3 id="decompose">Decompose</h3><ul><li>Converting 2014-09-20T20:45:40Z into categorical attributes like hour_of_the_day, part_of_day, etc.</li></ul><h3 id="discretization">Discretization</h3><ul><li><p>Continuous Features</p><ul><li>Typically data is discretized into partitions of K equal lengths/width (equal intervals) or K% of the total data (equal frequencies).</li></ul></li><li><p>Categorical Features</p><ul><li>Values for categorical features may be combined, particularly when there’s few samples for some categories.</li></ul></li></ul><h3 id="reframe-numerical-quantities">Reframe Numerical Quantities</h3><ul><li>Changing from grams to kg, and losing detail might be both wanted and efficient for calculation</li></ul><h3 id="crossing">Crossing</h3><ul><li>Creating new features as a combination of existing features. Could be multiplying numerical features, or combining categorical variables. This is a great way to add domain expertise knowledge to the dataset.</li></ul><h2 id="feature-imputation">Feature Imputation</h2><h3 id="hot-deck">Hot-Deck</h3><ul><li>The technique then finds the first missing value and uses the cell value immediately prior to the data that are missing to impute the missing value.</li></ul><h3 id="cold-deck">Cold-Deck</h3><ul><li>Selects donors from another dataset to complete missing data.</li></ul><h3 id="mean-substitution">Mean-substitution</h3><ul><li>Another imputation technique involves replacing any missing value with the mean of that variable for all other cases, which has the benefit of not changing the sample mean for that variable.</li></ul><h3 id="regression-1">Regression</h3><ul><li>A regression model is estimated to predict observed values of a variable based on other variables, and that model is then used to impute values in cases where that variable is missing</li></ul><h3 id="some-libraries...">Some Libraries...</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/091E0B05-1B93-4959-B8C7-7E135A336EF7.png" /></p><h2 id="feature-cleaning">Feature Cleaning</h2><h3 id="missing-values">Missing values</h3><ul><li>One may choose to either omit elements from a dataset that contain missing values or to impute a value</li></ul><h3 id="special-values">Special values</h3><ul><li>Numeric variables are endowed with several formalized special values including ±Inf, NA and NaN. Calculations involving special values often result in special values, and need to be handled/cleaned</li></ul><h3 id="outliers">Outliers</h3><ul><li>They should be detected, but not necessarily removed. Their inclusion in the analysis is a statistical decision.</li></ul><h3 id="obvious-inconsistencies">Obvious inconsistencies</h3><ul><li>A person's age cannot be negative, a man cannot be pregnant and an under-aged person cannot possess a drivers license.</li></ul><h2 id="data-exploration">Data Exploration</h2><h3 id="variable-identification">Variable Identification</h3><ul><li>Identify Predictor (Input) and Target (output) variables. Next, identify the data type and category of the variables.</li></ul><h3 id="univariate-analysis">Univariate Analysis</h3><ul><li><p>Continuous Features</p><ul><li>Mean, Median, Mode, Min, Max, Range, Quartile, IQR, Variance, Standard Deviation, Skewness, Histogram, Box Plot</li></ul></li><li><p>Categorical Features</p><ul><li>Frequency, Histogram</li></ul></li></ul><h3 id="bi-variate-analysis">Bi-variate Analysis</h3><ul><li><p>Finds out the relationship between two variables.</p></li><li><p>Scatter Plot</p></li><li><p>Correlation Plot - Heatmap</p></li><li><ul><li><p>Two-way table</p><ul><li>We can start analyzing the relationship by creating a two-way table of count and count%.</li></ul></li><li><p>Stacked Column Chart</p></li><li><p>Chi-Square Test</p><ul><li>This test is used to derive the statistical significance of relationship between the variables.</li></ul></li><li><p>Z-Test/ T-Test</p></li><li><p>ANOVA</p></li></ul></li></ul><h2 id="data-types">Data Types</h2><h3 id="nominal---is-for-mutual-exclusive-but-not-ordered-categories.">Nominal - is for mutual exclusive, but not ordered, categories.</h3><h3 id="ordinal---is-one-where-the-order-matters-but-not-the-difference-between-values.">Ordinal - is one where the order matters but not the difference between values.</h3><h3 id="ratio---has-all-the-properties-of-an-interval-variable-and-also-has-a-clear-definition-of-0.0.">Ratio - has all the properties of an interval variable, and also has a clear definition of 0.0.</h3><h3 id="interval---is-a-measurement-where-the-difference-between-two-values-is-meaningful.">Interval - is a measurement where the difference between two values is meaningful.</h3><h3 id="section-1"></h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/F45BC780-34A4-4478-8204-361A57CAC7A4.png" /></p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/F3BE7BDA-CC8D-44E9-9586-3C4EA3B875B2.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/385CB279-89CD-4AD6-82E7-D80BAA9F2826.png" /></li></ul></li></ul><h1 id="machine-learning-models">Machine Learning Models</h1><h2 id="regression-2">Regression</h2><h3 id="linear-regression">Linear Regression</h3><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/B3C1808C-9C79-4E45-9AC6-A5685A5D8407.png" /></li></ul><h3 id="generalised-linear-models-glms">Generalised Linear Models (GLMs)</h3><ul><li><p>Is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.</p></li><li><p>Link Function</p><ul><li><p>Identity</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C5A62BA8-B2BB-4325-A5CC-ADBF498E685A.png" /></li></ul></li><li><p>Inverse</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/72E0D7A0-9E26-49E9-A540-18A69873BE47.png" /></li></ul></li><li><p>Logit</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/3B5287CE-BF34-4688-844F-57875F627F8A.png" /></li></ul></li></ul></li><li><p>Cost Function is found via Maximum Likelihood Estimation</p></li></ul><h3 id="locally-estimated-scatterplot-smoothing-loess">Locally Estimated Scatterplot Smoothing (LOESS)</h3><h3 id="ridge-regression">Ridge Regression</h3><h3 id="least-absolute-shrinkage-and-selection-operator-lasso">Least Absolute Shrinkage and Selection Operator (LASSO)</h3><h3 id="logistic-regression">Logistic Regression</h3><ul><li><p>Logistic Function<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/249C3E38-0B9A-4493-982C-CC26B7614B12.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/D75A0917-3A7D-441E-B18F-A51B087761D3.png" /></li></ul></li></ul><h2 id="bayesian">Bayesian</h2><h3 id="naive-bayes">Naive Bayes</h3><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/A1AD6FA2-19D3-4C06-A092-420D007E8E3E.png" /></p><ul><li>Naive Bayes Classifier. We neglect the denominator as we calculate for every class and pick the max of the numerator<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/1810007C-AE05-41BF-A70B-6FDA309289BC.png" /></li></ul><h3 id="multinomial-naive-bayes">Multinomial Naive Bayes</h3><h3 id="bayesian-belief-network-bbn">Bayesian Belief Network (BBN)</h3><h2 id="dimensionality-reduction-2">Dimensionality Reduction</h2><h3 id="principal-component-analysis-pca">Principal Component Analysis (PCA)</h3><h3 id="partial-least-squares-regression-plsr">Partial Least Squares Regression (PLSR)</h3><h3 id="principal-component-regression-pcr">Principal Component Regression (PCR)</h3><h3 id="partial-least-squares-discriminant-analysis">Partial Least Squares Discriminant Analysis</h3><h3 id="quadratic-discriminant-analysis-qda">Quadratic Discriminant Analysis (QDA)</h3><h3 id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3><h2 id="instance-based">Instance Based</h2><h3 id="k-nearest-neighbour-knn">k-nearest Neighbour (kNN)</h3><h3 id="learning-vector-quantization-lvq">Learning Vector Quantization (LVQ)</h3><h3 id="self-organising-map-som">Self-Organising Map (SOM)</h3><h3 id="locally-weighted-learning-lwl">Locally Weighted Learning (LWL)</h3><h2 id="decision-tree">Decision Tree</h2><h3 id="random-forest">Random Forest</h3><h3 id="classification-and-regression-tree-cart">Classification and Regression Tree (CART)</h3><h3 id="gradient-boosting-machines-gbm">Gradient Boosting Machines (GBM)</h3><h3 id="conditional-decision-trees">Conditional Decision Trees</h3><h3 id="gradient-boosted-regression-trees-gbrt">Gradient Boosted Regression Trees (GBRT)</h3><h2 id="clustering-2">Clustering</h2><h3 id="algorithms">Algorithms</h3><ul><li><p>Hierarchical Clustering</p><ul><li><p>Linkage</p><ul><li><p>complete</p></li><li><p>single</p></li><li><p>average</p></li><li><p>centroid</p></li></ul></li><li><p>Dissimilarity Measure</p><ul><li><p>Euclidean</p><ul><li>Euclidean distance or Euclidean metric is the "ordinary" straight-line distance between two points in Euclidean space.</li></ul></li><li><p>Manhattan</p><ul><li>The distance between two points measured along axes at right angles.</li></ul></li></ul></li></ul></li><li><p>k-Means</p><ul><li>How many clusters do we select?</li></ul></li><li><p>k-Medians</p></li><li><p>Fuzzy C-Means</p></li><li><p>Self-Organising Maps (SOM)</p></li><li><p>Expectation Maximization</p></li><li><p>DBSCAN</p></li></ul><h3 id="validation">Validation</h3><ul><li><p>Data Structure Metrics</p><ul><li><p>Dunn Index</p></li><li><p>Connectivity</p></li><li><p>Silhouette Width</p></li></ul></li><li><p>Stability Metrics</p><ul><li><p>Non-overlap APN</p></li><li><p>Average Distance AD</p></li><li><p>Figure of Merit FOM</p></li><li><p>Average Distance Between Means ADM</p></li></ul></li></ul><h2 id="neural-networks">Neural Networks</h2><h3 id="unit-neurons">Unit (Neurons)</h3><ul><li><p>A unit often refers to the activation function in a layer by which the inputs are transformed via a nonlinear activation function (for example by the logistic sigmoid function). Usually, a unit has several incoming connections and several outgoing connections.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/5697CF3A-4832-4849-98B9-3132500C6576.png" /></li></ul></li></ul><h3 id="input-layer">Input Layer</h3><ul><li>Comprised of multiple Real-Valued inputs. Each input must be linearly independent from each other.</li></ul><h3 id="hidden-layers">Hidden Layers</h3><ul><li><p>Layers other than the input and output layers. A layer is the highest-level building block in deep learning. A layer is a container that usually receives weighted input, transforms it with a set of mostly non-linear functions and then passes these values as output to the next layer.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/EB87C752-40AC-40E4-89BF-E85F3AA6AE97.png" /></li></ul></li></ul><h3 id="batch-normalization">Batch Normalization</h3><ul><li><p>Using mini-batches of examples, as opposed to one example at a time, is helpful in several ways. First, the gradient of the loss over a mini-batch is an estimate of the gradient over the training set, whose quality improves as the batch size increases. Second, computation over a batch can be much more efficient than m computations for individual examples, due to the parallelism afforded by the modern computing platforms.</p><ul><li>With SGD, the training proceeds in steps, and at each step we consider a mini- batch x1...m of size m. The mini-batch is used to approx- imate the gradient of the loss function with respect to the parameters.</li></ul></li></ul><h3 id="learning-rate">Learning Rate</h3><ul><li><p>Neural networks are often trained by gradient descent on the weights. This means at each iteration we use backpropagation to calculate the derivative of the loss function with respect to each weight and subtract it from that weight.</p><ul><li>However, if you actually try that, the weights will change far too much each iteration, which will make them “overcorrect” and the loss will actually increase/diverge. So in practice, people usually multiply each derivative by a small value called the “learning rate” before they subtract it from its corresponding weight.</li></ul></li><li><p>Tricks</p><ul><li><p>Simplest recipe: keep it fixed and use the same for all parameters.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/0FCF647C-94C1-42AA-B26D-BB5F5DB14248.png" /></li></ul></li><li><p>Better results by allowing learning rates to decrease Options:</p><ul><li><p>Reduce by 0.5 when validation error stops improving</p></li><li><p>Reduction by O(1/t) because of theoretical convergence guarantees, with hyper-parameters ε0 and τ and t is iteration numbers.</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/5100966F-881F-45C0-9D48-807D86657D02.png" /></li></ul></li><li><p>Better yet: No hand-set learning of rates by using AdaGrad</p></li></ul></li></ul></li></ul><h3 id="weight-initialization">Weight Initialization</h3><ul><li><p>All Zero Initialization</p><ul><li><p>In the ideal situation, with proper data normalization it is reasonable to assume that approximately half of the weights will be positive and half of them will be negative. A reasonable-sounding idea then might be to set all the initial weights to zero, which you expect to be the “best guess” in expectation.</p><ul><li>But, this turns out to be a mistake, because if every neuron in the network computes the same output, then they will also all compute the same gradients during back-propagation and undergo the exact same parameter updates. In other words, there is no source of asymmetry between neurons if their weights are initialized to be the same.</li></ul></li></ul></li><li><p>Initialization with Small Random Numbers</p><ul><li><p>Thus, you still want the weights to be very close to zero, but not identically zero. In this way, you can random these neurons to small numbers which are very close to zero, and it is treated as symmetry breaking. The idea is that the neurons are all random and unique in the beginning, so they will compute distinct updates and integrate themselves as diverse parts of the full network.</p><ul><li>The implementation for weights might simply drawing values from a normal distribution with zero mean, and unit standard deviation. It is also possible to use small numbers drawn from a uniform distribution, but this seems to have relatively little impact on the final performance in practice.</li></ul></li></ul></li><li><p>Calibrating the Variances</p><ul><li><p>One problem with the above suggestion is that the distribution of the outputs from a randomly initialized neuron has a variance that grows with the number of inputs. It turns out that you can normalize the variance of each neuron's output to 1 by scaling its weight vector by the square root of its fan-in (i.e., its number of inputs)</p><ul><li>This ensures that all neurons in the network initially have approximately the same output distribution and empirically improves the rate of convergence. The detailed derivations can be found from Page. 18 to 23 of the slides. Please note that, in the derivations, it does not consider the influence of ReLU neurons.</li></ul></li></ul></li></ul><h3 id="backpropagation">Backpropagation</h3><ul><li><p>Is a method used in artificial neural networks to calculate the error contribution of each neuron after a batch of data. It calculates the gradient of the loss function. It is commonly used in the gradient descent optimization algorithm. It is also called backward propagation of errors, because the error is calculated at the output and distributed back through the network layers.</p><ul><li><p>Neural Network taking 4 dimension vector representation of words.<br /><img src="https://2020.iosdevlog.com/2020/02/22/ds/76B7C54A-E48B-4D1B-A1CF-602F165D7C09.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/DB988698-5B05-4D61-8514-5DE7B085C286.png" /></li></ul></li></ul></li><li><p>In this method, we reuse partial derivatives computed for higher layers in lower layers, for efficiency.</p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/3DAD67C3-1FCB-475E-96B7-E2D2793A9FB6.png" /></p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/F6753EA8-E4DB-4409-978F-AB2BCC323032.png" /></p><ul><li><p><img src="https://2020.iosdevlog.com/2020/02/22/ds/4C67AB0A-2FB0-4B03-B9FA-E36203B3E37C.png" /></p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/F340BAA3-345D-4D1E-9A6A-761D6BCF4E1F.png" /></li></ul></li></ul></li></ul></li></ul></li></ul><h3 id="activation-functions">Activation Functions</h3><ul><li><p>Defines the output of that node given an input or set of inputs.</p></li><li><p>Types</p><ul><li><p>ReLU</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/B6CD5EBF-451C-4E1F-AA90-DFB9FD2165FE.png" /></li></ul></li><li><p>Sigmoid / Logistic</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/D54BBB93-EE9A-433D-99ED-7D4C82B94AD2.png" /></li></ul></li><li><p>Binary</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C2E4A20B-CE21-414D-82F6-D179E30C7572.png" /></li></ul></li><li><p>Tanh</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/FCECCABF-A68B-421E-8498-EDF2D313371B.png" /></li></ul></li><li><p>Softplus</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/C4BDC911-1EDC-44D1-AEFA-FDC64360BA6D.png" /></li></ul></li><li><p>Softmax</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/D42822B8-CE14-4B16-A24D-8151614F601D.png" /></li></ul></li><li><p>Maxout</p><ul><li><img src="https://2020.iosdevlog.com/2020/02/22/ds/9E4B97B9-A6DC-4F0D-8D8A-7030819525B1.png" /></li></ul></li><li><p>Leaky ReLU, PReLU, RReLU, ELU, SELU, and others.</p></li></ul></li></ul><p>参考：<a href="https://github.com/dformoso/machine-learning-mindmap" target="_blank" rel="noopener" class="uri">https://github.com/dformoso/machine-learning-mindmap</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/22/ds/Process.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Process&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="ML" scheme="https://2020.iosdevlog.com/tags/ML/"/>
    
      <category term="DS" scheme="https://2020.iosdevlog.com/tags/DS/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习算法的数学解析与Python实现》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/21/9787111642602/"/>
    <id>https://2020.iosdevlog.com/2020/02/21/9787111642602/</id>
    <published>2020-02-21T10:47:23.000Z</published>
    <updated>2020-02-21T12:52:56.826Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/1.jpg" alt="" /><figcaption>《机器学习算法的数学解析与Python实现》</figcaption></figure><p>书名：机器学习算法的数学解析与Python实现<br />作者：莫凡<br />出版社：机械工业出版社<br />出版时间：2020-01<br />ISBN：9787111642602</p><a id="more"></a><p>第1章首先介绍机器学习究竟是什么，特别是与“人工智能”“深度学习”这些经常在一起出现的术语究竟有什么关系，又有什么区别。本章也将对机器学习知识体系里的一些常用术语进行简要说明，如果读者此前并不了解机器学习，则可以通过本章了解相关背景知识。</p><p>第2章对当前机器学习算法常用的Python编程语言以及相关的Python库进行介绍，同时列举一些常用的功能。</p><p>第3章开始正式介绍机器学习算法，要介绍的第一款机器学习算法是线性回归，本章将对回归问题、线性模型和如何用线性模型解决回归问题，以及对机器学习解决问题的主要模式进行介绍。</p><p>从第4章开始，介绍当下机器学习应用最广的分类问题，第一款解决分类问题的算法是Logistic回归分类算法，即用线性模型结合Logistic函数解决分类问题。</p><p>第5章介绍KNN分类算法，这款算法不依赖太复杂的数学原理，因此一般被认为是最直观好懂的分类算法之一。</p><p>第6章介绍朴素贝叶斯分类算法，它基于贝叶斯公式设计，理论清晰、逻辑易懂，是一款典型的基于概率统计理论解决分类问题的机器学习算法。</p><p>第7章介绍决策树分类算法，这是一款很重要的算法，从思想到结构都对程序员非常友好，当前XGBoost等主流机器学习算法就是在决策树算法的基础上，结合集成学习方法设计而成的。</p><p>第8章介绍支持向量机分类算法，这是一款在学术界和工业界都有口皆碑的机器学习模型。在深度学习出现之前，支持向量机被视作最被看好的机器学习算法，能力强、理论美，也是本书中最为复杂的机器模型。</p><p>第9章介绍无监督学习的聚类问题，以及简单好懂的聚类算法——K-means聚类算法。</p><p>第10章介绍神经网络分类算法，当前大热的深度学习就是从神经网络算法这一支发展而来的，而且大量继承了神经网络的思想和结构，可以作为了解深度学习的预备。</p><p>第11章介绍集成学习方法，以及如何通过组合两个以上的机器学习模型来提升预测效果。</p><h2 id="第1章-机器学习概述">第1章 机器学习概述</h2><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/2.jpg" alt="" /><figcaption>人工智能、机器学习和深度学习三者是包含关系</figcaption></figure><h3 id="机器学习知识的三个需求层次">机器学习知识的三个需求层次</h3><ol type="1"><li>设计需求层次<ul><li>思想原理</li></ul></li><li>调用需求层次<ul><li>运行流程</li></ul></li><li>数学需求层次<ul><li>数学解析</li></ul></li></ol><p>“训练模型”</p><p>“训练” == “拟合”</p><p>算法</p><ul><li>数据结构算法<ul><li>算</li></ul></li><li>机器学习算法<ul><li>猜<ul><li>我猜是什么</li><li>我猜中没有</li></ul></li></ul></li></ul><h3 id="猜数字游戏">“猜数字”游戏</h3><p>裁判选定一个数字，接着参赛选手也报一个数字，裁判回答他猜大了或猜小了，不断重复这个过程，直到最后猜中。</p><table><thead><tr class="header"><th>猜数字</th><th>机器学习</th></tr></thead><tbody><tr class="odd"><td>参赛选手</td><td>算法模型</td></tr><tr class="even"><td>裁判回答</td><td>损失函数</td></tr></tbody></table><h3 id="拟合">拟合</h3><ul><li>欠拟合<ul><li>准确性不够</li></ul></li><li>过拟合<ul><li>泛化性不好</li></ul></li></ul><h3 id="机器学习的基本概念">机器学习的基本概念</h3><h4 id="术语">术语</h4><ul><li><p><strong>模型</strong><br />模型（Model）是机器学习的核心概念。如果认为编程有两大组成部分，即算法和数据结构，那么机器学习的两大组成部分就是模型和数据集。如果之前没有接触过相关概念，想必你现在很希望直观地理解什么是模型，但对模型给出一个简洁又严谨的定义并不容易，你可以认为它是某种机器学习算法在设定参数后的产物，它的作用和编程时用到的函数一样，可以根据某些输入得到某些输出。既然叫机器学习算法，不妨将它想象成一台机器，其上有很多旋钮，这些旋钮就是参数。机器本身是有输入和输出功能的，根据不同的旋钮组合，同一种输入可以产生不同的输出，而机器学习的过程就是找到合适的那组旋钮组合，通过输入得到你所希望的输出。</p></li><li><p><strong>数据集</strong><br />如果说机器学习的“机器”指的是模型，那么数据集就可以说是驱动着这台机器去“学习”的“燃料”。有些文献将数据集又分为训练集和测试集，其实它们的内容和形式并无差异，只是用在不同的地方：在训练模型阶段使用，就叫作训练集；在测试模型阶段使用，就叫作测试集。</p></li><li><p><strong>数据</strong><br />我们刚才提到了数据集，数据集就是数据的集合。在机器学习中，我们称一条数据为一个样本（Sample），形式类似一维数组。样本通常包含多个特征（Feature），如果是用于分类问题的数据集，还会包含类别（Class Label）信息，如果是回归问题的数据集，则会包含一个连续型的数值。</p></li><li><p><strong>特征</strong><br />这个术语又容易让你产生误解了。我们一般把可以作为人或事物特点的征象、标志等称作特征，譬如这个人鼻子很大，这就是特征，但在机器学习中，特征是某个对象的几个记录维度。我们都填写过个人信息表，特征就是这张表里的空格，如名字、性别、出生日期、籍贯等，一份个人信息表格可以看成一个样本，名字、籍贯这些信息就称作特征。前面说数据形式类似一维数组，那么特征就是数组的值。</p></li><li><p><strong>向量</strong><br />向量为线性代数术语，机器学习模型算法的运算均基于线性代数法则，不妨认为向量就是该类算法所对应的“数据结构”。一条样本数据就是以一个向量的形式输入模型的。一条监督学习数据的向量形式如下：</p><p>[特征X1值，特征X2值，…, Y1值]</p></li><li><p><strong>矩阵</strong><br />矩阵为线性代数术语，可以将矩阵看成由向量组成的数组，形式上也非常接近二维数组。前面所说的数据集，通常就是以矩阵的形式输入模型的，常见的矩阵形式如下：</p><p>[[特征X1值，特征X2值，…, Y1值]，<br />'[特征X1值，特征X2值，…, Y2值]，<br />…<br />[特征X1值，特征X2值，…, Yn值]]</p></li></ul><p>其实这个组织形式非常类似电子表格，不妨就以电子表格来对照理解。每一行就是一个样本，每一列就是一个特征维度，譬如某个数据集一共包括了7个样本，那就是有7行数据，每个样本又都有4个维度的特征，那就是每行数据有4列，用电子表格表示如图1-2所示，其中，A～D列为特征，E列为结果。</p><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/3.jpg" alt="" /><figcaption>用电子表格来表示机器学习的数据集矩阵</figcaption></figure><h4 id="常用函数">常用函数</h4><ul><li><strong>假设函数（Hypothesis Function）</strong></li></ul><p><span class="math display">\[H(x)\]</span></p><p>这里的 <span class="math inline">\(x\)</span> 可以简单理解成矩阵形式的数据，我们把数据“喂”给假设函数，假设函数就会返回一个结果，而这个结果正是机器学习所得到的预测结果。</p><ul><li><strong>损失函数（Loss Function）/ 目标函数</strong></li></ul><p><span class="math display">\[L(x)\]</span></p><p><span class="math inline">\(L\)</span> 代表 Loss，这里的 <span class="math inline">\(x\)</span> 是假设函数的预测结果。</p><p>函数返回值越大，表示结果偏差越大。</p><ul><li><strong>成本函数（Cost Function）</strong></li></ul><p><span class="math display">\[J(x)\]</span></p><p>这里的 <span class="math inline">\(x\)</span> 也是假设函数的预测结果。</p><p>函数返回值越大，表示偏差越大。</p><table><thead><tr class="header"><th>差别</th><th style="text-align: center;">损失函数</th><th style="text-align: center;">成本函数</th></tr></thead><tbody><tr class="odd"><td>对象</td><td style="text-align: center;">单个样本</td><td style="text-align: center;">整个数据集</td></tr><tr class="even"><td>角度</td><td style="text-align: center;">微观</td><td style="text-align: center;">宏观</td></tr></tbody></table><p>成本函数是由损失函数计算得到的。</p><p><span class="math inline">\(J(x) = Sum(L(x))\)</span></p><p>或者</p><p><span class="math inline">\(J(x) = Avg(L(x))\)</span></p><h4 id="机器学习的基本模式">机器学习的基本模式</h4><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/4.jpg" alt="" /><figcaption>假设函数产生的偏差驱动着机器学习模型不断优化</figcaption></figure><ul><li>数据</li><li>假设函数</li><li>损失函数</li></ul><h4 id="优化方法">优化方法</h4><p><span class="math display">\[ min(L(x)) \]</span></p><p><span class="math display">\[新参数值 = 旧参数值 - 损失值\]</span></p><p>牛顿法、拟牛顿法、共轭梯度法</p><p><strong>梯度下降（Gradient Descent）</strong>法是机器学习中常用的一种优化方法</p><p>梯度下降（Gradient Descent）法是机器学习中常用的一种优化方法，梯度是微积分学的术语，某个函数在某点的梯度指向该函数取得最大值的方向，那么它的反方向自然就是取得最小值的方向。所以只要对损失函数采用梯度下降法，让假设函数朝着梯度的负方向更新权值，就能达到令损失值最小化的效果。</p><p><strong>倒车</strong>:<br />1. 方向<br />1. 大小</p><ul><li>批量梯度下降（Batch Gradient Descent<ul><li>每次迭代都使用全部样本</li></ul></li><li>随机梯度下降（Stochastic Gradient Descent<ul><li>每次迭代只使用一个样本</li></ul></li></ul><p>因为需要计算的样本小，随机梯度下降的迭代速度更快，但更容易陷入局部最优，而不能达到全局最优点。</p><h3 id="机器学习问题分类">机器学习问题分类</h3><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/5.jpg" alt="" /><figcaption>机器学习问题具体类别的判断方法图</figcaption></figure><p>无监督学习（Unsupervised Learning）<br />有监督学习（Supervised Learning）</p><h3 id="常用的机器学习算法">常用的机器学习算法</h3><ol type="1"><li>线性回归算法<ul><li>这是最基本的机器学习算法，但麻雀虽小，五脏俱全，该算法称得上是机器学习算法界的“Hello World”程序，是用线性方法解决回归问题。</li></ul></li><li>Logistic回归分类算法<ul><li>这可谓是线性回归算法的“孪生兄弟”，其核心思想仍然是线性方法，但套了一件名为Logistic函数的“马甲”，使得其具有解决分类问题的能力。</li></ul></li><li>KNN分类算法<ul><li>该算法是本书介绍的分类算法中唯一一个不依赖数学或统计模型，纯粹依靠“生活经验”的算法，它通过“找最近邻”的思想解决分类问题，其核心思想和区块链技术中的共识机制有着深远的关系。</li></ul></li><li>朴素贝叶斯分类算法<ul><li>这是一套能够刷新你世界观的算法，它认为结果不是确定性的而是概率性的，你眼前所见的不过是概率最大的结果罢了。当然，算法是用来解决问题的，朴素贝叶斯分类算法解决的是分类问题。</li></ul></li><li>决策树分类算法<ul><li>如果程序员的思维逻辑能够用if-else来概括的话，决策树分类算法应该就是最接近程序员逻辑的机器学习算法。</li></ul></li><li>支持向量机分类算法<ul><li>如果说Logistic回归分类算法是最基本的线性分类算法，那么支持向量机则是线性分类算法的最高形式，同时也是最“数学”的一种机器学习算法。该算法使用一系列令人拍案叫绝的数学技巧，将线性不可分的数据点映射成线性可分，再用最简单的线性方法来解决问题。</li></ul></li><li>K-means聚类算法<ul><li>有监督学习是当前机器学习的一种主流方式，但样本标记需要耗费大量人工成本，容易出现样本累积规模庞大，但标记不足的问题。无监督学习则是一种无须依赖标记样本的机器学习算法，聚类算法就是其中具有代表性的一种，而K-means是聚类算法中的典型代表。</li></ul></li><li>神经网络分类算法<ul><li>神经网络就是由许多神经元连接所构成的网络，很多人认为该算法是一种仿生算法，模仿的对象正是我们的大脑。神经网络分类算法也是当下热门的深度学习算法的起点。</li></ul></li></ol><h4 id="机器学习算法的性能衡量指标">机器学习算法的性能衡量指标</h4><p>NFL定律（No Free Lunch Theorem，中文一般翻译为“没有免费午餐定律”）。</p><ul><li>TP:True Positive，预测结果为正类，且与事实相符，即事实为正类。</li><li>TN:True Negative，预测结果为负类，且与事实相符，即事实为负类。</li><li>FP:False Positive，预测结果为正类，但与事实不符，即事实为负类。</li><li>FN:False Negative，预测结果为负类，但与事实不符，即事实为正类。</li></ul><p>常用的指标</p><ul><li>准确率（Accuracy）</li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/6.jpg" alt="" /><figcaption>准确率</figcaption></figure><ul><li>精确率（Precision），又叫查准率</li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/7.jpg" alt="" /><figcaption>查准率</figcaption></figure><ul><li>召回率（Recall），又叫查全率</li></ul><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/8.jpg" alt="" /><figcaption>查全率</figcaption></figure><h3 id="数据对算法结果的影响">数据对算法结果的影响</h3><h4 id="数据决定了算法的能力上限">数据决定了算法的能力上限</h4><blockquote><p>数据决定了模型能够达到的上限，而算法只是逼近这个上限。</p></blockquote><h4 id="特征工程">特征工程</h4><p>机器学习模型正是从这些特征中进行学习，特征有多少价值，机器才能学多少价值。</p><h2 id="第2章-机器学习所需的环境">第2章 机器学习所需的环境</h2><h3 id="python-简介">Python 简介</h3><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/9.jpg" alt="" /><figcaption>Python官网首页</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/10.jpg" alt="" /><figcaption>Python下载页面</figcaption></figure><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip</span></span><br><span class="line">pip install library</span><br><span class="line"><span class="comment"># conda</span></span><br><span class="line">conda install library</span><br></pre></td></tr></table></figure><p>使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># library.a_class</span></span><br><span class="line"><span class="keyword">import</span> library</span><br><span class="line"><span class="comment"># lib.a_class</span></span><br><span class="line"><span class="keyword">import</span> libray <span class="keyword">as</span> lib</span><br><span class="line"><span class="comment"># a_class</span></span><br><span class="line"><span class="keyword">from</span> library <span class="keyword">import</span> a_class</span><br></pre></td></tr></table></figure><h3 id="numpy-简介">Numpy 简介</h3><p>Numpy是Python语言的科学计算支持库，提供了线性代数、傅里叶变换等非常有用的数学工具。Numpy是Python圈子里非常知名的基础库，即使你并不直接进行科学计算，但如图像处理等相关功能库，其底层实现仍需要数学工具进行支持，则需要首先安装Numpy库。</p><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/11.jpg" alt="" /><figcaption>Numpy官网首页</figcaption></figure><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U numpy</span><br></pre></td></tr></table></figure><p>使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/12.jpg" alt="" /><figcaption>Numpy常用函数功能表</figcaption></figure><h3 id="scikit-learn-简介">Scikit-Learn 简介</h3><p>正如机器学习中推荐使用Python语言，用Python语言使用机器学习算法时，推荐使用Scikit-Learn工具，或者应该反过来，现在机器学习推荐使用Python，正是因为Python拥有Scikit-Learn这样功能强大的支持包，它已经把底层的脏活、累活都默默完成了，让使用者能够将宝贵的注意力和精力集中在解决问题上，极大地提高了产出效率。</p><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/13.jpg" alt="" /><figcaption>Scikit-Learn官网首页</figcaption></figure><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip</span></span><br><span class="line">pip install -U scikit-learn</span><br><span class="line"><span class="comment"># conda</span></span><br><span class="line">conda install scikit-learn</span><br></pre></td></tr></table></figure><p>使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br></pre></td></tr></table></figure><p>调用机器学习算法也非常简单，Scikit-Learn库已经将算法按模型分类，查找起来非常方便。如线性回归算法可以从线性模型中找到，用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">model = linear_model.LinearRegression()</span><br></pre></td></tr></table></figure><p>Logistic回归算法也是依据线性模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">model =linear_model.LogisticRegression()</span><br></pre></td></tr></table></figure><p>类似的还有基于近邻模型的KNN算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line">model =NearestNeighbors()</span><br></pre></td></tr></table></figure><p>生成模型后，一般使用fit方法给模型“喂”数据及进行训练。完成训练的模型可以使用predict方法进行预测。<br />Scikit-Learn库对机器学习算法进行了高度封装，使用过程非常简单，只要根据格式填入数据即可，不涉及额外的数学运算操作，甚至可以说只要知道机器学习算法的名字和优劣，就能直接使用，非常便利。</p><h3 id="pandas简介">Pandas简介</h3><p>Pandas是Python语言中知名的数据处理库。数据是模型算法的燃料，也决定了算法能够达到的上限。一般在学习中接触的数据都十分规整，可以直接供模型使用。但实际上，从生产环境中采集得到的“野生”数据则需要首先进行数据清洗工作，最常见的如填充丢失字段值。数据清洗工作一般使用Pandas来完成，前文所提到的特征工程也可通过Pandas完成。</p><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/14.jpg" alt="" /><figcaption>Pandas官网首页</figcaption></figure><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip</span></span><br><span class="line">pip install -U pandas</span><br><span class="line"><span class="comment"># conda</span></span><br><span class="line">conda install pandas</span><br></pre></td></tr></table></figure><h4 id="pandas的基本用法">Pandas的基本用法</h4><p>Pandas针对数据处理的常用功能而设计，具有从不同格式的文件中读写数据的功能，使用Pandas进行一些统计操作特别便利。与Numpy类似，Pandas也有两个核心的数据类型，即Series和DataFrame。</p><ul><li>Series：一维数据，可以认为是一个统计功能增强版的List类型。</li><li>DataFrame：多维数据，由多个Series组成，不妨认为是电子表格里的Sheet。使用Pandas包很简单，只要import导入即可。业界习惯在导入时使用“pd”作为它的别名：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/15.jpg" alt="" /><figcaption>Pandas常用函数功能表</figcaption></figure><h2 id="第3章-线性回归算法">第3章 线性回归算法</h2><p>机器学习涉及的知识面很广，但总的来说有两条主线，</p><ul><li><strong>问题</strong></li><li><strong>模型</strong></li></ul><p><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/16.jpg" alt="16" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/17.jpg" alt="17" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/18.jpg" alt="18" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/19.jpg" alt="19" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/20.jpg" alt="20" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/21.jpg" alt="21" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/22.jpg" alt="22" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/23.jpg" alt="23" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/24.jpg" alt="24" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/25.jpg" alt="25" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/26.jpg" alt="26" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/27.jpg" alt="27" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/28.jpg" alt="28" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/29.jpg" alt="29" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/30.jpg" alt="30" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/31.jpg" alt="31" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/32.jpg" alt="32" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/33.jpg" alt="33" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/34.jpg" alt="34" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/35.jpg" alt="35" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/36.jpg" alt="36" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/37.jpg" alt="37" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/38.jpg" alt="38" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/39.jpg" alt="39" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/40.jpg" alt="40" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/41.jpg" alt="41" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/42.jpg" alt="42" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/43.jpg" alt="43" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/44.jpg" alt="44" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/45.jpg" alt="45" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/46.jpg" alt="46" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/47.jpg" alt="47" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/48.jpg" alt="48" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/49.jpg" alt="49" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/50.jpg" alt="50" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/51.jpg" alt="51" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/52.jpg" alt="52" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/53.jpg" alt="53" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/54.jpg" alt="54" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/55.jpg" alt="55" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/56.jpg" alt="56" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/57.jpg" alt="57" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/58.jpg" alt="58" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/59.jpg" alt="59" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/60.jpg" alt="60" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/61.jpg" alt="61" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/62.jpg" alt="62" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/63.jpg" alt="63" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/64.jpg" alt="64" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/65.jpg" alt="65" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/66.jpg" alt="66" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/67.jpg" alt="67" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/68.jpg" alt="68" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/69.jpg" alt="69" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/70.jpg" alt="70" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/71.jpg" alt="71" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/72.jpg" alt="72" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/73.jpg" alt="73" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/74.jpg" alt="74" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/75.jpg" alt="75" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/76.jpg" alt="76" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/77.jpg" alt="77" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/78.jpg" alt="78" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/79.jpg" alt="79" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/80.jpg" alt="80" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/81.jpg" alt="81" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/82.jpg" alt="82" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/83.jpg" alt="83" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/84.jpg" alt="84" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/85.jpg" alt="85" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/86.jpg" alt="86" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/87.jpg" alt="87" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/88.jpg" alt="88" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/89.jpg" alt="89" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/90.jpg" alt="90" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/91.jpg" alt="91" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/92.jpg" alt="92" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/93.jpg" alt="93" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/94.jpg" alt="94" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/95.jpg" alt="95" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/96.jpg" alt="96" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/97.jpg" alt="97" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/98.jpg" alt="98" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/99.jpg" alt="99" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/100.jpg" alt="100" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/101.jpg" alt="101" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/102.jpg" alt="102" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/103.jpg" alt="103" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/104.jpg" alt="104" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/105.jpg" alt="105" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/106.jpg" alt="106" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/107.jpg" alt="107" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/108.jpg" alt="108" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/109.jpg" alt="109" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/110.jpg" alt="110" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/111.jpg" alt="111" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/112.jpg" alt="112" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/113.jpg" alt="113" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/114.jpg" alt="114" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/115.jpg" alt="115" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/116.jpg" alt="116" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/117.jpg" alt="117" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/118.jpg" alt="118" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/119.jpg" alt="119" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/120.jpg" alt="120" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/121.jpg" alt="121" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/122.jpg" alt="122" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/123.jpg" alt="123" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/124.jpg" alt="124" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/125.jpg" alt="125" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/126.jpg" alt="126" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/127.jpg" alt="127" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/128.jpg" alt="128" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/129.jpg" alt="129" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/130.jpg" alt="130" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/131.jpg" alt="131" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/132.jpg" alt="132" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/133.jpg" alt="133" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/134.jpg" alt="134" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/135.jpg" alt="135" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/136.jpg" alt="136" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/137.jpg" alt="137" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/138.jpg" alt="138" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/139.jpg" alt="139" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/140.jpg" alt="140" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/141.jpg" alt="141" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/142.jpg" alt="142" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/143.jpg" alt="143" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/144.jpg" alt="144" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/145.jpg" alt="145" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/146.jpg" alt="146" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/147.jpg" alt="147" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/148.jpg" alt="148" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/149.jpg" alt="149" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/150.jpg" alt="150" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/151.jpg" alt="151" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/152.jpg" alt="152" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/153.jpg" alt="153" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/154.jpg" alt="154" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/155.jpg" alt="155" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/156.jpg" alt="156" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/157.jpg" alt="157" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/158.jpg" alt="158" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/159.jpg" alt="159" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/160.jpg" alt="160" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/161.jpg" alt="161" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/162.jpg" alt="162" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/163.jpg" alt="163" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/164.jpg" alt="164" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/165.jpg" alt="165" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/166.jpg" alt="166" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/167.jpg" alt="167" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/168.jpg" alt="168" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/169.jpg" alt="169" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/170.jpg" alt="170" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/171.jpg" alt="171" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/172.jpg" alt="172" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/173.jpg" alt="173" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/174.jpg" alt="174" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/175.jpg" alt="175" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/176.jpg" alt="176" /><br /><img src="https://2020.iosdevlog.com/2020/02/21/9787111642602/177.jpg" alt="177" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/21/9787111642602/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《机器学习算法的数学解析与Python实现》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：机器学习算法的数学解析与Python实现&lt;br /&gt;
作者：莫凡&lt;br /&gt;
出版社：机械工业出版社&lt;br /&gt;
出版时间：2020-01&lt;br /&gt;
ISBN：9787111642602&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="ML" scheme="https://2020.iosdevlog.com/tags/ML/"/>
    
      <category term="Math" scheme="https://2020.iosdevlog.com/tags/Math/"/>
    
      <category term="Python" scheme="https://2020.iosdevlog.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>hexo 数学公式 mathjax</title>
    <link href="https://2020.iosdevlog.com/2020/02/20/math/"/>
    <id>https://2020.iosdevlog.com/2020/02/20/math/</id>
    <published>2020-02-20T10:39:08.000Z</published>
    <updated>2020-02-20T14:30:52.289Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/20/math/1.png" alt="" /><figcaption>math</figcaption></figure><a id="more"></a><h2 id="更换渲染工具为-hexo-renderer-pandoc">更换渲染工具为 hexo-renderer-pandoc</h2><p>首先需要安装 pandoc</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install pandoc</span><br></pre></td></tr></table></figure><p>更换渲染工具为 hexo-renderer-pandoc</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-pandoc --save</span><br></pre></td></tr></table></figure><h2 id="hexo-renderer-mathjax"><code>hexo-renderer-mathjax</code></h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-math --save</span><br><span class="line">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure><p>在hexo 博客中的 <code>_config.yml</code> 中添加 hexo-math 插件</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">math:</span></span><br><span class="line">  <span class="symbol">engine:</span> <span class="string">'mathjax'</span> <span class="comment"># or 'katex'</span></span><br><span class="line">  <span class="symbol">mathjax:</span></span><br><span class="line">    <span class="symbol">src:</span> custom_mathjax_source</span><br><span class="line">    <span class="symbol">config:</span></span><br><span class="line">      <span class="comment"># MathJax config</span></span><br><span class="line">  <span class="symbol">katex:</span></span><br><span class="line">    <span class="symbol">css:</span> custom_css_source</span><br><span class="line">    <span class="symbol">js:</span> custom_js_source <span class="comment"># not used</span></span><br><span class="line">    <span class="symbol">config:</span></span><br><span class="line">      <span class="comment"># KaTeX config</span></span><br></pre></td></tr></table></figure><h2 id="硬换行">硬换行</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">pandoc:</span></span><br><span class="line">  <span class="symbol">extensions:</span></span><br><span class="line">    - <span class="string">"+hard_line_breaks"</span></span><br></pre></td></tr></table></figure><h2 id="打开-主题-的-mathjax-开关">打开 主题 的 mathjax 开关</h2><p><code>vim themes/landscape/_config.yml</code> 文件，找到 <code>mathjax</code> 位置, 设置为以下</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MathJax Support</span></span><br><span class="line"><span class="symbol">mathjax:</span></span><br><span class="line">  <span class="symbol">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="symbol">per_page:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="在每一个博客中都打开-mathjax-开关">在每一个博客中都打开 mathjax 开关</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"><span class="symbol">title:</span> <span class="number">2020</span></span><br><span class="line"><span class="symbol">date:</span> <span class="number">2020</span>-<span class="number">02</span>-<span class="number">20</span> <span class="number">18</span><span class="symbol">:</span><span class="number">39</span><span class="symbol">:</span>08</span><br><span class="line"><span class="symbol">tags:</span></span><br><span class="line">    - tag1</span><br><span class="line">    - tag2</span><br><span class="line"><span class="symbol">categories:</span></span><br><span class="line">    - parent</span><br><span class="line">    - child</span><br><span class="line"><span class="symbol">mathjax:</span> <span class="literal">true</span></span><br><span class="line">---</span><br></pre></td></tr></table></figure><h2 id="重新生成">重新生成</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><h2 id="测试">测试</h2><p><span class="math inline">\(h(\theta) = \alpha\)</span></p><p><span class="math display">\[\begin{array}{l}{u_{i} \leftarrow\left[u_{i}-\gamma_{t}\left(\lambda-\left(y_{t}-w^{\top} \Phi\left(x_{t}\right)\right) \Phi_{i}\left(x_{t}\right)\right)\right]_{+}} \\{v_{i} \leftarrow\left[v_{i}-\gamma_{t}\left(\lambda+\left(y_{t}-w_{t}^{\top} \Phi\left(x_{t}\right)\right) \Phi_{i}\left(x_{t}\right)\right)\right]_{+}}\end{array}\]</span></p><p><span class="math display">\[f^{\prime}\left(x_{0}\right)=\lim _{\Delta x \rightarrow 0} \frac{f\left(x_{0}+\Delta x\right)-f\left(x_{0}\right)}{\Delta x}\]</span></p><p><span class="math display">\[\begin{equation}w \leftarrow w-\gamma_{t}\left\{\begin{array}{ll}{\lambda w} &amp; {\text { if } y_{t} w^{\top} \Phi\left(x_{t}\right)&gt;1} \\{\lambda w-y_{t} \Phi\left(x_{t}\right)} &amp; {\text { otherwise }}\end{array}\right.\end{equation}\]</span></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/20/math/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;math&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://2020.iosdevlog.com/categories/math/"/>
    
    
      <category term="hexo" scheme="https://2020.iosdevlog.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>《大国崛起的新政治经济学》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/20/9787220098970/"/>
    <id>https://2020.iosdevlog.com/2020/02/20/9787220098970/</id>
    <published>2020-02-20T09:30:50.000Z</published>
    <updated>2020-02-20T14:07:00.017Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/20/9787220098970/1.jpg" alt="" /><figcaption>《大国崛起的新政治经济学》</figcaption></figure><p>作者：聂永有，殷凤等<br />出版社：四川人民出版社<br />出版时间：2016-09<br />ISBN：9787220098970</p><a id="more"></a><h2 id="中共十八届五中全会提出了五大发展理念">中共十八届五中全会，提出了五大发展理念</h2><ul><li>创新</li><li>协调</li><li>绿色</li><li>开放</li><li>共享</li></ul><p>500年来，在这个充满希望而又遍布危机的发展舞台上，相继出现了9个世界性大国</p><p>葡萄牙、西班牙、荷兰、</p><p>英国（工业革命）、法国</p><p>后来居上的</p><p>德国、日本、俄罗斯与美国</p><h2 id="拉动经济增长的三驾马车">拉动经济增长的三驾马车</h2><ol type="1"><li>消费</li><li>投资</li><li>净出口</li></ol><h2 id="为什么必须由市场而不是政府来决定资源的配置">为什么必须由市场而不是政府来决定资源的配置？</h2><p>这是由市场本身所具有的特定功能决定的。</p><ol type="1"><li>市场价格能够有效协调商品供求关系。</li><li>市场价格的自由涨跌可以有效引导资源配置。</li><li>市场价格机制能够有效提高经济效率。</li></ol><h2 id="政府的经济职能可概括为三个方面">政府的经济职能可概括为三个方面</h2><ol type="1"><li>提升经济效率，如管制行业垄断和不正当竞争行为，解决外部性问题，保障公共物品的供给和改善信息不对称问题等，也就是解决市场失灵问题。</li><li>促进社会公平，一般认为，市场能够有效促进效率，甚至产生马太效应，恶化社会公平问题，这时需要政府适当的干预，采用诸如税收和政府转移支付等收入再分配政策缩小贫富差异，改善这个社会的收入分配状况。</li><li>维持宏观经济稳定。</li></ol><h2 id="经济学家认为能影响经济增长率长期变动的因素可分为七个">经济学家认为，能影响经济增长率长期变动的因素可分为七个：</h2><ol type="1"><li>就业人数和年龄、性别构成；</li><li>包括非全日制工人在内的工时数；</li><li>就业人员的受教育程度；</li><li>资本存量；</li><li>资源配置改善；</li><li>规模经济的程度；</li><li>知识进步。</li></ol><p>其中，前四项可归结为生产要素的供给增长（前三项为劳动要素的增长，第四项为资本要素的增长）；<br />后三项是生产要素的生产率增长，也就是技术进步的贡献。</p><h2 id="大国创新之路有哪些共同规律">大国创新之路有哪些共同规律？</h2><ol type="1"><li>创新是大国崛起的重要驱动力。</li><li>创新成果转化和创新同等重要。</li><li>结合自身国情和发展阶段，采取适合本国的创新模式非常重要。</li><li>世界科技革命和产业大变革通常是新兴大国崛起的重要历史机遇。</li></ol><h2 id="创新需要怎样的生态环境">创新需要怎样的生态环境？</h2><ol type="1"><li>激励创新的制度，是创新的根本保证。</li><li>激励创新的金融支撑手段，是创新的重要推进剂。</li></ol><h2 id="中国产业发展和结构中存在哪些问题">中国产业发展和结构中存在哪些问题？</h2><ol type="1"><li>产能过剩。</li><li>现有产业规模较大但是实力不强。</li><li>第三产业增长非常快，但行业结构并不合理，发展水平滞后。</li><li>外向型产业大多处于全球产业链低端。</li></ol><h2 id="产业转型与升级的路在何方">产业转型与升级的路在何方？</h2><ol type="1"><li>化解产能过剩危机。</li><li>要加强企业自主创新，促进技术升级。</li><li>要结合地区比较优势，加快产业转移与承接，实现产业雁行模式的梯度发展。</li><li>在产业选择方面，要重点发展包括先进制造业在内的新兴产业，并促成新兴科技与传统产业的有机融合，实现新技术、新产品和新业态的发展。</li><li>完善和提升产业价值链。</li></ol><h2 id="如何发挥产业政策在中国产业转型升级中的作用">如何发挥产业政策在中国产业转型升级中的作用？</h2><ol type="1"><li>促进产业结构调整，</li><li>对产能过剩问题的关注和解决。</li></ol><h2 id="中国式的市场失灵是如何产生的">中国式的市场失灵是如何产生的？</h2><ol type="1"><li>从体制上来看，现行的行政管理体制、财税体制并不利于资源和环境的管理，也不利于资源税的改革。</li><li>从法律角度来看，中国并不缺少资源与环境保护的相关法律，但执行不力。</li><li>从经济角度来看，“中国式的市场失灵”更多是市场本身的问题。</li><li>资源与环境不能完全依靠市场，市场失灵在某种程度上是客观存在的，</li></ol><h2 id="如何跨越增长的极限实现绿色经济的转型">如何跨越增长的极限，实现绿色经济的转型？</h2><ol type="1"><li>中国需要建立与资源环境管理相适应的财税体系和法律制度。</li><li>要从全球的、多维度的、战略的眼光来看待资源治理与经济增长的关系。</li><li>中国必须通过绿色科技创新来跨越增长的极限。</li></ol><h2 id="开放历程大体经历了以下三个时期">开放历程大体经历了以下三个时期：</h2><ul><li>被动式对外开放<ul><li>从鸦片战争到新中国建立的109年间</li></ul></li><li>一边倒式的对外开放<ul><li>孤立封锁政策</li><li>“另起炉灶”和“一边倒”</li></ul></li><li>主动的对外开放。<ul><li>第一阶段：1978—1991年<ul><li>这是以沿海地区开放为重点的探索开放阶段，以重点开放沿海地区，建立经济特区并实行特殊优惠政策为主要特征。</li></ul></li><li>第二阶段：1992－2000年<ul><li>对外开放加速向纵深推进，全方位开放格局基本形成，是建立有中国特色社会主义市场经济体制的阶段。</li></ul></li><li>第三阶段：2001年至今<ul><li>经历了15年曲折与漫长的谈判后，2001年12月11日，我国正式成为世界贸易组织（WTO）成员。</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/20/9787220098970/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《大国崛起的新政治经济学》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;作者：聂永有，殷凤等&lt;br /&gt;
出版社：四川人民出版社&lt;br /&gt;
出版时间：2016-09&lt;br /&gt;
ISBN：9787220098970&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="中国" scheme="https://2020.iosdevlog.com/tags/%E4%B8%AD%E5%9B%BD/"/>
    
  </entry>
  
  <entry>
    <title>《线性代数的几何意义》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/20/algebra/"/>
    <id>https://2020.iosdevlog.com/2020/02/20/algebra/</id>
    <published>2020-02-20T07:12:11.000Z</published>
    <updated>2020-02-20T14:00:48.509Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/20/algebra/1.jpg" alt="" /><figcaption>algebra</figcaption></figure><p>作者: 任广千 / 谢聪 / 胡翠芳<br />出版社: 西安电子科技大学出版社<br />副标题: 图解线性代数<br />出版年: 2015-7-15<br />页数: 280<br />定价: 46.00元<br />装帧: 平装、四色印刷<br />ISBN: 9787560634548</p><a id="more"></a><p>代数英文是 <code>Algebra</code>，源于阿拉伯语，其本意是“结合在一起”的意思。</p><p>也就是说代数的功能是把 许多看似不相关的事物“结合在一起”，也就是进行抽象。</p><p>线性函数表现为直线，这只是几何意义。那么所谓“线性”的代数意义是什么呢?实际上，最基本 的意义只有两条:可加性和比例性。</p><ul><li>可加性: 即如果函数 <span class="math inline">\(f(x)\)</span> 是线性的，那么有:</li></ul><p><span class="math display">\[f(x1 +x2)= f(x1)+ f(x2)\]</span></p><p>一句话:和的函数等于函数的和。</p><ul><li>比例性: 也叫做齐次性、数乘性或均匀性，即如果函数 f (x)是线性的，那么有</li></ul><p><span class="math display">\[f(kx)=kf(x) \]</span></p><p>其中k是常数。</p><p>一句话:比例的函数等于函数的比例;或者说自变量缩放，函数也同等比例地缩放。</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/20/algebra/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;algebra&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;作者: 任广千 / 谢聪 / 胡翠芳&lt;br /&gt;
出版社: 西安电子科技大学出版社&lt;br /&gt;
副标题: 图解线性代数&lt;br /&gt;
出版年: 2015-7-15&lt;br /&gt;
页数: 280&lt;br /&gt;
定价: 46.00元&lt;br /&gt;
装帧: 平装、四色印刷&lt;br /&gt;
ISBN: 9787560634548&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Math" scheme="https://2020.iosdevlog.com/tags/Math/"/>
    
      <category term="Algebra" scheme="https://2020.iosdevlog.com/tags/Algebra/"/>
    
  </entry>
  
  <entry>
    <title>《东野圭吾作品：11字谜案》人物关系图</title>
    <link href="https://2020.iosdevlog.com/2020/02/19/9787020156047/"/>
    <id>https://2020.iosdevlog.com/2020/02/19/9787020156047/</id>
    <published>2020-02-19T03:34:10.000Z</published>
    <updated>2020-02-19T09:59:27.736Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/19/9787020156047/1.svg" alt="" /><figcaption>《东野圭吾作品：11字谜案》人物关系图</figcaption></figure><a id="more"></a><figure><img src="https://2020.iosdevlog.com/2020/02/19/9787020156047/2.jpg" alt="" /><figcaption>《东野圭吾作品：11字谜案》</figcaption></figure><p>东野圭吾作品：11字谜案<br />作者：[日]东野圭吾<br />译者：羊恩媺<br />出版社：人民文学出版社<br />出版时间：2020-01<br />ISBN：9787020156047</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/19/9787020156047/1.svg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《东野圭吾作品：11字谜案》人物关系图&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="东野圭吾" scheme="https://2020.iosdevlog.com/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch iOS</title>
    <link href="https://2020.iosdevlog.com/2020/02/18/PyTorch-iOS/"/>
    <id>https://2020.iosdevlog.com/2020/02/18/PyTorch-iOS/</id>
    <published>2020-02-18T14:30:04.000Z</published>
    <updated>2020-02-20T14:05:37.315Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/18/PyTorch-iOS/15.png" alt="" /><figcaption>小武</figcaption></figure><a id="more"></a><h2 id="xcode-reset">Xcode Reset</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">default delete com.apple.Xcode</span><br></pre></td></tr></table></figure><h2 id="ui">UI</h2><h2 id="cocoapods">CocoaPods</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pod init</span><br><span class="line">cat Podfile</span><br></pre></td></tr></table></figure><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Uncomment the next line to define a global platform for your project</span></span><br><span class="line">platform <span class="symbol">:ios</span>, <span class="string">'12.0'</span></span><br><span class="line"></span><br><span class="line">target <span class="string">'PyTorch_iOS'</span> <span class="keyword">do</span></span><br><span class="line">  <span class="comment"># Comment the next line if you don't want to use dynamic frameworks</span></span><br><span class="line">  use_frameworks!</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Pods for PyTorch_iOS</span></span><br><span class="line">  pod <span class="string">'LibTorch'</span>, <span class="string">'~&gt; 1.4.0'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="model">model</h2><p><code>trace_model.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">model = torchvision.models.mobilenet_v2(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.eval()</span><br><span class="line">example = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">traced_script_module = torch.jit.trace(model, example)</span><br><span class="line">traced_script_module.save(<span class="string">"model.pt"</span>)</span><br></pre></td></tr></table></figure><p>模型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget -c https://download.pytorch.org/models/mobilenet_v2-b0353104.pth</span><br><span class="line">cp mobilenet_v2-b0353104.pth /Users/iosdevlog/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth</span><br><span class="line">python trace_model.py</span><br></pre></td></tr></table></figure><p>拖动生成的 <code>model.pt</code> 到 <code>iOS</code> 项目。</p><h2 id="拍照相册">拍照/相册</h2><p><code>Info.plist</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>NSCameraUsageDescription<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">string</span>&gt;</span>Camera Usage Description<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">key</span>&gt;</span>NSPhotoLibraryUsageDescription<span class="tag">&lt;/<span class="name">key</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">string</span>&gt;</span>Photo Library Usage Description<span class="tag">&lt;/<span class="name">string</span>&gt;</span></span><br></pre></td></tr></table></figure><p>拍照/相册选择图片</p><h2 id="官文教程"><img src="https://pytorch.org/mobile/ios/" alt="官文教程" /></h2><p>要在 <code>iOS</code> 上开始使用 <code>PyTorch</code>，我们建议您浏览以下<a href="https://github.com/pytorch/ios-demo-app/tree/master/HelloWorld" target="_blank" rel="noopener">HelloWorld</a>。</p><h2 id="hello-world示例快速入门">HELLO WORLD示例快速入门<a href="https://pytorch.org/mobile/ios/#quickstart-with-a-hello-world-example" target="_blank" rel="noopener"></a></h2><p>HelloWorld是一个简单的图像分类应用程序，演示了如何在iOS上使用PyTorch C ++库。该代码用Swift编写，并使用Objective-C作为桥梁。</p><h3 id="模型准备">模型准备<a href="https://pytorch.org/mobile/ios/#model-preparation" target="_blank" rel="noopener"></a></h3><p>让我们从模型准备开始。如果您熟悉PyTorch，您可能应该已经知道如何训练和保存模型。如果您没有，我们将使用预先训练的图像分类模型<a href="https://pytorch.org/hub/pytorch_vision_mobilenet_v2/" target="_blank" rel="noopener">-MobileNet v2</a>，该模型已经包装在<a href="https://pytorch.org/docs/stable/torchvision/index.html" target="_blank" rel="noopener">TorchVision中</a>。要安装它，请运行以下命令。</p><blockquote><p>我们强烈建议您遵循<a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">Pytorch Github页面</a>在本地计算机上设置Python开发环境。</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torchvision</span><br></pre></td></tr></table></figure><p>成功安装TorchVision后，让我们导航到HelloWorld文件夹并运行<code>trace_model.py</code>。该脚本包含跟踪和保存可在移动设备上运行的<a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" target="_blank" rel="noopener">Torchscript模型</a>的代码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python trace_model.py</span><br></pre></td></tr></table></figure><p>如果一切正常，我们应该<code>model.pt</code>在<code>HelloWorld</code>文件夹中生成模型。现在将模型文件复制到我们的应用程序文件夹中<code>HelloWorld/model</code>。</p><blockquote><p>要了解有关TorchScript的更多详细信息，请访问<a href="https://pytorch.org/tutorials/advanced/cpp_export.html" target="_blank" rel="noopener">pytorch.org上的教程。</a></p></blockquote><h3 id="通过cocoapods安装libtorch">通过Cocoapods安装LibTorch<a href="https://pytorch.org/mobile/ios/#install-libtorch-via-cocoapods" target="_blank" rel="noopener"></a></h3><p>PyTorch C++库在<a href="https://cocoapods.org/" target="_blank" rel="noopener">Cocoapods中</a>可用，可以将其集成到我们的项目中，只需运行即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod install</span><br></pre></td></tr></table></figure><p>现在是时候<code>HelloWorld.xcworkspace</code>在XCode中打开，选择一个iOS模拟器并启动它（cmd + R）。如果一切正常，我们应该在模拟器屏幕上看到狼的图片以及预测结果。</p><p>我已经加了一张新图片。</p><figure><img src="https://2020.iosdevlog.com/2020/02/18/PyTorch-iOS/Simulator.png" alt="" /><figcaption>iOS 模拟器</figcaption></figure><h3 id="代码演练">代码演练<a href="https://pytorch.org/mobile/ios/#code-walkthrough" target="_blank" rel="noopener"></a></h3><p>在这一部分中，我们将逐步介绍代码。</p><h4 id="图片载入">图片载入<a href="https://pytorch.org/mobile/ios/#image-loading" target="_blank" rel="noopener"></a></h4><p>让我们从图像加载开始。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> image = <span class="type">UIImage</span>(named: <span class="string">"image.jpg"</span>)!</span><br><span class="line">imageView.image = image</span><br><span class="line"><span class="keyword">let</span> resizedImage = image.resized(to: <span class="type">CGSize</span>(width: <span class="number">224</span>, height: <span class="number">224</span>))</span><br><span class="line"><span class="keyword">guard</span> <span class="keyword">var</span> pixelBuffer = resizedImage.normalized() <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们首先从包中加载图像，然后将其调整为224x224。然后，我们将此<code>normalized()</code>类别方法称为归一化像素缓冲区。让我们仔细看看下面的代码。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> normalizedBuffer: [<span class="type">Float32</span>] = [<span class="type">Float32</span>](repeating: <span class="number">0</span>, <span class="built_in">count</span>: w * h * <span class="number">3</span>)</span><br><span class="line"><span class="comment">// normalize the pixel buffer</span></span><br><span class="line"><span class="comment">// see https://pytorch.org/hub/pytorch_vision_resnet/ for more detail</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">0</span> ..&lt; w * h &#123;</span><br><span class="line">    normalizedBuffer[i]             = (<span class="type">Float32</span>(rawBytes[i * <span class="number">4</span> + <span class="number">0</span>]) / <span class="number">255.0</span> - <span class="number">0.485</span>) / <span class="number">0.229</span> <span class="comment">// R</span></span><br><span class="line">    normalizedBuffer[w * h + i]     = (<span class="type">Float32</span>(rawBytes[i * <span class="number">4</span> + <span class="number">1</span>]) / <span class="number">255.0</span> - <span class="number">0.456</span>) / <span class="number">0.224</span> <span class="comment">// G</span></span><br><span class="line">    normalizedBuffer[w * h * <span class="number">2</span> + i] = (<span class="type">Float32</span>(rawBytes[i * <span class="number">4</span> + <span class="number">2</span>]) / <span class="number">255.0</span> - <span class="number">0.406</span>) / <span class="number">0.225</span> <span class="comment">// B</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>乍一看，这些代码可能看起来很奇怪，但是一旦我们理解了模型，它就会变得有意义。输入数据是形状为（3 x H x W）的3通道RGB图像，其中H和W至少应为224。图像必须加载到的范围内<code>[0, 1]</code>，然后使用<code>mean = [0.485, 0.456, 0.406]</code>和进行归一化<code>std = [0.229, 0.224, 0.225]</code>。</p><h4 id="torchscript模块">TorchScript模块<a href="https://pytorch.org/mobile/ios/#torchscript-module" target="_blank" rel="noopener"></a></h4><p>现在我们已经对输入数据进行了预处理，并且有了预先训练的TorchScript模型，下一步就是使用它们来运行谓词。为此，我们首先将模型加载到应用程序中。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="built_in">lazy</span> <span class="keyword">var</span> module: <span class="type">TorchModule</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> filePath = <span class="type">Bundle</span>.main.path(forResource: <span class="string">"model"</span>, ofType: <span class="string">"pt"</span>),</span><br><span class="line">        <span class="keyword">let</span> module = <span class="type">TorchModule</span>(fileAtPath: filePath) &#123;</span><br><span class="line">        <span class="keyword">return</span> module</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">fatalError</span>(<span class="string">"Can't find the model file!"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><p>请注意，<code>TorchModule</code>该类是的Objective-C包装器<code>torch::jit::script::Module</code>。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch::jit::script::<span class="type">Module</span> module = torch::jit::load(filePath.<span class="type">UTF8String</span>);</span><br></pre></td></tr></table></figure><p>由于Swift无法直接与C ++对话，因此我们必须使用Objective-C类作为桥梁，或者为C ++库创建C包装器。出于演示目的，我们将把所有内容包装在这个Objective-C类中。但是，我们正在努力为PyTorch提供Swift / Objective-C API包装器。敬请关注！</p><h4 id="运行推断">运行推断<a href="https://pytorch.org/mobile/ios/#run-inference" target="_blank" rel="noopener"></a></h4><p>现在该进行推断并获取结果了。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">guard</span> <span class="keyword">let</span> outputs = module.predict(image: <span class="type">UnsafeMutableRawPointer</span>(&amp;pixelBuffer)) <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，该<code>predict</code>方法只是一个Objective-C包装器。在后台，它调用C ++ <code>forward</code>函数。让我们看一下它是如何实现的。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">at::<span class="type">Tensor</span> tensor = torch::from_blob(imageBuffer, &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>&#125;, at::kFloat);</span><br><span class="line">torch::autograd::<span class="type">AutoGradMode</span> <span class="keyword">guard</span>(<span class="literal">false</span>);</span><br><span class="line">auto outputTensor = _impl.forward(&#123;tensor&#125;).toTensor();</span><br><span class="line">float* floatBuffer = outputTensor.data_ptr&lt;float&gt;();</span><br></pre></td></tr></table></figure><p>C ++函数<code>torch::from_blob</code>将从像素缓冲区创建输入张量。请注意，张量的形状<code>{1,3,224,224}</code>代表<code>NxCxWxH</code>我们在上一节中讨论的形状。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch::autograd::<span class="type">AutoGradMode</span> <span class="keyword">guard</span>(<span class="literal">false</span>);</span><br><span class="line">at::<span class="type">AutoNonVariableTypeMode</span> non_var_type_mode(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>以上两行告诉PyTorch引擎仅进行推断。这是因为默认情况下，PyTorch内置了对进行自动分化的支持，这也称为<a href="https://pytorch.org/docs/stable/notes/autograd.html" target="_blank" rel="noopener">autograd</a>。由于我们不进行手机培训，因此我们可以禁用自动毕业模式。</p><p>最后，我们可以调用此<code>forward</code>函数以获取输出张量并将其转换为<code>float</code>缓冲区。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto outputTensor = _impl.forward(&#123;tensor&#125;).toTensor();</span><br><span class="line">float* floatBuffer = outputTensor.data_ptr&lt;float&gt;();</span><br></pre></td></tr></table></figure><h3 id="收集结果">收集结果<a href="https://pytorch.org/mobile/ios/#collect-results" target="_blank" rel="noopener"></a></h3><p>输出张量是形状为1x1000的一维浮点数组，其中每个值表示从图像预测标签的置信度。下面的代码对数组进行排序，并检索前三个结果。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> zippedResults = <span class="built_in">zip</span>(labels.<span class="built_in">indices</span>, outputs)</span><br><span class="line"><span class="keyword">let</span> sortedResults = zippedResults.sorted &#123; $<span class="number">0.1</span>.floatValue &gt; $<span class="number">1.1</span>.floatValue &#125;.<span class="keyword">prefix</span>(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h3 id="pytorch演示应用">PyTorch演示应用<a href="https://pytorch.org/mobile/ios/#pytorch-demo-app" target="_blank" rel="noopener"></a></h3><p>对于更复杂的用例，我们建议您检查<a href="https://github.com/pytorch/ios-demo-app" target="_blank" rel="noopener">PyTorch演示应用程序</a>。该演示应用程序包含两个展示柜。一个运行量化模型的相机应用程序，可以实时预测来自设备后置相机的图像。还有一个基于文本的应用程序，它使用文本分类模型来根据输入字符串预测主题。</p><h2 id="从源代码构建pytorch-ios库">从源代码构建PYTORCH IOS库<a href="https://pytorch.org/mobile/ios/#build-pytorch-ios-libraries-from-source" target="_blank" rel="noopener"></a></h2><p>要跟踪iOS的最新更新，您可以从源代码构建PyTorch iOS库。</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https:<span class="comment">//github.com/pytorch/pytorch</span></span><br><span class="line">cd pytorch</span><br><span class="line"># <span class="keyword">if</span> you are updating an existing checkout</span><br><span class="line">git submodule sync</span><br><span class="line">git submodule update --<span class="keyword">init</span> --recursive</span><br></pre></td></tr></table></figure><blockquote><p>确保已<code>cmake</code>在本地计算机上正确安装了Python。我们建议您遵循<a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">Pytorch Github页面</a>来设置Python开发环境</p></blockquote><h3 id="为ios模拟器构建libtorch">为iOS模拟器构建LibTorch<a href="https://pytorch.org/mobile/ios/#build-libtorch-for-ios-simulators" target="_blank" rel="noopener"></a></h3><p>打开终端并导航到PyTorch根目录。运行以下命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BUILD_PYTORCH_MOBILE=1 IOS_PLATFORM=SIMULATOR ./scripts/build_ios.sh</span><br></pre></td></tr></table></figure><p>构建成功后，所有静态库和头文件将在 <code>build_ios/install</code></p><h3 id="为arm64设备构建libtorch">为arm64设备构建LibTorch<a href="https://pytorch.org/mobile/ios/#build-libtorch-for-arm64-devices" target="_blank" rel="noopener"></a></h3><p>打开终端并导航到PyTorch根目录。运行以下命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BUILD_PYTORCH_MOBILE=1 IOS_ARCH=arm64 ./scripts/build_ios.sh</span><br></pre></td></tr></table></figure><p>构建成功后，所有静态库和头文件将在 <code>build_ios/install</code></p><h3 id="xcode设置">XCode设置<a href="https://pytorch.org/mobile/ios/#xcode-setup" target="_blank" rel="noopener"></a></h3><p>在XCode中打开您的项目，将所有静态库以及头文件复制到您的项目中。导航到项目设置，将“ <strong>Header Search Paths</strong> ”值设置为刚复制的头文件的路径。</p><p>在构建设置中，搜索<strong>其他链接器标志</strong>。在下面添加自定义链接器标志</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-force_load $(PROJECT_DIR)/<span class="variable">$&#123;path-to-libtorch.a&#125;</span></span><br></pre></td></tr></table></figure><p>最后，通过选择“构建设置”，搜索“ <strong>启用位码”</strong>，然后将值设置为<strong>No</strong>，为目标禁用位码。</p><h3 id="api文件">API文件<a href="https://pytorch.org/mobile/ios/#api-docs" target="_blank" rel="noopener"></a></h3><p>当前，iOS框架直接使用Pytorch C ++前端API。可以在<a href="https://pytorch.org/cppdocs/" target="_blank" rel="noopener">这里</a>找到C ++文档。要了解更多信息，我们建议在PyTorch网页上浏览<a href="https://pytorch.org/tutorials/advanced/cpp_frontend.html" target="_blank" rel="noopener">C ++前端教程</a>。同时，我们正在努力为PyTorch提供Swift / Objective-C API包装器。</p><h3 id="定制版">定制版<a href="https://pytorch.org/mobile/ios/#custom-build" target="_blank" rel="noopener"></a></h3><p>从1.4.0开始，PyTorch支持自定义构建。现在，您可以构建PyTorch库，其中仅包含模型所需的运算符。为此，请按照以下步骤操作</p><p>1.确认您的PyTorch版本为1.4.0或更高版本。您可以通过检查的值来实现<code>torch.__version__</code>。</p><p>2.要转储模型中的运算符，请说<code>MobileNetV2</code>运行以下几行Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch, yaml</span><br><span class="line">model = torch.jit.load(<span class="string">'MobileNetV2.pt'</span>)</span><br><span class="line">ops = torch.jit.export_opnames(model)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'MobileNetV2.yaml'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> output:</span><br><span class="line">    yaml.dump(ops, output)</span><br></pre></td></tr></table></figure><p>在上面的代码段中，您首先需要加载ScriptModule。然后，使用<code>export_opnames</code>来返回ScriptModule及其子模块的运算符名称的列表。最后，将结果保存在yaml文件中。</p><p>3.要使用准备好的yaml运算符列表在本地运行iOS构建脚本，请将从最后一步生成的yaml文件传递到环境变量中<code>SELECTED_OP_LIST</code>。同样在自变量中，指定<code>BUILD_PYTORCH_MOBILE=1</code>以及平台/架构类型。以arm64构建为例，命令应为：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECTED_OP_LIST=MobileNetV2.yaml BUILD_PYTORCH_MOBILE=1 IOS_ARCH=arm64 ./scripts/build_ios.sh</span><br></pre></td></tr></table></figure><p>4.构建成功后，您可以按照上面的<a href="https://pytorch.org/mobile/ios/#xcode-setup" target="_blank" rel="noopener">XCode Setup</a>部分将结果库集成到项目中。</p><p>5.最后一步是在运行之前添加一行C ++代码<code>forward</code>。这是因为默认情况下，JIT将对运算符进行一些优化（例如，融合），这可能会破坏我们从模型中转储的操作的一致性。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch::jit::<span class="function">GraphOptimizerEnabledGuard <span class="title">guard</span><span class="params">(<span class="literal">false</span>)</span></span>;</span><br></pre></td></tr></table></figure><h2 id="问题与贡献">问题与贡献<a href="https://pytorch.org/mobile/ios/#issues-and-contribution" target="_blank" rel="noopener"></a></h2><p>如果您有任何疑问或想为PyTorch做出贡献，请随时提出问题或打开请求请求以取得联系。</p><p>PyTorch iOS 官方：</p><p><a href="https://github.com/pytorch/ios-demo-app" target="_blank" rel="noopener" class="uri">https://github.com/pytorch/ios-demo-app</a></p><p>带拍照和相册的源码：</p><p><a href="https://github.com/Game2020/PyTorch_iOS" target="_blank" rel="noopener" class="uri">https://github.com/Game2020/PyTorch_iOS</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/18/PyTorch-iOS/15.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;小武&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/categories/DL/"/>
    
    
      <category term="PyTorch" scheme="https://2020.iosdevlog.com/tags/PyTorch/"/>
    
      <category term="iOS" scheme="https://2020.iosdevlog.com/tags/iOS/"/>
    
  </entry>
  
  <entry>
    <title>《放学后》人物关系图</title>
    <link href="https://2020.iosdevlog.com/2020/02/18/9787544291224/"/>
    <id>https://2020.iosdevlog.com/2020/02/18/9787544291224/</id>
    <published>2020-02-17T16:22:29.000Z</published>
    <updated>2020-02-19T09:59:44.886Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/1.svg" alt="" /><figcaption>《放学后》人物关系图</figcaption></figure><a id="more"></a><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/2.jpg" alt="" /><figcaption>《放学后》</figcaption></figure><p>书名：放学后<br />作者：[日]东野圭吾<br />译者：赵峻<br />出版社：南海出版公司出版<br />时间：2017-09<br />ISBN：9787544291224</p><h2 id="更衣室">更衣室</h2><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/3.jpg" alt="" /><figcaption>更衣室简图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/4.jpg" alt="" /><figcaption>门</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/5.jpg" alt="" /><figcaption>北条雅美 推理</figcaption></figure><h2 id="体育节">体育节</h2><table><thead><tr class="header"><th>时间</th><th>事件</th></tr></thead><tbody><tr class="odd"><td>14:15</td><td>　来宾、教职员趣味赛跑</td></tr><tr class="even"><td>14:30</td><td>　三人拉力赛（一年级）</td></tr><tr class="odd"><td>14:45</td><td>　师生对抗障碍赛</td></tr><tr class="even"><td>15:00</td><td>　创编舞（三年级）</td></tr><tr class="odd"><td>15:20</td><td>　化装游行（运动社团）</td></tr></tbody></table><h2 id="更衣室解迷">更衣室解迷</h2><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/6.jpg" alt="" /><figcaption>更衣室解迷</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/18/9787544291224/7.jpg" alt="" /><figcaption>更衣室解迷</figcaption></figure><h2 id="动机">动机</h2><blockquote><p>“对她们来说，最重要的应该是美丽、纯粹、真实的东西，比如友情、爱情，也可能是自己的身体或容貌。很多时候，更抽象的回忆或梦想对她们来说也很重要。反过来说，她们最憎恨企图破坏或者从她们手中夺</p></blockquote><ol type="1"><li>自慰被看到的惠美<ul><li>惠美&amp;惠子：杀害看到学生自慰的老师</li></ul></li><li>“他根本不知道头发被剪得乱七八糟对我来说有多痛苦。”-阳子<ul><li>阳子：试图诬陷教导主任性骚扰</li></ul></li><li>“我没有给过她任何东西,甚至一直都是从她身上予取予求,更夺走了她的自由、快乐, 以及孩子。” 冷漠的丈夫和婚姻给她的精神带来的创痛。-裕美子<ul><li>裕美子&amp;情夫：杀害前岛的</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/18/9787544291224/1.svg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《放学后》人物关系图&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="东野圭吾" scheme="https://2020.iosdevlog.com/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"/>
    
  </entry>
  
  <entry>
    <title>《Python深度学习：基于PyTorch》 读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/17/pytorch/"/>
    <id>https://2020.iosdevlog.com/2020/02/17/pytorch/</id>
    <published>2020-02-17T05:28:39.000Z</published>
    <updated>2020-02-17T15:42:20.233Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/1.jpg" alt="" /><figcaption>《Python深度学习：基于PyTorch》</figcaption></figure><p>书名：Python深度学习：基于PyTorch<br />作者：吴茂贵，郁明敏，杨本法，李涛，张粤磊<br />出版社：机械工业出版社<br />出版时间：2019-10<br />ISBN：9787111637172</p><a id="more"></a><p>建议初学者选择PyTorch的主要依据是：</p><ol type="1"><li>PyTorch是动态计算图，其用法更贴近Python，并且，PyTorch与Python共用了许多Numpy的命令，可以降低学习的门槛，比TensorFlow更容易上手。</li><li>PyTorch需要定义网络层、参数更新等关键步骤，这非常有助于理解深度学习的核心；而Keras虽然也非常简单，且容易上手，但封装粒度很粗，隐藏了很多关键步骤。</li><li>PyTorch的动态图机制在调试方面非常方便，如果计算图运行出错，马上可以跟踪问题。PyTorch的调试与Python的调试一样，通过断点检查就可以高效解决问题。</li><li>PyTorch的流行度仅次于TensorFlow。而最近一年，在GitHub关注度和贡献者的增长方面，PyTorch跟TensorFlow基本持平。PyTorch的搜索热度持续上涨，加上FastAI的支持，PyTorch将受到越来越多机器学习从业者的青睐。</li></ol><p>本书特点</p><ul><li>内容选择<ul><li>广泛涉猎</li><li>精讲</li><li>注重实战</li></ul></li><li>内容安排<ul><li>简单实例开始</li><li>循序渐进</li></ul></li><li>表达形式<ul><li>让图说话</li><li>一张好图胜过千言万语</li></ul></li></ul><p>本书内容</p><ol type="1"><li>PyTorch基础</li><li>深度学习基本原理</li><li>实战部分</li></ol><h2 id="基础篇">基础篇</h2><h3 id="pytorch基础">PyTorch基础</h3><h3 id="第1章-numpynumerical-python基础">第1章 Numpy（Numerical Python）基础</h3><p>基本的对像</p><ol type="1"><li>ndarray（N-dimensional Array Object）<ul><li>单一数据类型的多维数组</li></ul></li><li>ufunc（UniversalFunction Object）<ul><li>对数组进行处理的函数</li></ul></li></ol><p>Numpy的主要特点：</p><ol type="1"><li>ndarray，快速节省空间的多维数组，提供数组化的算术运算和高级的广播功能。</li><li>使用标准数学函数对整个数组的数据进行快速运算，且不需要编写循环。</li><li>读取/写入磁盘上的阵列数据和操作存储器映像文件的工具。</li><li>线性代数、随机数生成和傅里叶变换的能力。</li><li>集成C、C++、Fortran代码的工具。</li></ol><h4 id="生成numpy数组">1.1 生成Numpy数组</h4><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/3.jpg" alt="" /><figcaption>Tab</figcaption></figure><h5 id="从已有数据中创建数组">从已有数据中创建数组</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.array(l)</span><br></pre></td></tr></table></figure><h5 id="利用random模块生成数组">利用random模块生成数组</h5><table><thead><tr class="header"><th>函数</th><th>描述</th></tr></thead><tbody><tr class="odd"><td>np.random.random</td><td>生成0到1之间的随机数</td></tr><tr class="even"><td>np.random.uniform</td><td>生成均匀分布的随机数</td></tr><tr class="odd"><td>np.random.randn</td><td>生成标准正态的随机数</td></tr><tr class="even"><td>np.random.randint</td><td>生成随机的整数</td></tr><tr class="odd"><td>np.random.normal</td><td>生成正态分布</td></tr><tr class="even"><td>np.random.shuffle</td><td>随机打乱顺序</td></tr><tr class="odd"><td>np.random.seed</td><td>设置随机数种子</td></tr><tr class="even"><td>random._sample</td><td>生成随机的浮点数</td></tr></tbody></table><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/4.jpg" alt="" /><figcaption>np.random模块常用函数</figcaption></figure><h5 id="创建特定形状的多维数组">创建特定形状的多维数组</h5><table><thead><tr class="header"><th>函数</th><th>描述</th></tr></thead><tbody><tr class="odd"><td>np.zeros((3, 4))</td><td>创建3×4的元素全为0的数组</td></tr><tr class="even"><td>np.ones((3, 4))</td><td>创建3×4的元素全为1的数组</td></tr><tr class="odd"><td>np.empty( (2, 3))</td><td>创建2×3的空数组,空数据中的值并不为0,而是未初始化的垃圾值</td></tr><tr class="even"><td>np.zeros.like(darr)</td><td>以 darr相同维度创建元素全为0数组</td></tr><tr class="odd"><td>np.ones.like(darr)</td><td>以 narr相同维度创建元素全为1数组</td></tr><tr class="even"><td>np.empty.like(ndarr)</td><td>以 darr相同维度创建空数组</td></tr><tr class="odd"><td>np.eye(5)</td><td>该函数用于创建一个5×5的矩阵,对角线为1,其余为0</td></tr><tr class="even"><td>np.full((3, 5), 666)</td><td>创建3×5的元素全为666的数组,666为指定值</td></tr></tbody></table><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/5.jpg" alt="" /><figcaption>Numpy数组创建函数</figcaption></figure><h5 id="利用arangelinspace函数生成数组">利用arange、linspace函数生成数组`````</h5><p>arange是numpy模块中的函数，其格式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">help(np.arange)</span><br><span class="line">arange([start,] stop[, step,], dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>其中start与stop用来指定范围，step用来设定步长。在生成一个ndarray时，start默认为0，步长step可为小数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linspace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, retstep=<span class="literal">False</span>, dtype=<span class="literal">None</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h4 id="获取元素">1.2 获取元素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">2020</span>)</span><br><span class="line">nd11 = np.random.random([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取指定位置的数据,获取第4个元素</span></span><br><span class="line">nd11[<span class="number">3</span>]</span><br><span class="line"><span class="comment"># 截取一段数据</span></span><br><span class="line">nd11[<span class="number">3</span>:<span class="number">6</span>]</span><br><span class="line"><span class="comment"># 截取固定间隔数据</span></span><br><span class="line">nd11[<span class="number">1</span>:<span class="number">6</span>:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 倒序取数</span></span><br><span class="line">nd11[::<span class="number">-2</span>]</span><br><span class="line"><span class="comment"># 截取一个多维数组的一个区域内数据</span></span><br><span class="line">nd12 = np.arange(<span class="number">25</span>).reshape([<span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">nd12[<span class="number">1</span>:<span class="number">31</span>:<span class="number">3</span>]</span><br><span class="line"><span class="comment"># 截取一个多维数组中,数值在一个值域之內的数据</span></span><br><span class="line">nd12[(nd12 &gt; <span class="number">3</span>) &amp; (nd12 &lt; <span class="number">10</span>)]</span><br><span class="line"><span class="comment"># 截取多维数组中,指定的行,如读取第2,3行</span></span><br><span class="line">nd12[[<span class="number">1</span>, <span class="number">2</span>]]  <span class="comment"># 或nd12[1:3,:]</span></span><br><span class="line"><span class="comment"># 并截取多维数组中,指定的列,如读取第2,3列</span></span><br><span class="line">nd12[:, <span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/6.jpg" alt="" /><figcaption>获取多维数组中的元素</figcaption></figure><p>随机抽取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> random <span class="keyword">as</span> nr</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="number">1</span>, <span class="number">25</span>, dtype=float)</span><br><span class="line">c1 = nr.choice(a, size=(<span class="number">3</span>, <span class="number">4</span>))  <span class="comment"># size指定输出数组形状</span></span><br><span class="line">c2 = nr.choice(a, size=(<span class="number">3</span>, <span class="number">4</span>), replace=<span class="literal">False</span>)  <span class="comment"># replace缺省为True，即可重复抽取。</span></span><br><span class="line"><span class="comment"># 下式中参数p指定每个元素对应的抽取概率，缺省为每个元素被抽取的概率相同。</span></span><br><span class="line">c3 = nr.choice(a, size=(<span class="number">3</span>, <span class="number">4</span>), p=a / np.sum(a))</span><br><span class="line">print(<span class="string">"随机可重复抽取"</span>)</span><br><span class="line">print(c1)</span><br><span class="line">print(<span class="string">"随机但不重复抽取"</span>)</span><br><span class="line">print(c2)</span><br><span class="line">print(<span class="string">"随机但按制度概率抽取"</span>)</span><br><span class="line">print(c3)</span><br></pre></td></tr></table></figure><h4 id="numpy的算术运算">1.3 Numpy的算术运算</h4><h5 id="对应元素相乘">1.3.1 对应元素相乘</h5><p><code>np.info(np.multiply)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multiply(x1, x2, /, out=<span class="literal">None</span>, *, where=<span class="literal">True</span>, casting=<span class="string">'same_kind'</span>, order=<span class="string">'K'</span>, dtype=<span class="literal">None</span>, subok=<span class="literal">True</span>[, signature, extobj])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">-1</span>, <span class="number">4</span>]])</span><br><span class="line">B = np.array([[<span class="number">2</span>, <span class="number">0</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">A*B</span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line">array([[<span class="number">2</span>,  <span class="number">0</span>],</span><br><span class="line">       [<span class="number">-3</span>, <span class="number">16</span>]])</span><br><span class="line"><span class="comment"># 或另一种表示方法</span></span><br><span class="line">np.multiply(A, B)</span><br><span class="line"><span class="comment"># 运算结果也是</span></span><br><span class="line">array([[<span class="number">2</span>,  <span class="number">0</span>],</span><br><span class="line">       [<span class="number">-3</span>, <span class="number">16</span>]])</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/7.jpg" alt="" /><figcaption>对应元素相乘示意图</figcaption></figure><h5 id="点积运算">1.3.2 点积运算</h5><p>点积运算（Dot Product）又称为内积</p><p><code>np.info(np.dot)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dot(a, b, out=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X1=np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">X2=np.array([[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]])</span><br><span class="line">X3=np.dot(X1,X2)</span><br><span class="line">print(X3)</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/8.jpg" alt="" /><figcaption>矩阵的点积示意图，对应维度的元素个数需要保持一致</figcaption></figure><h4 id="数组变形">1.4 数组变形</h4><h5 id="更改数组的形状">1.4.1 更改数组的形状</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/9.jpg" alt="" /><figcaption>Numpy中改变向量形状的一些函数</figcaption></figure><h5 id="合并数组">1.4.2 合并数组</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/10.jpg" alt="" /><figcaption>Numpy数组合并方法</figcaption></figure><ol type="1"><li>append、concatenate以及stack都有一个axis参数，用于控制数组的合并方式是按行还是按列。</li><li>对于append和concatenate，待合并的数组必须有相同的行数或列数（满足一个即可）。</li><li>stack、hstack、dstack，要求待合并的数组必须具有相同的形状（shape）。</li></ol><h4 id="批量处理">1.5 批量处理</h4><ol type="1"><li>得到数据集</li><li>随机打乱数据</li><li>定义批大小</li><li>批处理数据集</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 生成10000个形状为2X3的矩阵</span></span><br><span class="line">data_train = np.random.randn(<span class="number">10000</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 这是一个3维矩阵，第1个维度为样本数，后两个是数据形状</span></span><br><span class="line">print(data_train.shape)</span><br><span class="line"><span class="comment"># (10000,2,3)</span></span><br><span class="line"><span class="comment"># 打乱这10000条数据</span></span><br><span class="line">np.random.shuffle(data_train)</span><br><span class="line"><span class="comment"># 定义批量大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># 进行批处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(data_train), batch_size):</span><br><span class="line">    x_batch_sum = np.sum(data_train[i:i+batch_size])</span><br><span class="line">    print(<span class="string">"第&#123;&#125;批次,该批次的数据之和:&#123;&#125;"</span>.format(i, x_batch_sum))</span><br></pre></td></tr></table></figure><p>【说明】批次从0开始，所以最后一个批次是9900。</p><h4 id="通用函数">1.6 通用函数</h4><p>ufunc是universalfunction的缩写，它是一种能对数组的每个元素进行操作的函数。</p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/11.jpg" alt="" /><figcaption>Numpy中的几个常用通用函数</figcaption></figure><h4 id="广播">1.7 广播</h4><p>Numpy的Universal functions中要求输入的数组shape是一致的，当数组的shape不相等时，则会使用广播机制。不过，调整数组使得shape一样，需要满足一定的规则，否则将出错。</p><p>这些规则可归纳为以下4条。</p><ol type="1"><li>让所有输入数组都向其中shape最长的数组看齐，不足的部分则通过在前面加1补齐，如：<ul><li>a：2×3×2</li><li>b：3×2</li><li>则b向a看齐，在b的前面加1，变为：1×3×2</li></ul></li><li>输出数组的shape是输入数组shape的各个轴上的最大值</li><li>如果输入数组的某个轴和输出数组的对应轴的长度相同或者某个轴的长度为1时，这个数组能被用来计算，否则出错</li><li>当输入数组的某个轴的长度为1时，沿着此轴运算时都用（或复制）此轴上的第一组值。</li></ol><p>广播在整个Numpy中用于决定如何处理形状迥异的数组，涉及的算术运算包括（+，-，*，/…）。</p><p>这些规则说得很严谨，但不直观，下面我们结合图形与代码来进一步说明。</p><p>目的：A+B，其中A为4×1矩阵，B为一维向量（3,）。</p><p>要相加，需要做如下处理：</p><ol type="1"><li>根据规则1，B需要向看齐，把B变为（1,3）</li><li>根据规则2，输出的结果为各个轴上的最大值，即输出结果应该为（4,3）矩阵，那么A如何由（4,1）变为（4,3）矩阵？B又如何由（1,3）变为（4,3）矩阵？</li><li>根据规则4，用此轴上的第一组值（要主要区分是哪个轴），进行复制（但在实际处理中不是真正复制，否则太耗内存，而是采用其他对象如ogrid对象，进行网格处理）即可，详细处理过程如图所示。</li></ol><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/12.jpg" alt="" /><figcaption>Numpy广播规则示意图</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.arange(<span class="number">0</span>, <span class="number">40</span>, <span class="number">10</span>).reshape(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">B = np.arange(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">print(<span class="string">"A矩阵的形状:&#123;&#125;,B矩阵的形状:&#123;&#125;"</span>.format(A.shape, B.shape))</span><br><span class="line">C = A+B</span><br><span class="line">print(<span class="string">"C矩阵的形状:&#123;&#125;"</span>.format(C.shape))</span><br><span class="line">print(C)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A矩阵的形状:(4, 1),B矩阵的形状:(3,)</span><br><span class="line">C矩阵的形状:(4, 3)</span><br><span class="line">[[ 0  1  2]</span><br><span class="line"> [10 11 12]</span><br><span class="line"> [20 21 22]</span><br><span class="line"> [30 31 32]]</span><br></pre></td></tr></table></figure><h3 id="第2章-pytorch基础">第2章 Pytorch基础</h3><h4 id="为何选择pytorch">2.1 为何选择Pytorch？</h4><p>PyTorch由4个主要的包组成：</p><ol type="1"><li><code>torch</code>：类似于Numpy的通用数组库，可将张量类型转换为torch.cuda.TensorFloat，并在GPU上进行计算。</li><li><code>torch.autograd</code>：用于构建计算图形并自动获取梯度的包。</li><li><code>torch.nn</code>：具有共享层和损失函数的神经网络库。</li><li><code>torch.optim</code>：具有通用优化算法（如SGD、Adam等）的优化包。</li></ol><h4 id="安装配置">2.2 安装配置</h4><p>参考 <a href="https://pytorch.org" target="_blank" rel="noopener" class="uri">https://pytorch.org</a> 就可以了。</p><h5 id="cpu版pytorch">2.2.1 CPU版Pytorch</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/13.jpg" alt="" /><figcaption>下载Anaconda界面</figcaption></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh</span><br><span class="line">sh Miniconda3-latest-MacOSX-x86_64.sh</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/14.jpg" alt="" /><figcaption>PyTorch安装界面</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure><p>当前最新版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.4.0</span><br></pre></td></tr></table></figure><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/15.jpg" alt="" /><figcaption>验证安装是否成功</figcaption></figure><h5 id="gpu版pytorch">2.2.2 GPU版Pytorch</h5><h6 id="安装nvidia驱动">安装NVIDIA驱动</h6><p><a href="https://www.nvidia.cn/Download/index.aspx?lang=cn" target="_blank" rel="noopener" class="uri">https://www.nvidia.cn/Download/index.aspx?lang=cn</a></p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/16.jpg" alt="" /><figcaption>NVIDIA的下载界面</figcaption></figure><p>安装完成后，在命令行输入 <code>nvidia-smi</code>，用来显示GPU卡的基本信息</p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/17.jpg" alt="" /><figcaption>显示GPU卡的基本信息</figcaption></figure><h6 id="安装cuda">安装CUDA</h6><p>CUDA（Compute Unified Device Architecture），是英伟达公司推出的一种基于新的并行编程模型和指令集架构的通用计算架构，它能利用英伟达GPU的并行计算引擎，比CPU更高效地解决许多复杂计算任务。安装CUDA Driver时，其版本需与NVIDIA GPU Driver的版本一致，这样CUDA才能找到显卡。</p><h6 id="安装cudnn">安装cuDNN</h6><p>NVIDIA cuDNN是用于深度神经网络的GPU加速库。注册NVIDIA并下载cuDNN包，获取地址为<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener" class="uri">https://developer.nvidia.com/rdp/cudnn-archive</a>。</p><h6 id="安装python及pytorch">安装Python及PyTorch</h6><p>安装GPU版PyTorch相同，只是选择CUDA时，不是None，而是对应CUDA的版本号。</p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/18.jpg" alt="" /><figcaption>安装GPU版PyTorch</figcaption></figure><h6 id="验证">验证</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat test_gpu.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 测试 CUDA</span></span><br><span class="line">    print(<span class="string">"Support CUDA ?: "</span>, torch.cuda.is_available())</span><br><span class="line">    x = torch.tensor([<span class="number">10.0</span>])</span><br><span class="line">    x = x.cuda()</span><br><span class="line">    print(x)</span><br><span class="line">    y = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    y = y.cuda()</span><br><span class="line">    print(y)</span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">   <span class="comment"># 测试 CUDNN</span></span><br><span class="line">    <span class="keyword">from</span> torch.backends <span class="keyword">import</span> cudnn</span><br><span class="line">    print(<span class="string">"Support cudnn ?: "</span>, cudnn.is_acceptable(x))</span><br></pre></td></tr></table></figure><p><code>python torch</code></p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/19.jpg" alt="" /><figcaption>运行test_gpu.py的结果</figcaption></figure><p>在命令行运行：<code>nvidia-smi</code></p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/20.jpg" alt="" /><figcaption>含GPU进程的显卡信息</figcaption></figure><h4 id="jupyter-notebook环境配置">2.3 Jupyter Notebook环境配置</h4><ul><li>编程时具有语法高亮、缩进、Tab补全的功能</li><li>可直接通过浏览器运行代码，同时在代码块下方展示运行结果</li><li>以富媒体格式展示计算结果。富媒体格式包括：HTML、LaTeX、PNG、SVG等</li><li>对代码编写说明文档或语句时，支持Markdown语法</li><li>支持使用LaTeX编写数学性说明。</li></ul><ol type="1"><li>生成配置文件。</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure><p>执行上述代码，将在当前用户目录下生成文件：<code>.jupyter/jupyter_notebook_config.py</code></p><ol type="1"><li>生成当前用户登录Jupyter密码。打开Ipython，创建一个密文密码。</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [1]: from notebook.auth import passwd</span><br><span class="line">In [2]: passwd()</span><br><span class="line">Enter password: </span><br><span class="line">Verify password:</span><br></pre></td></tr></table></figure><ol type="1"><li>修改配置文件。</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>进行如下修改：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'*'</span>  <span class="comment"># 就是设置所有ip皆可访问</span></span><br><span class="line">c.NotebookApp.password = u<span class="string">'sha:ce...刚才复制的那个密文'</span></span><br><span class="line">c.NotebookApp.open_browser = False  <span class="comment"># 禁止自动打开浏览器</span></span><br><span class="line">c.NotebookApp.port = 8888  <span class="comment"># 这是缺省端口，也可指定其他端口</span></span><br></pre></td></tr></table></figure><ol type="1"><li>启动Jupyter Notebook。</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 后台启动jupyter：不记日志：</span></span><br><span class="line">nohup jupyter notebook &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在浏览器上，输入IP:port，即可看到与下图类似的界面。</p><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/21.jpg" alt="" /><figcaption>Jupyter Notebook网页界面</figcaption></figure><p>接下来就可以在浏览器进行开发调试PyTorch、Python等任务了。</p><h4 id="numpy与tensor">2.4 Numpy与Tensor</h4><p>Numpy存取数据非常方便，而且还拥有大量的函数，所以深得数据处理、机器学习者喜爱。</p><p>Tensor，它可以是零维（又称为标量或一个数）、一维、二维及多维的数组。</p><p>Tensor自称为神经网络界的Numpy，它与Numpy相似，二者可以共享内存，且之间的转换非常方便和高效。</p><p>不过它们也有不同之处，最大的区别就是Numpy会把ndarray放在CPU中进行加速运算，而由Torch产生的Tensor会放在GPU中进行加速运算（假设当前环境有GPU）。</p><h5 id="tensor概述">2.4.1 Tensor概述</h5><p>对Tensor的操作很多，从接口的角度来划分，可以分为两类：</p><ol type="1"><li>torch.function，如torch.sum、torch.add等</li><li>tensor.function，如tensor.view、tensor.add等</li></ol><p>如果从修改方式的角度来划分，可以分为以下两类：</p><ol type="1"><li>不修改自身数据，如x.add(y)，x的数据不变，返回一个新的Tensor。</li><li>修改自身数据，如x.add_(y)（运行符带下划线后缀），运算结果存在x中，x被修改。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = torch.tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">z = x.add(y)</span><br><span class="line">print(z)</span><br><span class="line">print(x)</span><br><span class="line">x.add_(y)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure><h5 id="创建tensor">2.4.2 创建Tensor</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/22.jpg" alt="" /><figcaption>常见的创建Tensor的方法</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 根据list数据生成Tensor</span></span><br><span class="line">torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="comment"># 根据指定形状生成Tensor</span></span><br><span class="line">torch.Tensor(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 根据给定的Tensor的形状</span></span><br><span class="line">t = torch.Tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="comment"># 查看Tensor的形状</span></span><br><span class="line">t.size()</span><br><span class="line"><span class="comment"># shape与size()等价方式</span></span><br><span class="line">t.shape</span><br><span class="line"><span class="comment"># 根据已有形状创建Tensor</span></span><br><span class="line">torch.Tensor(t.size())</span><br></pre></td></tr></table></figure><h5 id="修改tensor形状">2.4.3 修改Tensor形状</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/23.jpg" alt="" /><figcaption>为tensor常用修改形状的函数</figcaption></figure><h5 id="索引操作">2.4.4 索引操作</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/24.jpg" alt="" /><figcaption>常用选择操作函数</figcaption></figure><h5 id="广播机制">2.4.5 广播机制</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.arange(<span class="number">0</span>, <span class="number">40</span>, <span class="number">10</span>).reshape(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">B = np.arange(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 把ndarray转换为Tensor</span></span><br><span class="line">A1 = torch.from_numpy(A)  <span class="comment"># 形状为4x1</span></span><br><span class="line">B1 = torch.from_numpy(B)  <span class="comment"># 形状为3</span></span><br><span class="line"><span class="comment"># Tensor自动实现广播</span></span><br><span class="line">C = A1+B1</span><br><span class="line"><span class="comment"># 我们可以根据广播机制，手工进行配置</span></span><br><span class="line"><span class="comment"># 根据规则1，B1需要向A1看齐，把B变为（1,3）</span></span><br><span class="line">B2 = B1.unsqueeze(<span class="number">0</span>)  <span class="comment"># B2的形状为1x3</span></span><br><span class="line"><span class="comment"># 使用expand函数重复数组，分别的4x3的矩阵</span></span><br><span class="line">A2 = A1.expand(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">B3 = B2.expand(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 然后进行相加,C1与C结果一致</span></span><br><span class="line">C1 = A2+B3</span><br></pre></td></tr></table></figure><h5 id="逐元素操作">2.4.6 逐元素操作</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/25.jpg" alt="" /><figcaption>常见逐元素操作</figcaption></figure><h5 id="归并操作">2.4.7 归并操作</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/26.jpg" alt="" /><figcaption>常见的归并操作</figcaption></figure><h5 id="比较操作">2.4.8 比较操作</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/27.jpg" alt="" /><figcaption>常用的比较函数</figcaption></figure><h5 id="矩阵操作">2.4.9 矩阵操作</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/28.jpg" alt="" /><figcaption>常用矩阵函数</figcaption></figure><h5 id="pytorch与numpy比较">2.4.10 Pytorch与Numpy比较</h5><figure><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/29.jpg" alt="" /><figcaption>PyTorch与Numpy函数对照表</figcaption></figure><h4 id="tensor与autograd">2.5 Tensor与Autograd</h4><h5 id="自动求导要点">2.5.1 自动求导要点</h5><h5 id="计算图">2.5.2计算图</h5><h5 id="标量反向传播">2.5.3 标量反向传播</h5><h5 id="非标量反向传播">2.5.4 非标量反向传播</h5><h4 id="使用numpy实现机器学习">2.6 使用Numpy实现机器学习</h4><h4 id="使用tensor及antograd实现机器学习">2.7 使用Tensor及antograd实现机器学习</h4><h4 id="使用tensorflow架构">2.8 使用TensorFlow架构</h4><h3 id="第3章-pytorch实现神经网络工具箱">第3章 Pytorch实现神经网络工具箱</h3><h4 id="神经网络核心组件">3.1 神经网络核心组件</h4><h4 id="实现神经网络实例">3.2实现神经网络实例</h4><h5 id="背景说明">3.2.1背景说明</h5><h5 id="准备数据">3.2.2准备数据</h5><h5 id="可视化源数据">3.2.3可视化源数据</h5><h5 id="构建模型">3.2.4 构建模型</h5><h5 id="训练模型">3.2.5 训练模型</h5><h4 id="如何构建神经网络">3.3 如何构建神经网络？</h4><h5 id="构建网络层">3.3.1 构建网络层</h5><h5 id="前向传播">3.3.2 前向传播</h5><h5 id="反向传播">3.3.3 反向传播</h5><h5 id="训练模型-1">3.3.4 训练模型</h5><h4 id="nn.module">3.4 nn.Module</h4><h4 id="nn.functional">3.5 nn.functional</h4><h4 id="优化器">3.6 优化器</h4><h4 id="动态修改学习率参数">3.7 动态修改学习率参数</h4><h4 id="优化器比较">3.8 优化器比较</h4><h3 id="第4章-pytorch数据处理工具箱">第4章 Pytorch数据处理工具箱</h3><h4 id="数据处理工具箱概述">4.1 数据处理工具箱概述</h4><h4 id="utils.data简介">4.2 utils.data简介</h4><h4 id="torchvision简介">4.3 torchvision简介</h4><h5 id="transforms">4.3.1 transforms</h5><h5 id="imagefolder">4.3.2 ImageFolder</h5><h4 id="可视化工具">4.4 可视化工具</h4><h5 id="tensorboardx简介">4.4.1 tensorboardX简介</h5><h5 id="用tensorboardx可视化神经网络">4.4.2用tensorboardX可视化神经网络</h5><h5 id="用tensorboardx可视化损失值">4.4.3用tensorboardX可视化损失值</h5><h5 id="用tensorboardx可视化特征图">4.4.4用tensorboardX可视化特征图</h5><h2 id="深度学习基础">深度学习基础</h2><h3 id="第5章-机器学习基础">第5章 机器学习基础</h3><h4 id="机器学习的基本任务">5.1 机器学习的基本任务</h4><h5 id="监督学习">5.1.1监督学习</h5><h5 id="无监督学习">5.1.2 无监督学习</h5><h5 id="半监督学习">5.1.3 半监督学习</h5><h5 id="强化学习">5.1.4 强化学习</h5><h4 id="机器学习一般流程">5.2 机器学习一般流程</h4><h5 id="明确目标">5.2.1 明确目标</h5><h5 id="收集数据">5.2.2收集数据</h5><h5 id="数据探索与预处理">5.2.3 数据探索与预处理</h5><h5 id="选择模型">5.2.4 选择模型</h5><h5 id="评估及优化模型">5.2.5 评估及优化模型</h5><h4 id="过拟合与欠拟合">5.3 过拟合与欠拟合</h4><h5 id="权重正则化">5.3.1 权重正则化</h5><h5 id="dropout正则化">5.3.2 dropout正则化</h5><h5 id="批量正则化">5.3.3 批量正则化</h5><h5 id="权重初始化">5.3.4权重初始化</h5><h4 id="选择合适激活函数">5.4 选择合适激活函数</h4><h4 id="选择合适的损失函数">5.5 选择合适的损失函数</h4><h4 id="选择合适优化器">5.6 选择合适优化器</h4><h5 id="传统梯度优化的不足">5.6.1传统梯度优化的不足</h5><h5 id="动量算法">5.6.2动量算法</h5><h5 id="adagrad算法">5.6.3 AdaGrad算法</h5><h5 id="rmsprop算法">5.6.4 RMSProp算法</h5><h5 id="adam算法">5.6.5 Adam算法</h5><h4 id="gpu加速">5.7GPU加速</h4><h5 id="单gpu加速">5.7.1 单GPU加速</h5><h5 id="多gpu加速">5.7.2 多GPU加速</h5><h5 id="使用gpu注意事项">5.7.3使用GPU注意事项</h5><h3 id="第6章-视觉处理基础">第6章 视觉处理基础</h3><h4 id="卷积神经网络简介">6.1卷积神经网络简介</h4><h4 id="卷积层">6.2卷积层</h4><h5 id="卷积核">6.2.1 卷积核</h5><h5 id="步幅">6.2.2步幅</h5><h5 id="填充">6.2.3 填充</h5><h5 id="多通道上的卷积">6.2.4 多通道上的卷积</h5><h5 id="激活函数">6.2.5激活函数</h5><h5 id="卷积函数">6.2.6卷积函数</h5><h5 id="转置卷积">6.2.7转置卷积</h5><h4 id="池化层">6.3池化层</h4><h5 id="局部池化">6.3.1局部池化</h5><h5 id="全局池化">6.3.2全局池化</h5><h4 id="现代经典网络">6.4现代经典网络</h4><h5 id="lenet-5模型">6.4.1 LeNet-5模型</h5><h5 id="alexnet模型">6.4.2 AlexNet模型</h5><h5 id="vgg模型">6.4.3 VGG模型</h5><h5 id="googlenet模型">6.4.4 GoogleNet模型</h5><h5 id="resnet模型">6.4.5 ResNet模型</h5><h5 id="胶囊网络简介">6.4.6 胶囊网络简介</h5><h4 id="pytorch实现cifar10多分类">6.5 Pytorch实现cifar10多分类</h4><h5 id="数据集说明">6.5.1 数据集说明</h5><h5 id="加载数据">6.5.2 加载数据</h5><h5 id="构建网络">6.5.3 构建网络</h5><h5 id="训练模型-2">6.5.4 训练模型</h5><h5 id="测试模型">6.5.5 测试模型</h5><h5 id="采用全局平均池化">6.5.6 采用全局平均池化</h5><h5 id="像keras一样显示各层参数">6.5.7像keras一样显示各层参数</h5><h4 id="模型集成提升性能">6.6 模型集成提升性能</h4><h5 id="使用模型">6.6.1 使用模型</h5><h5 id="集成方法">6.6.2 集成方法</h5><h5 id="集成效果">6.6.3 集成效果</h5><h4 id="使用经典模型提升性能">6.7使用经典模型提升性能</h4><h3 id="第7章-自然语言处理基础">第7章 自然语言处理基础</h3><h4 id="循环神经网络基本结构">7.1 循环神经网络基本结构</h4><h4 id="前向传播与随时间反向传播">7.2前向传播与随时间反向传播</h4><h4 id="循环神经网络变种">7.3 循环神经网络变种</h4><h5 id="lstm">7.3.1 LSTM</h5><h5 id="gru">7.3.2 GRU</h5><h5 id="bi-rnn">7.3.3 Bi-RNN</h5><h4 id="循环神经网络的pytorch实现">7.4 循环神经网络的Pytorch实现</h4><h5 id="rnn实现">7.4.1 RNN实现</h5><h5 id="lstm实现">7.4.2LSTM实现</h5><h5 id="gru实现">7.4.3GRU实现</h5><h4 id="文本数据处理">7.5文本数据处理</h4><h4 id="词嵌入">7.6词嵌入</h4><h5 id="word2vec原理">7.6.1Word2Vec原理</h5><h5 id="cbow模型">7.6.2 CBOW模型</h5><h5 id="skim-gram模型">7.6.3 Skim-gram模型</h5><h4 id="pytorch实现词性判别">7.7 Pytorch实现词性判别</h4><h5 id="词性判别主要步骤">7.7.1 词性判别主要步骤</h5><h5 id="数据预处理">7.7.2 数据预处理</h5><h5 id="构建网络-1">7.7.3 构建网络</h5><h5 id="训练网络">7.7.4 训练网络</h5><h5 id="测试模型-1">7.7.5 测试模型</h5><h4 id="循环神经网络应用场景">7.8循环神经网络应用场景</h4><h3 id="第8章-生成式深度学习">第8章 生成式深度学习</h3><h4 id="用变分自编码器生成图像">8.1 用变分自编码器生成图像</h4><h5 id="自编码器">8.1.1 自编码器</h5><h5 id="变分自编码器">8.1.2变分自编码器</h5><h5 id="用变分自编码器生成图像-1">8.1.3用变分自编码器生成图像</h5><h4 id="gan简介">8.2 GAN简介</h4><h5 id="gan架构">8.2.1 GAN架构</h5><h5 id="gan的损失函数">8.2.2 GAN的损失函数</h5><h4 id="用gan生成图像">8.3用GAN生成图像</h4><h5 id="判别器">8.3.1判别器</h5><h5 id="生成器">8.3.2 生成器</h5><h5 id="训练模型-3">8.3.3 训练模型</h5><h5 id="可视化结果">8.3.4 可视化结果</h5><h4 id="vae与gan的异同">8.4 VAE与GAN的异同</h4><h4 id="condition-gan">8.5 Condition GAN</h4><h5 id="cgan的架构">8.5.1 CGAN的架构</h5><h5 id="cgan-生成器">8.5.2 CGAN 生成器</h5><h5 id="cgan-判别器">8.5.3 CGAN 判别器</h5><h5 id="cgan-损失函数">8.5.4 CGAN 损失函数</h5><h5 id="cgan-可视化">8.5.5 CGAN 可视化</h5><h5 id="查看指定标签的数据">8.5.6 查看指定标签的数据</h5><h5 id="可视化损失值">8.5.7 可视化损失值</h5><h4 id="dcgan">8.6 DCGAN</h4><h4 id="提升gan训练效果的一些技巧">8.7 提升GAN训练效果的一些技巧</h4><h2 id="深度学习实战">深度学习实战</h2><h3 id="第9章-人脸检测与识别">第9章 人脸检测与识别</h3><h4 id="人脸识别一般流程">9.1 人脸识别一般流程</h4><h5 id="图像采集">9.1.1图像采集</h5><h5 id="人脸检测">9.1.2 人脸检测</h5><h4 id="特征提取">9.3特征提取</h4><h4 id="人脸识别">9.4人脸识别</h4><h5 id="人脸识别主要原理">9.4.1 人脸识别主要原理</h5><h5 id="人脸识别发展">9.4.2人脸识别发展</h5><h4 id="人脸检测与识别实例">9.5 人脸检测与识别实例</h4><h5 id="验证检测代码">9.5.1.验证检测代码</h5><h5 id="检测图像">9.5.2.检测图像</h5><h5 id="检测后进行预处理">9.5.3.检测后进行预处理</h5><h5 id="查看经检测后的图片">9.5.4.查看经检测后的图片</h5><h5 id="人脸识别-1">9.5.5.人脸识别</h5><h3 id="第10章-迁移学习实例">第10章 迁移学习实例</h3><p>10.1 迁移学习简介<br />10.2 特征提取<br />10.2.1 Pytorch提供的预处理模块<br />10.2.2 特征提取实例<br />10.3 数据增强<br />10.3.1 按比例缩放<br />10.3.2 裁剪<br />10.3.3翻转<br />10.3.4改变颜色<br />10.3.5组合多种增强方法<br />10.4 微调实例<br />10.4.1 数据预处理<br />10.4.2 加载预训练模型<br />10.4.3 修改分类器<br />10.4.4 选择损失函数及优化器<br />10.4.5 训练及验证模型<br />10.5 用预训练模型清除图像中的雾霾<br />10.5.1 导入需要的模块<br />10.5.2 查看原来的图像<br />10.5.3 定义一个神经网络<br />10.5.4 训练模型<br />10.5.5 查看处理后的图像</p><h3 id="第11章-神经网络机器翻译实例">第11章 神经网络机器翻译实例</h3><p>11.1 Encode-Decoder模型原理<br />11.2 注意力框架<br />11.3 Pytorch实现注意力Decoder<br />11.3.1 构建Encoder<br />11.3.2 构建简单Decoder<br />11.3.3 构建注意力Decoder<br />11.4 用注意力机制实现中英文互译<br />11.4.1 导入需要的模块<br />11.4.2数据预处理<br />11.4.3构建模型<br />11.4.4训练模型<br />11.4.5随机采样，对模型进行测试<br />11.4.6可视化注意力</p><h3 id="第12章-实战生成式模型">第12章 实战生成式模型</h3><p>12.1 Deep Dream模型<br />12.1.1 Deep Dream原理<br />12.1.2 DeepDream算法流程<br />12.1.3 用Pytorch实现Deep Dream<br />12.2 风格迁移<br />12.2.1 内容损失<br />12.2.2 风格损失<br />12.2.3 用Pytorch实现神经网络风格迁移<br />12.3 Pytorch实现图像修复<br />12.3.1 网络结构<br />12.3.2 损失函数<br />12.3.3 图像修复实例<br />12.4 Pytorch实现DiscoGAN<br />12.4.1 DiscoGAN架构<br />12.4.2 损失函数<br />12.4.3 DiscoGAN实现<br />12.4.4 用Pytorch实现从边框生成鞋子<br />### 第13章 Caffe2模型迁移实例<br />13.1 Caffe2简介<br />13.2 Caffe如何迁移到Caffe2<br />13.3 Pytorch如何迁移到caffe2</p><h3 id="第14章-ai新方向对抗攻击">第14章 AI新方向：对抗攻击</h3><p>14.1对抗攻击简介<br />14.1.1白盒攻击与黑盒攻击<br />14.1.2无目标攻击与有目标攻击<br />14.2常见对抗样本生成方式<br />14.2.1快速梯度符号法<br />14.2.2快速梯度算法<br />14.3 Pytorch实现对抗攻击<br />14.3.1 实现无目标攻击<br />14.3.2 实现有目标攻击<br />14.4 对抗攻击和防御措施<br />14.4.1 对抗攻击<br />14.4.2 常见防御方法分类<br />14.5 总结<br />### 第15章 强化学习<br />15.1 强化学习简介<br />15.2Q Learning 原理<br />15.2.1 Q Learning主要流程<br />15.2.2 Q函数<br />15.2.3 贪婪策略<br />15.3 用Pytorch实现Q Learning<br />15.3.1 定义Q-Learing主函数<br />15.3.2执行Q-Learing<br />15.4 SARSA 算法<br />15.4.1 SARSA算法主要步骤<br />15.4.2 用Pytorch实现SARSA算法</p><p>第16章 深度强化学习<br />16.1 DSN算法原理<br />16.1.1 Q-Learning方法的局限性<br />16.1.2 用DL处理RL需要解决的问题<br />16.1.3 用DQN解决方法<br />16.1.4 定义损失函数<br />16.1.5 DQN的经验回放机制<br />16.1.6 目标网络<br />16.1.7 网络模型<br />16.1.8 DQN算法<br />16.2 用Pytorch实现 DQN算法</p><h2 id="ai在各行业的最新应用">AI在各行业的最新应用</h2><h3 id="ai电商">AI+电商</h3><h3 id="ai金融">AI+金融</h3><h3 id="ai医疗">AI+医疗</h3><h3 id="ai零售">AI+零售</h3><h3 id="ai投行">AI+投行</h3><h3 id="ai制造">AI+制造</h3><h3 id="aiit服务">AI+IT服务</h3><h3 id="ai汽车">AI+汽车</h3><h3 id="ai公共安全">AI+公共安全</h3><p><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/30.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/31.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/32.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/33.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/34.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/35.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/36.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/37.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/38.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/39.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/40.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/41.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/42.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/43.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/44.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/45.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/46.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/47.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/48.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/49.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/50.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/51.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/52.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/53.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/54.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/55.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/56.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/57.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/58.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/59.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/60.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/61.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/62.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/63.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/64.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/65.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/66.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/67.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/68.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/69.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/70.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/71.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/72.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/73.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/74.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/75.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/76.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/77.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/78.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/79.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/80.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/81.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/82.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/83.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/84.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/85.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/86.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/87.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/88.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/89.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/90.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/91.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/92.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/93.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/94.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/95.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/96.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/97.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/98.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/99.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/100.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/101.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/102.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/103.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/104.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/105.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/106.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/107.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/108.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/109.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/110.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/111.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/112.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/113.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/114.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/115.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/116.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/117.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/118.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/119.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/120.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/121.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/122.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/123.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/124.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/125.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/126.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/127.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/128.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/129.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/130.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/131.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/132.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/133.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/134.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/135.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/136.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/137.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/138.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/139.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/140.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/141.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/142.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/143.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/144.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/145.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/146.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/147.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/148.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/149.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/150.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/151.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/152.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/153.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/154.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/155.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/156.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/157.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/158.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/159.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/160.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/161.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/162.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/163.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/164.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/165.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/166.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/167.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/168.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/169.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/170.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/171.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/172.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/173.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/174.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/175.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/176.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/177.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/178.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/179.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/180.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/181.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/182.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/183.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/184.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/185.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/186.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/187.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/188.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/189.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/190.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/191.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/192.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/193.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/194.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/195.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/196.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/197.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/198.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/199.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/200.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/201.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/202.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/203.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/204.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/205.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/206.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/207.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/208.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/209.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/210.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/211.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/212.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/213.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/214.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/215.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/216.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/217.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/218.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/219.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/220.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/221.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/222.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/223.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/224.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/225.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/226.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/227.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/228.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/229.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/230.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/231.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/232.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/233.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/234.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/235.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/236.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/237.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/238.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/239.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/240.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/241.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/242.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/243.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/244.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/245.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/246.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/247.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/248.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/249.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/250.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/251.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/252.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/253.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/254.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/255.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/256.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/257.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/258.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/259.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/260.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/261.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/262.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/263.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/264.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/265.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/266.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/267.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/268.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/269.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/270.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/271.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/272.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/273.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/274.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/275.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/276.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/277.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/278.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/279.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/280.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/281.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/282.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/283.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/284.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/285.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/286.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/287.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/288.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/289.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/290.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/291.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/292.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/293.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/294.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/295.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/296.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/297.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/298.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/299.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/300.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/301.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/17/pytorch/302.jpg" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/17/pytorch/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《Python深度学习：基于PyTorch》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：Python深度学习：基于PyTorch&lt;br /&gt;
作者：吴茂贵，郁明敏，杨本法，李涛，张粤磊&lt;br /&gt;
出版社：机械工业出版社&lt;br /&gt;
出版时间：2019-10&lt;br /&gt;
ISBN：9787111637172&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="PyTorch" scheme="https://2020.iosdevlog.com/tags/PyTorch/"/>
    
      <category term="Python" scheme="https://2020.iosdevlog.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>智能安卓恶意软件检测系统</title>
    <link href="https://2020.iosdevlog.com/2020/02/16/android/"/>
    <id>https://2020.iosdevlog.com/2020/02/16/android/</id>
    <published>2020-02-16T10:50:36.000Z</published>
    <updated>2020-02-16T11:04:03.888Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/16/android/1.png" alt="" /><figcaption>HinDroid</figcaption></figure><p><a href="https://dl.acm.org/doi/10.1145/3097983.3098026" target="_blank" rel="noopener">HinDroid: An Intelligent Android Malware Detection System Based on Structured Heterogeneous Information Network</a></p><a id="more"></a><h2 id="主要贡献">主要贡献</h2><p>这篇论文希望解决的问题是如何有效地监测安卓手机系统下的恶意软件。</p><p>之前很多恶意软件的分析和检测都是基于某种 <strong>指纹签字</strong> 技术，然而这种技术常常被恶意软件开发者的新手段绕过。</p><p>因此，寻找更加复杂有效的检测方式就成了各种信息安全公司所追逐的目标。</p><p>这篇论文的主要贡献是根据安卓的 API，提出了一种新的基于结构性异构信息网络的方法，来对安卓程序的 API 模式进行更加复杂的建模，从而能够理解整个安卓程序的语义。作者们还采用了多核学习（Multi-Kernel Learning）的方法，在结构性异构信息网络的基础上对程序语义模式进行分类。</p><h2 id="核心方法">核心方法</h2><p>首先，需要将安卓的程序代码转换为可以分析的形式。一般来说，安卓的软件被打包为后缀名为 Dex 的 Dalivik 执行文件，这个执行文件无法被直接分析。于是，需要把这个执行文件通过一个叫 Smali 的反汇编器解析成 Smali 代码。这个时候，软件的语义就能够通过 Smali 代码来解析了。作者们从 Smali 代码中提取所有的 API 调用，通过对 API 的分析来对程序行为建模。下一步，就是要从繁复的 API 调用中摸索出这里面的规律。</p><p>作者们这个时候构建了四类矩阵来表达 API 和某个 App 之间的基本特征：</p><ol type="1"><li>某一个 App 是否包含了某一个 API；</li><li>某两个 API 是否同时出现在某一段代码中；</li><li>某两个 API 是否出现在同一个 App 中；</li><li>某两个 API 是否使用了相同的调用方法。</li></ol><p>为了发现更加复杂的规律，作者们在这里引入了一个工具叫异构信息网络。异构信息网络的概念最早由伊利诺伊大学香槟分校的数据挖掘权威韩家炜（Jiawei Han）和他当时的学生孙怡舟（Yizhou Sun，目前在加州大学洛杉矶分校任教）提出。异构信息网络的核心思想就是希望能够表达一系列实体（Entity）之间的复杂规律。</p><p>把 App 和 API 的关系描述成为异构信息网络以后，下面的工作就是定义更高阶的规律关系。</p><p>利用异构信息网络和元路径构建了程序的语义表达后，下一步就是进行恶意软件的判别。</p><figure><img src="https://2020.iosdevlog.com/2020/02/16/android/2.png" alt="" /><figcaption>Multi-kernel Learning</figcaption></figure><p>参考: <a href="https://time.geekbang.org/column/article/394" target="_blank" rel="noopener" class="uri">https://time.geekbang.org/column/article/394</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/16/android/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;HinDroid&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3097983.3098026&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;HinDroid: An Intelligent Android Malware Detection System Based on Structured Heterogeneous Information Network&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="paper" scheme="https://2020.iosdevlog.com/tags/paper/"/>
    
      <category term="Android" scheme="https://2020.iosdevlog.com/tags/Android/"/>
    
  </entry>
  
</feed>
