<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Game 2020</title>
  
  <subtitle>https://2020.iosdevlog.com</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://2020.iosdevlog.com/"/>
  <updated>2020-03-15T15:20:59.941Z</updated>
  <id>https://2020.iosdevlog.com/</id>
  
  <author>
    <name>iOSDevLog</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习算法之旅</title>
    <link href="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/"/>
    <id>https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/</id>
    <published>2020-03-15T13:49:49.000Z</published>
    <updated>2020-03-15T15:20:59.941Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/ensemble.png" /></p><p>最合适的线条组合的一个很好的例子。弱预测成员为灰色，组合预测为红色。</p><p>绘图来自Wikipedia，在公共领域获得许可。</p><a id="more"></a><p>在本文中，我们将浏览<strong><em>最流行的机器学习算法</em></strong>。</p><p>考察该领域的主要算法对了解可用的方法很有用。</p><p>有太多算法，当抛出算法名称时会感到不知所措，并且您应该只知道它们是什么以及它们适合什么位置。</p><p>我想给您提供两种方式来考虑和分类您在该领域可能遇到的算法。</p><ul><li>首先是按照<strong>学习风格</strong>对算法进行分组。</li><li>第二个是按形式或功能上的<strong>相似性</strong>将算法分组（例如将相似的动物分组在一起）。</li></ul><p>两种方法都是有用的，但是我们将着重于通过相似性进行算法分组，并浏览各种不同的算法类型。</p><p>阅读这篇文章后，您将对用于监督学习的最受欢迎的机器学习算法以及它们之间的关系有更好的了解。</p><p><a href="https://machinelearningmastery.com/master-machine-learning-algorithms/" target="_blank" rel="noopener">在我的新书中</a>（包括22个excel教程和示例），了解机器学习算法如何工作，包括kNN，决策树，朴素贝叶斯，SVM，集成等。</p><p>让我们开始吧。</p><h2 id="按学习风格分组的算法">按学习风格分组的算法</h2><p>算法可以根据其与经验或环境的交互作用或我们要调用输入数据的方式，以不同的方式对问题建模。</p><p>首先要考虑算法可以采用的学习方式，这在机器学习和人工智能教科书中很普遍。</p><p>一个算法只能有几种主要的学习方式或学习模型，我们将在此通过一些适合他们的算法和问题类型的示例进行介绍。</p><p>这种分类法或组织机器学习算法的方法很有用，因为它迫使您考虑输入数据的角色和模型准备过程，并选择最适合您问题的模型，以获得最佳结果。</p><h3 id="让我们看一下机器学习算法中的三种不同的学习风格">让我们看一下机器学习算法中的三种不同的学习风格：</h3><h4 id="监督学习"><strong>1.监督学习</strong></h4><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Supervised-Learning-Algorithms.png" /></p><p>输入数据称为训练数据，并且一次具有已知标签或结果，例如垃圾邮件/非垃圾邮件或股票价格。</p><p>通过训练过程来准备模型，其中需要进行预测，并在这些预测错误时进行校正。训练过程将继续进行，直到模型在训练数据上达到所需的准确性水平为止。</p><p>示例问题是 <strong>分类</strong> 和 <strong>回归</strong>。</p><p>示例算法包括：<strong>逻辑回归</strong> 和 <strong>反向传播神经网络</strong>。</p><h4 id="无监督学习"><strong>2.无监督学习</strong></h4><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Unsupervised-Learning-Algorithms.png" /></p><p>输入数据未标记，结果未知。</p><p>通过推导输入数据中存在的结构来准备模型。这可能是提取一般规则。可以通过数学过程来系统地减少冗余，也可以通过相似性组织数据。</p><p>示例问题包括 <strong>聚类</strong>，<strong>降维</strong> 和 <strong>关联规则学习</strong>。</p><p>示例算法包括：<strong>Apriori算法</strong> 和 <strong>K-Means</strong>。</p><h4 id="半监督学习"><strong>3.半监督学习</strong></h4><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Semi-supervised-Learning-Algorithms.png" /></p><p>输入数据是带标签和未带标签的示例的混合。</p><p>存在一个期望的预测问题，但是模型必须学习用于组织数据以及进行预测的结构。</p><p>示例问题是 <strong>分类</strong> 和 <strong>回归</strong>。</p><p>示例算法是对其他灵活方法的扩展，这些方法对如何建模未标记数据进行了假设。</p><h3 id="机器学习算法概述">机器学习算法概述</h3><p>处理数据以对业务决策进行建模时，最典型的情况是您使用有监督和无监督的学习方法。</p><p>目前最热门的话题是 <strong>图像分类</strong> 等领域的 <code>半监督</code> 学习方法，在这些领域中，大型数据集的示例很少。</p><h2 id="相似度分组算法">相似度分组算法</h2><p>算法通常在功能（工作方式）方面按相似性分组。例如，基于树的方法和基于神经网络的方法。</p><p>我认为这是对算法进行分组的最有用的方法，也是我们将在此处使用的方法。</p><p>这是一种有用的分组方法，但并不完美。仍然有一些算法可以很容易地适合多个类别，例如“学习矢量量化”既是神经网络启发性方法又是基于实例的方法。也有描述问题的同名类别和算法类别，例如回归和聚类。</p><p>我们可以通过两次列出算法或选择主观上 <em>最</em> 适合的组来处理这些情况。我喜欢后一种方法，即不重复算法以保持简单。</p><p>在本节中，我们列出了许多流行的机器学习算法，这些算法按照我们认为最直观的方式进行了分组。该列表在组或算法中都不是详尽无遗的，但我认为它是具有代表性的，对您了解土地状况将很有用。</p><blockquote><p><strong>请注意</strong>：用于分类和回归的算法有很大的偏见，这是您将遇到的两个最普遍的监督式机器学习问题。</p></blockquote><p>如果您知道某个算法或一组未列出的算法，请在注释中添加并与我们分享。让我们潜入。</p><h3 id="回归算法">回归算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Regression-Algorithms.png" /></p><p>回归模型涉及对变量之间的关系进行建模，这些变量之间的关系使用模型进行的预测中的误差度量进行了迭代完善。</p><p>回归方法是统计工作的主力军，已被选入统计机器学习中。这可能会造成混淆，因为我们可以使用回归来指代问题的类别和算法的类别。确实，回归是一个过程。</p><p>最受欢迎的回归算法是：</p><ul><li>普通最小二乘回归（OLSR）</li><li>线性回归</li><li>逻辑回归</li><li>逐步回归</li><li>多元自适应回归样条（MARS）</li><li>局部估计的散点图平滑（LOESS）</li></ul><h3 id="基于实例的算法">基于实例的算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Instance-based-Algorithms.png" /></p><p>基于实例的学习模型是一个决策问题，其中包含训练数据的实例或示例，这些实例或示例被认为对该模型很重要或需要。</p><p>这样的方法通常建立示例数据的数据库，并使用相似性度量将新数据与数据库进行比较，以便找到最佳匹配并做出预测。因此，基于实例的方法也称为获胜者通吃方法和基于内存的学习。重点放在存储实例的表示以及实例之间使用的相似性度量上。</p><p>最受欢迎的基于实例的算法是：</p><ul><li>k最近邻居（kNN）</li><li>学习矢量量化（LVQ）</li><li>自组织图（SOM）</li><li>本地加权学习（LWL）</li><li>支持向量机（SVM）</li></ul><h3 id="正则化算法">正则化算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Regularization-Algorithms.png" /></p><p>对另一种方法（通常是回归方法）的扩展，该方法根据模型的复杂性对模型进行惩罚，而倾向于更易于泛化的简单模型。</p><p>我在这里单独列出了正则化算法，因为它们是对其他方法的流行，功能强大且通常简单的修改。</p><p>最受欢迎的正则化算法是：</p><ul><li>岭回归</li><li>最小绝对收缩和选择算子（LASSO）</li><li>弹性网</li><li>最小角度回归（LARS）</li></ul><h3 id="决策树算法">决策树算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Decision-Tree-Algorithms.png" /></p><p>决策树方法构建了一个基于数据中属性的实际值制定的决策模型。</p><p>决策派生到树结构中，直到为给定记录做出预测决策为止。对决策树进行有关分类和回归问题的数据训练。决策树通常快速，准确，并且在机器学习中大受欢迎。</p><p>最受欢迎的决策树算法是：</p><ul><li>分类和回归树（CART）</li><li>迭代二叉树 3 代（ID3）</li><li>C4.5和C5.0（功能强大的方法的不同版本）</li><li>卡方自动互动检测（CHAID）</li><li>决策树桩</li><li>M5</li><li>条件决策树</li></ul><h3 id="贝叶斯算法">贝叶斯算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Bayesian-Algorithms.png" /></p><p>贝叶斯方法是将贝叶斯定理明确应用于分类和回归等问题的方法。</p><p>最受欢迎的贝叶斯算法是：</p><ul><li>朴素贝叶斯</li><li>高斯朴素贝叶斯</li><li>多项式朴素贝叶斯</li><li>平均一依赖估计量（AODE）</li><li>贝叶斯信仰网络（BBN）</li><li>贝叶斯网络（BN）</li></ul><h3 id="聚类算法">聚类算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Clustering-Algorithms.png" /></p><p>像回归一样，聚类描述问题的类别和方法的类别。</p><p>聚类方法通常通过建模方法（例如基于质心和层次的方法）进行组织。所有方法都涉及使用数据中的固有结构来最好地将数据组织成具有最大共性的组。</p><p>最受欢迎的聚类算法是：</p><ul><li>k均值 k-Means</li><li>k中位数 k-Medians</li><li>期望最大化（EM）</li><li>层次聚类</li></ul><h3 id="关联规则学习算法">关联规则学习算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Assoication-Rule-Learning-Algorithms.png" /></p><p>关联规则学习方法提取的规则可以最好地解释数据中变量之间观察到的关系。</p><p>这些规则可以在组织可以利用的大型多维数据集中发现重要的商业上有用的关联。</p><p>最受欢迎的关联规则学习算法是：</p><ul><li>Apriori 算法</li><li>Eclat 算法</li></ul><h3 id="人工神经网络算法">人工神经网络算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Artificial-Neural-Network-Algorithms.png" /></p><p>人工神经网络是受生物神经网络的结构和/或功能启发的模型。</p><p>它们是一类模式匹配，通常用于回归和分类问题，但实际上是一个巨大的子领域，由数百种算法和各种问题类型的变体组成。</p><p>请注意，由于该领域的迅速发展和普及，我将深度学习与神经网络分开了。在这里，我们关注更经典的方法。</p><p>最受欢迎的人工神经网络算法是：</p><ul><li>感知器</li><li>多层感知器（MLP）</li><li>反向传播</li><li>随机梯度下降</li><li>霍普菲尔德网络</li><li>径向基函数网络（RBFN）</li></ul><h3 id="深度学习算法">深度学习算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Deep-Learning-Algorithms.png" /></p><p><a href="https://machinelearningmastery.com/what-is-deep-learning/" target="_blank" rel="noopener">深度学习</a>方法是对利用大量廉价计算的人工神经网络的一种现代更新。</p><p>他们关注的是构建更大，更复杂的神经网络，并且如上所述，许多方法都涉及标记的模拟数据（例如图像，文本）的超大型数据集。音频和视频。</p><p>最受欢迎的深度学习算法是：</p><ul><li>卷积神经网络（CNN）</li><li>递归神经网络（RNN）</li><li>长短期记忆网络（LSTM）</li><li>堆叠式自动编码器</li><li>深玻尔兹曼机（DBM）</li><li>深度信仰网络（DBN）</li></ul><h3 id="降维算法">降维算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Dimensional-Reduction-Algorithms.png" /></p><p>像聚类方法一样，降维会寻找和利用数据中的固有结构，但是在这种情况下，将以无监督的方式或顺序使用较少的信息来汇总或描述数据。</p><p>这对于可视化尺寸数据或简化可以在监督学习方法中使用的数据很有用。这些方法中的许多方法都可以用于分类和回归。</p><ul><li>主成分分析（PCA）</li><li>主成分回归（PCR）</li><li>偏最小二乘回归（PLSR）</li><li>萨蒙地图</li><li>多维缩放（MDS）</li><li>投影追踪</li><li>线性判别分析（LDA）</li><li>混合判别分析（MDA）</li><li>二次判别分析（QDA）</li><li>弹性判别分析（FDA）</li></ul><h3 id="集成学习算法">集成学习算法</h3><p><img src="https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/Ensemble-Algorithms.png" /></p><p>集合方法是由多个较弱的模型组成的模型，这些模型经过独立训练，其预测以某种方式组合在一起以进行总体预测。</p><p>对于要组合哪些类型的弱学习者以及如何将它们组合在一起，需要付出很多努力。这是一类非常强大的技术，因此非常受欢迎。</p><ul><li>Boosting</li><li>Bootstrapped Aggregation (Bagging)</li><li>AdaBoost</li><li>加权平均值（混合）</li><li>堆叠泛化（堆叠）Stacked Generalization (Stacking)</li><li>梯度提升机（GBM）Gradient Boosting Machines (GBM)</li><li>梯度增强回归树（GBRT）Gradient Boosting Machines (GBM)</li><li>随机森林</li></ul><h3 id="其他机器学习算法">其他机器学习算法</h3><p>许多算法没有涵盖。</p><p>在机器学习过程中，我没有涉及特殊任务的算法，例如：</p><ul><li>特征选择算法</li><li>算法精度评估</li><li>绩效指标</li><li>优化算法</li></ul><p>我也没有涵盖来自机器学习专业子领域的算法，例如：</p><ul><li>计算智能（进化算法等）</li><li>计算机视觉（CV）</li><li>自然语言处理（NLP）</li><li>推荐系统</li><li>强化学习</li><li>图形模型</li><li>更多…</li></ul><p>这些可能会在以后的帖子中出现。</p><h2 id="机器学习算法的进一步阅读">机器学习算法的进一步阅读</h2><p>这次机器学习算法之旅旨在为您提供概述，以及有关如何将算法相互关联的一些想法。</p><p>我已经收集了一些资源，供您继续阅读算法。如果您有特定问题，请发表评论。</p><h3 id="机器学习算法的其他列表">机器学习算法的其他列表</h3><p>如果您有兴趣，还有很多其他的算法列表。以下是一些精选示例。</p><ul><li><a href="http://en.wikipedia.org/wiki/List_of_machine_learning_algorithms" target="_blank" rel="noopener">机器学习算法列表</a>：在Wikipedia上。尽管内容广泛，但我认为此列表或算法的组织并没有特别有用。</li><li><a href="http://en.wikipedia.org/wiki/Category:Machine_learning_algorithms" target="_blank" rel="noopener">机器学习算法类别</a>：也在Wikipedia上，比上面的Wikipedia很棒的列表稍微有用。它按字母顺序组织算法。</li><li><a href="http://cran.r-project.org/web/views/MachineLearning.html" target="_blank" rel="noopener">CRAN任务视图：机器学习和统计学习</a>：R中每个机器学习软件包所支持的所有软件包和所有算法的列表。它使您对现有内容以及人们日常使用的分析有扎实的感觉。</li><li><a href="http://www.cs.uvm.edu/~icdm/algorithms/index.shtml" target="_blank" rel="noopener">数据挖掘中的十大算法</a>：已<a href="http://link.springer.com/article/10.1007/s10115-007-0114-2" target="_blank" rel="noopener">发表的文章</a>，现在是一<a href="http://www.amazon.com/dp/1420089641?tag=inspiredalgor-20" target="_blank" rel="noopener">本有关最流行的数据挖掘算法的书</a>（会员链接）。另一种扎根但不太压倒性的方法可以让您深入学习。</li></ul><h3 id="如何学习机器学习算法">如何学习机器学习算法</h3><p>算法是机器学习的重要组成部分。这是我热衷的话题，并在此博客上写了很多。以下是一些可能会吸引您进一步阅读的精选帖子。</p><ul><li><a href="http://machinelearningmastery.com/how-to-learn-a-machine-learning-algorithm/" target="_blank" rel="noopener">如何学习任何机器学习算法</a>：一种可以使用“算法描述模板”来学习和理解任何机器学习算法的系统方法（我用这种方法写了<a href="http://cleveralgorithms.com/nature-inspired/index.html" target="_blank" rel="noopener">第一本书</a>）。</li><li><a href="http://machinelearningmastery.com/create-lists-of-machine-learning-algorithms/" target="_blank" rel="noopener">如何创建机器学习算法的目标列表</a>：如何创建自己的机器学习算法的系统列表，以开始处理下一个机器学习问题。</li><li><a href="http://machinelearningmastery.com/how-to-research-a-machine-learning-algorithm/" target="_blank" rel="noopener">如何研究机器学习算法</a>：您可以用来研究机器学习算法的系统方法（与上面列出的模板方法协同工作非常有效）。</li><li><a href="http://machinelearningmastery.com/how-to-investigate-machine-learning-algorithm-behavior/" target="_blank" rel="noopener">如何研究机器学习算法的行为</a>：可以通过对行为进行很小的研究并对其进行研究，从而了解机器学习算法如何工作的方法。研究不仅针对学者！</li><li><a href="http://machinelearningmastery.com/how-to-implement-a-machine-learning-algorithm/" target="_blank" rel="noopener">如何实施机器学习算法</a>：从头开始实施机器学习算法的过程，技巧和窍门。</li></ul><h3 id="如何运行机器学习算法">如何运行机器学习算法</h3><p>有时，您只想深入研究代码。以下是一些链接，您可以使用这些链接来运行机器学习算法，使用标准库对其进行编码或从头开始实施它们。</p><ul><li><a href="http://machinelearningmastery.com/how-to-get-started-with-machine-learning-algorithms-in-r/" target="_blank" rel="noopener">如何开始使用R中的机器学习算法</a>：链接到此站点上的大量代码示例，这些示例演示了R中的机器学习算法。</li><li><a href="http://machinelearningmastery.com/get-your-hands-dirty-with-scikit-learn-now/" target="_blank" rel="noopener">scikit-learn中的机器学习算法食谱</a>：一系列Python代码示例，展示了如何使用scikit-learn创建预测模型。</li><li><a href="http://machinelearningmastery.com/how-to-run-your-first-classifier-in-weka/" target="_blank" rel="noopener">如何在Weka中运行您的第一个分类器如何在Weka</a>：中运行第一个分类器的教程（<strong>无需任何代码！</strong>）。</li></ul><p>原文：<a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" target="_blank" rel="noopener">A Tour of Machine Learning Algorithms</a></p><p>作者：<a href="https://machinelearningmastery.com/author/jasonb/" target="_blank" rel="noopener" title="Posts by Jason Brownlee">Jason Brownlee</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/15/A-Tour-of-Machine-Learning-Algorithms/ensemble.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;最合适的线条组合的一个很好的例子。弱预测成员为灰色，组合预测为红色。&lt;/p&gt;
&lt;p&gt;绘图来自Wikipedia，在公共领域获得许可。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="ml" scheme="https://2020.iosdevlog.com/tags/ml/"/>
    
      <category term="algorithm" scheme="https://2020.iosdevlog.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>机器学习算法实现的简洁示例：MLAlgorithms</title>
    <link href="https://2020.iosdevlog.com/2020/03/15/MLAlgorithms/"/>
    <id>https://2020.iosdevlog.com/2020/03/15/MLAlgorithms/</id>
    <published>2020-03-15T13:03:07.000Z</published>
    <updated>2020-03-15T13:42:39.639Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://2020.iosdevlog.com/2020/03/15/MLAlgorithms/1.jpg" /></p><p>Minimal and clean examples of machine learning algorithms implementations</p><p>介绍一个常用的机器学习算法的最小和简洁实现的集合：机器学习算法库 <a href="https://github.com/rushter/MLAlgorithms" target="_blank" rel="noopener" class="uri">https://github.com/rushter/MLAlgorithms</a>。</p><a id="more"></a><h2 id="为什么"><a href="https://github.com/rushter/MLAlgorithms#why" target="_blank" rel="noopener">为什么</a>？</h2><p>该项目面向想要学习ml算法的内部知识或从头开始实现它们的人们。</p><p>与优化的库相比，该代码更易于遵循和使用。</p><p>所有算法均使用 <code>numpy</code>，<code>scipy</code> 和 <code>autograd</code> 在 <code>Python</code> 中实现。</p><h2 id="实现"><a href="https://github.com/rushter/MLAlgorithms#implemented" target="_blank" rel="noopener">实现</a> ：</h2><ul><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/neuralnet" target="_blank" rel="noopener">深度学习（MLP，CNN，RNN，LSTM）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/linear_models.py" target="_blank" rel="noopener">线性回归，逻辑回归</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/ensemble/random_forest.py" target="_blank" rel="noopener">随机森林</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/svm" target="_blank" rel="noopener">支持向量机（SVM），带有内核（线性，多项式，RBF）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/kmeans.py" target="_blank" rel="noopener">K均值</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/gaussian_mixture.py" target="_blank" rel="noopener">高斯混合模型</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/knn.py" target="_blank" rel="noopener">K近邻</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/naive_bayes.py" target="_blank" rel="noopener">朴素贝叶斯</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/pca.py" target="_blank" rel="noopener">主成分分析（PCA）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/fm.py" target="_blank" rel="noopener">分解机</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/rbm.py" target="_blank" rel="noopener">受限玻尔兹曼机（RBM）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/tsne.py" target="_blank" rel="noopener">t分布随机邻居嵌入（t-SNE）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/ensemble/gbm.py" target="_blank" rel="noopener">梯度增强树（也称为GBDT，GBRT，GBM，XGBoost）</a></li><li><a href="https://github.com/rushter/MLAlgorithms/blob/master/mla/rl" target="_blank" rel="noopener">强化学习（深度Q学习）</a></li></ul><h2 id="安装"><a href="https://github.com/rushter/MLAlgorithms#installation" target="_blank" rel="noopener">安装</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;rushter&#x2F;MLAlgorithms</span><br><span class="line"> cd MLAlgorithms </span><br><span class="line">pip install scipy numpy </span><br><span class="line">python setup.py开发</span><br></pre></td></tr></table></figure><h2 id="如何在不安装的情况下运行示例"><a href="https://github.com/rushter/MLAlgorithms#how-to-run-examples-without-installation" target="_blank" rel="noopener">如何在不安装的情况下运行示例</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd MLAlgorithms </span><br><span class="line">python -m examples.linear_models</span><br></pre></td></tr></table></figure><h2 id="如何在docker中运行示例"><a href="https://github.com/rushter/MLAlgorithms#how-to-run-examples-within-docker" target="_blank" rel="noopener">如何在Docker中运行示例</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd MLAlgorithms docker </span><br><span class="line">build -t mlalgorithms 。</span><br><span class="line">docker run --rm -it mlalgorithms bash </span><br><span class="line">python -m examples.linear_models</span><br></pre></td></tr></table></figure><h2 id="贡献"><a href="https://github.com/rushter/MLAlgorithms#contributing" target="_blank" rel="noopener">贡献</a></h2><p>永远欢迎您的贡献！<br />随时改进现有代码，文档或实施新算法。<br />如果您的更改足够大，请提出一个建议。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/15/MLAlgorithms/1.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Minimal and clean examples of machine learning algorithms implementations&lt;/p&gt;
&lt;p&gt;介绍一个常用的机器学习算法的最小和简洁实现的集合：机器学习算法库 &lt;a href=&quot;https://github.com/rushter/MLAlgorithms&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://github.com/rushter/MLAlgorithms&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="dl" scheme="https://2020.iosdevlog.com/tags/dl/"/>
    
      <category term="nn" scheme="https://2020.iosdevlog.com/tags/nn/"/>
    
      <category term="ml" scheme="https://2020.iosdevlog.com/tags/ml/"/>
    
      <category term="algorithm" scheme="https://2020.iosdevlog.com/tags/algorithm/"/>
    
      <category term="python" scheme="https://2020.iosdevlog.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>仿抖音小游戏《潜水艇》-FlappyBird</title>
    <link href="https://2020.iosdevlog.com/2020/03/14/FalppyBird/"/>
    <id>https://2020.iosdevlog.com/2020/03/14/FalppyBird/</id>
    <published>2020-03-14T13:01:39.000Z</published>
    <updated>2020-03-14T13:28:44.786Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://raw.githubusercontent.com/iOSDevLog/FlappySwift/master/FlappySwift.png" alt="" /><figcaption>FlappySwift</figcaption></figure><a id="more"></a><h2 id="flappyswift">FlappySwift</h2><p>An implementation of Flappy Bird and Face Detection in Swift for iOS 11.</p><p><a href="https://www.bilibili.com/video/av96310774/" target="_blank" rel="noopener">B站视频</a></p><h2 id="face-detection">Face Detection</h2><p><a href="https://www.raywenderlich.com/1163620-face-detection-tutorial-using-the-vision-framework-for-ios" target="_blank" rel="noopener">Face Detection Tutorial Using the Vision Framework for iOS</a></p><h2 id="flappybird">FlappyBird</h2><p><a href="https://github.com/fullstackio/FlappySwift" target="_blank" rel="noopener">FlappySwift</a></p><h2 id="github">GitHub</h2><p><a href="https://github.com/iOSDevLog/FlappySwift" target="_blank" rel="noopener" class="uri">https://github.com/iOSDevLog/FlappySwift</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/iOSDevLog/FlappySwift/master/FlappySwift.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;FlappySwift&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="game" scheme="https://2020.iosdevlog.com/categories/game/"/>
    
    
      <category term="iOS" scheme="https://2020.iosdevlog.com/tags/iOS/"/>
    
      <category term="Swift" scheme="https://2020.iosdevlog.com/tags/Swift/"/>
    
      <category term="cv" scheme="https://2020.iosdevlog.com/tags/cv/"/>
    
  </entry>
  
  <entry>
    <title>tf2 CheekSheet</title>
    <link href="https://2020.iosdevlog.com/2020/03/13/tf2/"/>
    <id>https://2020.iosdevlog.com/2020/03/13/tf2/</id>
    <published>2020-03-13T15:34:37.000Z</published>
    <updated>2020-03-14T13:29:46.585Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://2020.iosdevlog.com/2020/03/13/tf2/0.jpg" /></p><p><a href="https://www.aicheatsheets.com/" target="_blank" rel="noopener" class="uri">https://www.aicheatsheets.com/</a></p><a id="more"></a><p><img src="https://2020.iosdevlog.com/2020/03/13/tf2/1.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/13/tf2/2.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/13/tf2/3.jpg" /></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/13/tf2/0.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.aicheatsheets.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://www.aicheatsheets.com/&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="tf2" scheme="https://2020.iosdevlog.com/tags/tf2/"/>
    
      <category term="cheeksheet" scheme="https://2020.iosdevlog.com/tags/cheeksheet/"/>
    
  </entry>
  
  <entry>
    <title>《香农传》</title>
    <link href="https://2020.iosdevlog.com/2020/03/12/Shannon/"/>
    <id>https://2020.iosdevlog.com/2020/03/12/Shannon/</id>
    <published>2020-03-12T09:15:04.000Z</published>
    <updated>2020-03-12T15:30:10.685Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/1.jpg" alt="" /><figcaption>《香农传》</figcaption></figure><p>书名：香农传<br />作者：[美]吉米·索尼，[美]罗伯·古德曼<br />译者：杨晔<br />出版社：中信出版集团<br />出版时间：2019-02<br />ISBN：9787508694801</p><a id="more"></a><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/20.jpg" /></p><p>克劳德·香农的父亲老克劳德·艾尔伍德·香农，1862年出生于美国新泽西州，他曾做过家具推销员、丧葬承办人和遗嘱检验法官。克劳德的母亲玛贝尔·沃尔夫是一位德国移民的女儿，她曾做过教师和校长。1909年，他们的婚礼公告成为盖洛德的头条新闻。这验证了这座城有多么小，也验证了香农夫妇在这一社群里的活跃角色</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/3.jpg" /></p><p>到了克劳德·香农在密歇根大学拍下注册照片的时候，他已经成为一名娴熟的发明家。他的发明包括简易升降机、后院小推车和通过带刺铁丝网传递加密消息的电报系统</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/4.jpg" /></p><p>香农似乎遗传了他的爷爷戴维·香农的才华，他骄傲地持有美国第407130号专利，对洗衣机进行了一系列改进。这个男孩继承了爷爷在机械方面的天赋，对于他来说，家里出了这样一名拥有专利的发明家是一件值得炫耀的事情</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/5.jpg" /></p><p>在香农入学之前，密歇根大学工程学院经历了巨大的发展。在学院的一次公开展览上，学生们“震惊了访客，他们使用20000转/分钟的纸张切割木材，通过液态气体冷冻鲜花，还展示了只用两根细线支撑的瓶子，水流从中缓缓流出——这是罕有人能够解决的难题”。密歇根大学的工程建筑可以满足重工业的要求，正如这间工厂……</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/6.jpg" /></p><p>……以及这个船舶池，学生们在这里测试模型船的流体动力</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/7.jpg" /></p><p>1934年春，克劳德·香农于17岁的时候，在《美国数学月刊》第191页上发表了第一篇学术作品。香农解出了一道数学难题。他阅读这类期刊的行为本身，揭示了他对学术事务非同寻常的关注，而他的解题方法被选中也表明他不是一个普通的人才</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/8.jpg" /></p><p>麻省理工学院的校园是香农初次作为工程师成名的地方，它的设计是建筑师们相互妥协的产物，建筑上方的圆顶秉承了“效率的原则，避免师生做无用功，它相当于最好的工业作品”。它半是庙宇，半是工厂</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/9.jpg" /></p><p>在麻省理工学院，香农加入了一个小组。这个小组旨在使得微分分析仪成为通用机械计算机，助力解决计算电力传输、电话网络等工程难题或宇宙射线和亚原子微粒等高等物理难题。这个项目追随了威廉·汤姆森的步伐，他是一名留着独特胡子的物理学家，被尊称为凯尔文爵士。他在1876年建造了早期的机械计算机</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/10.jpg" /></p><p>在麻省理工学院，香农在业余时间选修了飞行课。这门课的执教教授强烈建议麻省理工学院的校长禁止他继续上课，他认为香农是一个不可多得的人才，不应为可能发生的飞机事故而冒险。校长则拒绝了他的建议：“我怀疑以他智力超群为由，禁止这位年轻人参加飞行课或者武断地剥夺他的机会是明智的。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/11.jpg" /></p><p>微分分析仪是如房间般大小的“大脑”，为了解决问题会日夜不停地运转。“这个由轴、齿轮、线路、滚轮组成的家伙十分可怕，但它确实有效。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/12.jpg" /></p><p>在绝大多数情况下，范内瓦·布什都是20世纪中期美国最有权力的科学家。他在麻省理工学院主持微分分析仪，为总统提供咨询服务，在“二战”期间领导美国的科学家。《科利尔》杂志将他称为“会决定战争胜利或失败的男人”；《时代周刊》将他称作“物理将军”。而且，这些成就中尤其有这么一条：他成为克劳德·香农的第一位导师，也是对他影响最大的导师</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/13.jpg" /></p><p>1939年夏，香农来到了冷泉港，抵达了美国最顶尖的基因实验室，这也是美国最大的科学羞耻之一——优生学记录室。它收藏了大量基因数据，基于此，香农完成了他的理论基因学论文</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/14.jpg" /></p><p>香农拿到奖学金前往负有盛名的普林斯顿高等研究院，但这次经历并不令人愉快。这里见证了他第一段婚姻的失败，以及他对愈演愈烈的第二次世界大战的恐惧；在这里他还与阿尔伯特·爱因斯坦有过几次接触</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/15.jpg" /></p><p>这里是1936年的贝尔实验室综合楼，照片上的视角是从曼哈顿西村的华盛顿街看过去的景象。香农的一名同事回忆道：“大家在贝尔实验室做得非常好，他们做的事在其他人看来根本不可能。”当贝尔实验室的办公场所还在下曼哈顿区（靠近当今的高线公园）的时候，香农签下了这里的全职工作</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/16.jpg" /></p><p>克劳德·香农和他的同事戴维·哈格尔巴格一同在贝尔实验室工作。另一名同事回忆起那段时光：“在这里，我可以任意获取全世界电气工程领域的信息。我所需要的就是拿起电话或者去询问某人，然后便能得到答案。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/17.jpg" /></p><p>桑顿·弗赖伊成立了实验室的数学组，并将香农派到这里。他有一次说，“数学家们都是怪人，这是事实，所以遇到任何足够奇怪而你又不知道如何沟通的人，你就说，‘这家伙是个数学家，把他交给弗赖伊吧’。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/18.jpg" /></p><p>香农和约翰·皮尔斯（如图）同巴尼·奥利弗一起组成了实验室的天才三人组。一位同辈开玩笑道：“他们三个人的智商高到令人难以忍受的程度。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/19.jpg" /></p><p>在曼哈顿，香农是一名单身汉（在第一段婚姻终结之后），他有一间位于格林尼治村的小公寓和一份要求颇高的工作。他保留了一些时间以满足自己古怪的爱好，包括用力弹琴，以及欣赏纽约爵士乐</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/2.jpg" /></p><p>对抗纳粹德国一定程度上是一场“科学战争”，香农在这方面的贡献包括研究密码学、防空火力控制和“绿色大黄蜂”系统（如图），后者是迄今为止最具野心的语言加扰系</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/21.jpg" /></p><p>对香农的信息论研究影响最大的是拉尔夫·哈特利。他1927年关于“信息传递”的论文是当时最接近掌握信息本质的方法，解释了科学家是怎样从物理的角度而非心理的角度思索这一问题的</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/22.jpg" /></p><p>在《通信的数学理论》之前，长达一个世纪的常识与反复进行的工程试验，都认为通信必然会伴有噪声——这是物理世界要求我们付出的代价。然而香农证明了信道噪声是可以被克服的，由A点发出的信息“总是可以”，而不仅仅是“经常能够”在B点被完全接收。他向工程师提供了使信息数字化并将其可靠发送（或者，准确地说，可能伴有少量随机误差）的概念工具，直到香农证实噪声可控之前，该结论一直被当作不可能实现的乌托邦</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/23.jpg" /></p><p>1948年之后，香农被媒体赞誉为科学名人。他接受电视采访，被国家出版物报道，并被授予一些荣誉学位</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/24.jpg" /></p><p>1948年，克劳德·香农认识了贝蒂·摩尔，她是贝尔实验室的一名工作人员，他鼓起勇气邀请她共进晚餐。之后他们又有了第二顿、第三顿，直到他们每天都在一起吃晚餐</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/25.jpg" /></p><p>克劳德·香农和贝蒂·摩尔的关系发展得非常迅速：他们相识于1948年秋，而到了1949年年初，克劳德便求婚了。根据贝蒂的回忆，求婚是以“不太正式”的方式进行的。她不仅有幽默感，而且同他一样热爱数学，这奠定了他们伙伴关系的基础，直到克劳德生命的终结</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/26.jpg" /></p><p>贝蒂为克劳德购买了他的第一辆独轮车，这开启了他与这种机器一辈子的不解之缘。他为自己亲手打造了各种量身定制的独轮车，并在贝尔实验室狭窄的甬道里骑车。这使得访客们对他的灵活性印象深刻</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/27.jpg" /></p><p>即使成了科学名人，香农也仍然是一名发明家。他最著名的发明“忒修斯”是一只能够自动穿越迷宫并“记住”金属乳酪位置的人工老鼠。（倘若乳酪被拿走了，“忒修斯”就只会漫无目的地走来走去。一名科学家说：“这一切都太人性化了。”）</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/28.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/29.jpg" /></p><p>贝尔实验室墨累山园区——“设想与设计未来的地方，这里的未来指的是我们所谓的现在。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/30.jpg" /></p><p>香农建造了世界上最早的弈棋机。它在1949年完工，香农的机器只能控制六枚棋子，聚焦于棋局中的走位。它使用了超过150个继电器计算走棋，它的处理能力使得机器能够在10~15秒做出决定</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/31.jpg" /></p><p>“我是机器，你也是机器，我们都会思考，不是吗？”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/32.jpg" /></p><p>香农为人工智能设定了四个目标：到2001年，创造出打败世界冠军的象棋程序；写出被《纽约客》认可的诗文的诗歌程序；写出能够证明难以捉摸的黎曼假设的数学程序；以及“最重要的”，设计出收益超过50%的选股软件。他半开玩笑地说，“这些目标可能意味着逐步淘汰愚蠢的、熵增加的、好战的人类，转而支持更加合乎逻辑的、节约能源的、友善的物种，即计算机。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/33.jpg" /></p><p>诺伯特·维纳（图片中间，右侧为香农，左侧为麻省理工学院校长朱利叶斯·斯特拉顿）曾是一名神童，“控制论”的提出者，也是唯一可能挑战香农“信息论之父”地位的人</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/34.jpg" /></p><p>香农在马萨诸塞州温彻斯特买下了一幢房子，是一处位于麻省理工学院以北8千米的近郊住宅区。这幢房子建于1858年，是为天才发明家托马斯·杰斐逊的曾孙女艾伦·德怀特修建的。它占地约48.6平方千米，受蒙蒂塞洛启发而设计</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/35.jpg" /></p><p>在一次前往俄罗斯的旅程中，香农想要与苏联国际象棋冠军、计算机工程师米哈伊尔·鲍特维尼克下一场友谊赛。鲍特维尼克并没有给予足够的重视，直至香农在对弈中吃掉了他的马和兵。在走了42步之后，香农推倒了他的王，认输了。但能与鲍特维尼克对弈几十步，仍然为香农赢得了值得终生吹嘘的资本，因为前者一直被认为是最具天赋的棋手之一</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/36.jpg" /></p><p>1957年，香农回到麻省理工学院做教授。然而，他的研究生名额并未招满，“你必须有足够的自信，才能请求像香农这样的人做你的导师”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/37.jpg" /></p><p>1967年2月6日，林登·B.约翰逊总统向克劳德·香农颁发了美国国家科学奖奖章，以表彰他“对通信和信息处理的数学理论的杰出贡献”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/38.jpg" /></p><p>早期，香农在麻省理工学院的讲座场场爆满，但这些都比不过他做的关于股票市场的报告，这场在学校里最大的报告厅内举办的讲座挤满了听众</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/39.jpg" /></p><p>在美国马萨诸塞州，香农教授留起了胡子，继续杂耍事业。他也完全沉浸在自己发明创造的兴趣爱好里，在自己家颇具规模的工作坊里设计出许多自己最著名的发明</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/40.jpg" /></p><p>世界上第一台可穿戴计算机是由香农和爱德华·索普开发的，可用来计算轮盘赌一类的东西。他们佩戴着它，在拉斯维加斯的赌场里成功了几次，却最终放弃了这个项目，因为他们惧怕卷入与黑手党的麻烦之中</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/41.jpg" /></p><p>香农使用建造者套件模仿W.C.菲尔兹打造了这个机器人，它可以抛接三个球。球从钢鼓上弹起，机器人以摇摆的动作挥舞桨臂。“每次手臂摆下来它都能接住球，而当手臂摆上去它又会抛出球。”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/42.jpg" /></p><p>香农自己既是一名技艺高超的杂耍者，也是第一位将杂耍数学写成论文的作者。他写道，他的读者应当“尽量不要忘记杂耍的诗歌、喜剧和音乐……我听起来是不是很自以为是？”</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/43.jpg" /></p><p>香农在生命中的最后几年，仍旧保持着骑独轮车的爱好</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/44.jpg" /></p><p>香农终其一生都在追求满足自己的好奇心，认真地做游戏：他是罕见的科学天才，像满足于探索数字电路一样，满足于制作杂耍机器人和喷射小号</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/45.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/46.jpg" /></p><p>六步解法</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/52.jpg" /></p><h2 id="庥省理工学院">庥省理工学院</h2><p>乔治·布尔</p><ul><li>和（And）<code>*</code></li><li>或（Or）<code>+</code></li><li>非（Not）<code>‘</code></li><li>如果（If）</li></ul><p>电流</p><ul><li>串联 =&gt; “和”</li><li>并联 =&gt; “或”</li><li>两个并联 =&gt; 1+1=1</li></ul><h2 id="贝尔实验室">贝尔实验室</h2><h2 id="密码学研究">密码学研究</h2><h2 id="与图灵的友谊">与图灵的友谊</h2><p>1942年，图灵跟随英国政府发起的军事密码项目访问团来到美国。</p><p>1936年，他设计出图灵机，这一里程碑式的思想实验为现代电脑的发明打下了理论基础。</p><p>除此之外，图灵还开始破解密码。</p><h2 id="从情报到信息">从情报到信息</h2><p><code>情报减去含义即为信息。</code></p><ol type="1"><li>奈奎斯特曾使用“情报”这个模糊的概念，</li><li>哈特利曾努力地解释撇开心理学和语义学的价值，</li><li>而到香农的时代，他已经理所当然地认为含义是可以被忽略的。</li></ol><p>最简本质</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/64.jpg" /></p><ul><li>信源生成信息。</li><li>发射器将信息转码成能够发射的信号。</li><li>信道是信号通过的媒介。</li><li>噪声源代表了信号在被接收的过程中遭到的扭曲与破坏。</li><li>接收器解码消息，与发射器原理相反。</li><li>信宿是信息的接收者。</li></ul><p>这种精简模式的妙处在于它的普遍适用性。信息对于一则故事来说无意义，却能将它播放出来，包括人的信息、电路中的信息、神经元中的信息、血液中的信息。你对着电话听筒讲话（信源）；电话将你声音的声压编码成电信号（发射器）；信号通过电线（信道）；附近的电线会干扰信号（噪声）；信号被解码回声音（接收器）；声音到达另一个人的耳中（信宿）。</p><p>在细胞中，DNA链指导蛋白质的生成（信源）；它通过编码转录储存在信使RNA链中（发射器）；信使RNA携带代码到细胞的蛋白质合成处（信道）；RNA编码中的一个“字母”随机地在“点突变”（噪声）中切换；每3个“字母”代码被翻译成氨基酸–蛋白质的构件（接收器）；氨基酸被结合到蛋白质链中。DNA由此得到复制（信宿）。</p><p>香农认为，信息科学仍然未能发现对信息至关重要的东西——<code>概率的本质</code>。</p><p>新生科学需要新的计量单位，或者至少要证明他们一直谈论的概念最终能否被数字捕捉。香农研究的信息科学的新单位要表达选择的基本情况。由于它是在0或1之间的选择，所以它是“二进制数字”。在香农的全部设计中，仅有有限的部分是他允许与其他人进行合作的，这包括他在午餐时提出与贝尔实验室的同事们商讨一个更简洁的名字。二进制符号“binit”和二进制数字“bigit”在经过考量后被放弃了，最终赢得大家认可的方案是由一名在贝尔实验室工作的普林斯顿大学的教授约翰·图基提出的 <code>“比特”（bit）</code>。</p><p>比特是在两个等概率的可能性之中进行选择后所产生的信息量。所以<code>“一台拥有两种稳定状态的设备……能够存储1比特信息”</code>。这种设备的位元（包括具有两种位置的开关，具有正反两面的硬币，以及具有两种状态的数字）不在选择的结果之中，而在可能选择的数量以及进行选择的概率之中。两台这样的器件能够代表全部4种选择，并且可被称作存储2比特。</p><blockquote><p>因为香农的标准是呈对数出现的（以2为基础，换句话说，就是“倒过来”将2赋予给定数字的权力），每当可供选择的数量平方之后，比特的数量将增加1倍：</p></blockquote><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/65.jpg" /></p><blockquote><p>信息到底衡量了什么？</p></blockquote><p><strong>它衡量了我们所克服的不确定性。</strong></p><p>它衡量了我们学习新事物的可能性，或者更具体地说，当一件事物承载了关于其他事物的信息（正如计数器能够告诉我们一个物理量，或一本书能够告诉我们人生），它所涵盖的信息数量反映了未知情况的减少。能够解析最大程度的不确定性的消息，即以最公平的方式从最广泛的符号集合中选择出的包含最丰富的信息。但当一切都充满确定性的时候，并不能产生信息，因为没有什么可以传达。</p><p>香农用 <code>抛硬币</code> 事件（判断给定正反面的可能性，这里称作p，有0、50%、100%三种情况）展示了利益攸关的信息量：</p><p><img src="https://2020.iosdevlog.com/2020/03/12/Shannon/66.jpg" /></p><p>H =–p log p – q log q</p><p>在这一公式中，p和q分别是两种结果的概率（硬币的任一面或者能被传输的任一符号），两者的数值加起来刚好为100%。</p><h2 id="维纳的控制论">维纳的控制论</h2><blockquote><p>维纳自以为到了家，笨拙地摸索出钥匙，却发现打不开门。他转向街道上玩耍的孩子们问道：“你们能告诉我维纳家住在哪里吗？”一个小女孩回答道：“爸爸，跟我走。妈妈派我来告诉你我们的新家在哪里。”</p></blockquote><p>他对这一领域的贡献是广泛而深入的：量子力学、布朗运动、控制论、随机过程、谐波分析。他涉猎了几乎所有数学世界的领域。1948年，他的简历上已经布满了闪闪发光的奖项和荣誉。维纳的合作伙伴与联系人名单也同样引人注目：范内瓦·布什、G. H.哈代、伯特兰·罗素、保罗·莱维、库尔特·哥德尔……和克劳德·香农。</p><p>《控制论》</p><h2 id="人造机器">人造机器</h2><blockquote><p>机器能够思考吗？它会痛吗？我们可以说人体也是机器吗？无疑，人体和机器非常相似，但是机器绝对不会思考！我们这样说有什么实证根据吗？并没有，我们可以这样说人，说一切可以思考的东西；而我们也可以这样说布娃娃，毫无疑问，还有鬼神。</p></blockquote><p>——路德维希·维特根斯坦</p><blockquote><p>我是机器，你也是机器，我们都会思考，不是吗？</p></blockquote><p>——克劳德·香农</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/12/Shannon/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《香农传》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：香农传&lt;br /&gt;
作者：[美]吉米·索尼，[美]罗伯·古德曼&lt;br /&gt;
译者：杨晔&lt;br /&gt;
出版社：中信出版集团&lt;br /&gt;
出版时间：2019-02&lt;br /&gt;
ISBN：9787508694801&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>看见统计</title>
    <link href="https://2020.iosdevlog.com/2020/03/11/seeing-theory/"/>
    <id>https://2020.iosdevlog.com/2020/03/11/seeing-theory/</id>
    <published>2020-03-11T10:51:29.000Z</published>
    <updated>2020-03-11T15:44:36.263Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/11/seeing-theory/1.png" alt="" /><figcaption>看见统计</figcaption></figure><p>看见统计由Daniel Kunin在布朗大学读本科的时候开始制作。致力于用数据可视化让统计概念更容易理解。 (数据可视化使用Mike Bostock的javascript库D3.js制作。)</p><a id="more"></a><h2 id="基础概率论">基础概率论</h2><p>主要介绍了概率论中的一些基本概念</p><h3 id="随机事件概率事件">随机事件(概率事件)</h3><p>生活中充满了随机性。概率论是一门用数学语言来刻画这些随机事件的学科。一个随机事件的概率是一个介于0与1之间的实数，这个实数的大小反映了这个事件发生的可能性。因此，概率为0意味着这个事件不可能发生（不可能事件），概率为1意味着这个事件必然发生（必然事件）。</p><p>以一个投掷一枚公平的硬币（出现正面和反面的概率相等，均为1/2）的经典的概率实验为例：。在现实中，如果我们重复抛一枚硬币，出现正面的频率可能不会恰好是50%。但是当抛硬币的次数增加时，出现正面的概率会越来越接近50%。</p><p>如果硬币两面的重量不一样， 出现正面的概率就和出现反面的概率不一样了。上下拖动屏幕右侧蓝色柱状图来改变硬币正面和反面的的重量分布。如果我们用一个实数来代表抛硬币的结果：比如说1表示正面，0表示反面，那么我们称这个数为 随机变量。</p><h3 id="期望">期望</h3><p>一个随机变量的期望刻画的是这个随机变量的概率分布的“中心”。简而言之，当有无穷多来自同一个概率分布的独立样本时，它们的平均值就是期望。数学上对期望的定义是以概率（或密度）为权重的加权平均值。</p><p><span class="math display">\[\mathrm{E}[X]=\sum_{x \in \mathcal{X}} x P(x)\]</span></p><p>现在以另一个经典的概率实验为例：扔一枚公平的骰子，每一面出现的概率相等，均为1/6。当试验的次数越来越多时，扔出的结果的平均值慢慢趋向于它的期望3.5。</p><h3 id="方差">方差</h3><p>如果说随机变量的期望刻画了它的概率分布的“中心”，那么方差则刻画了概率分布的分散度。方差的定义是一个随机变量与它的期望之间的差的平方的加权平均值。这里的权重仍然是概率（或者密度）。</p><p><span class="math display">\[\operatorname{Var}(X)=\mathrm{E}\left[(X-\mathrm{E}[X])^{2}\right]\]</span></p><p>随机从下面十张牌中抽牌。当抽取的次数越来越多时，可以观察到样本平方差的平均值（绿色）逐渐趋向于它的方差（蓝色）。</p><h2 id="进阶概率论">进阶概率论</h2><p>概率论中的一些核心知识</p><h3 id="集合论">集合论</h3><p>广而言之，一个集合指的是一些物体的总体。在概率论中，我们用一个集合来表示一些事件的组合。比如，我们可以用集合 <span class="math inline">\(\{2,4,6\}\)</span> 来表示“投骰子投出偶数”这个事件。因此我们有必要掌握一些基本的集合的运算。</p><h3 id="古典概型">古典概型</h3><p>古典概型本质上就是数数。但是在概率论中，数数有时候比想象中要困难的多。因为我们有时要数清楚符合一些性质的事件或者轨道个数的，而这些性质往往比较复杂，因此数数的任务也变得困难起来。假设我们有一袋珠子，每个珠子的颜色都不相同。如果我们无放回地从袋子里抽取珠子，一共有多少种可能出现的颜色序列（排列）呢？有多少种可能出现的没有顺序的序列（组合）呢？</p><h3 id="条件概率">条件概率</h3><p>条件概率让我们可以利用已有的信息。举个例子，在今天多云 的情况下，我们会估计“明天下雨”的概率小于“今天下雨”。这种基于已有的相关信息得出的概率称为条件概率。</p><p>数学上，条件概率的计算一般会把的样本空间缩小到一个我们已知信息的事件。再以之前举的下雨为例，我们现在只考虑所有前一天多云的日子，而不是考虑所有的日子。然后我们确定在这些天中有多少天下雨，这些下雨天数在所有我们考虑的天数中的比例即为条件概率。</p><h2 id="概率分布">概率分布</h2><p>描述了随机变量取值的规律</p><h3 id="随机变量">随机变量</h3><p>随机变量是一个函数，它用数字来表示一个可能出现的事件。你可以定义你自己的随机变量，然后生成一些样本来观察它的经验分布。</p><h3 id="离散型和连续型随机变量">离散型和连续型随机变量</h3><p>常见的随机变量类型有两种：</p><ul><li>离散型随机变量</li></ul><p>一个离散型随机变量可能的取值范围只有有限个或可列个值。离散型随机变量的定义是：如果 <span class="math inline">\(X\)</span> 是一个随机变量，存在非负函数 <span class="math inline">\(f(x)\)</span> 和 <span class="math inline">\(F(X)\)</span>,使得</p><p><span class="math display">\[\begin{array}{l}P(X=x)=f(x) \\P(X&lt;x)=F(x)\end{array}\]</span></p><p>则称 <span class="math inline">\(X\)</span> 是一个离散型随机变量。</p><p><code>伯努利分布(Bernoulli)</code></p><p>如果一个随机变量 <span class="math inline">\(X\)</span> 只取值 <span class="math inline">\(0\)</span> 或 <span class="math inline">\(1\)</span>，概率分布是</p><p><span class="math display">\[P(X=1)=p, \quad P(X=0)=1-p\]</span></p><p>则称 <span class="math inline">\(X\)</span> 符合伯努利分布(Bernoulli)。我们常用伯努利分布来模拟只有两种结果的试验，如抛硬币。</p><p>在概率论中，概率质量函数（probability mass function，简写为 <code>pmf</code>）是离散随机变量在各特定取值上的概率。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>PMF</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; p)=\left\{\begin{array}{ll}p &amp; \text { if } x=1 \\ 1-p &amp; \text { if } x=0\end{array}\right.\)</span></td><td><span class="math inline">\(p\)</span></td><td><span class="math inline">\(p(1-p)\)</span></td></tr></tbody></table><p><code>二项分布(Binomial)</code></p><p>如果随机变量 <span class="math inline">\(X\)</span> 是 <span class="math inline">\(n\)</span> 个参数为p的独立伯努利随机变量之和，则称 <span class="math inline">\(X\)</span> 是二项分布(binomial)。我们常用二项分布来模拟若干独立同分布的伯努利试验中的成功次数。比如说，抛五次硬币，其中正面的次数可以用二项分布来表示：<span class="math inline">\(\operatorname{Bin}\left(5, \frac{1}{2}\right)\)</span>。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>PMF</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; n, p)=\left(\begin{array}{l}n \\ x\end{array}\right) p^{x}(1-p)^{n-x}\)</span></td><td><span class="math inline">\(np\)</span></td><td><span class="math inline">\(np(1-p)\)</span></td></tr></tbody></table><p><code>几何分布(Geometric)</code></p><p>一个服从几何分布的随机变量表示了在重复独立同分布的伯努利试验中获得一次成功所需要的试验此时。比如说，如果我们重复投一枚骰子，我们则可以用几何分布来表示投出一个6所需要的试验次数。</p><table><thead><tr class="header"><th>PMF</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; p)=(1-p)^{x} p\)</span></td><td><span class="math inline">\(\frac{1}{p}\)</span></td><td><span class="math inline">\(\frac{1-p}{p^{2}}\)</span></td></tr></tbody></table><p><code>泊松分布(Poisson)</code></p><p>表示了一个事件在固定时间或者空间中发生的次数。泊松分布的参数 <span class="math inline">\(λ\)</span> 是这个时间发生的频率。比方说，我们可以用泊松分布来刻画流星雨或者足球比赛中的进球数。</p><table><thead><tr class="header"><th>PMF</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; \lambda)=\frac{\lambda^{x} e^{-\lambda}}{x !}\)</span></td><td><span class="math inline">\(\lambda\)</span></td><td><span class="math inline">\(\lambda\)</span></td></tr></tbody></table><p><code>负二项分布(Negative Binomial)</code></p><p>一个负二项分布的随机变量X表示的是若干独立同分布的参数为p的伯努利试验中获得r次失败前成功的次数。比方说，如果我们重复抛一枚硬币，我们则可以用负二项分布来表示抛出三次反面之前抛出正面的次数。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>PMF</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; n, r, p)=\left(\begin{array}{c}x+r-1 \\ x\end{array}\right) p^{x}(1-p)^{r}\)</span></td><td><span class="math inline">\(\frac{p r}{1-p}\)</span></td><td><span class="math inline">\(\frac{p r}{(1-p)^{2}}\)</span></td></tr></tbody></table><p><code>概率分布表</code></p><table><colgroup><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>PMF</th><th style="text-align: center;">期望</th><th style="text-align: center;">方差</th></tr></thead><tbody><tr class="odd"><td>伯努利分布(Bernoulli)</td><td><span class="math inline">\(f(x ; p)=\left\{\begin{array}{ll}p &amp; \text { if } x=1 \\ 1-p &amp; \text { if } x=0\end{array}\right.\)</span></td><td style="text-align: center;"><span class="math inline">\(p\)</span></td><td style="text-align: center;"><span class="math inline">\(p(1-p)\)</span></td></tr><tr class="even"><td>二项分布(Binomial)</td><td><span class="math inline">\(f(x ; n, p)=\left(\begin{array}{l}n \\ x\end{array}\right) p^{x}(1-p)^{n-x}\)</span></td><td style="text-align: center;"><span class="math inline">\(np\)</span></td><td style="text-align: center;"><span class="math inline">\(np(1-p)\)</span></td></tr><tr class="odd"><td>几何分布(Geometric)</td><td><span class="math inline">\(f(x ; p)=(1-p)^{x} p\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{1}{p}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{1-p}{p^{2}}\)</span></td></tr><tr class="even"><td>泊松分布(Poisson)</td><td><span class="math inline">\(f(x ; \lambda)=\frac{\lambda^{x} e^{-\lambda}}{x !}\)</span></td><td style="text-align: center;"><span class="math inline">\(\lambda\)</span></td><td style="text-align: center;"><span class="math inline">\(\lambda\)</span></td></tr><tr class="odd"><td>负二项分布(Negative Binomial)</td><td><span class="math inline">\(f(x ; n, r, p)=\left(\begin{array}{c}x+r-1 \\ x\end{array}\right) p^{x}(1-p)^{r}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{p r}{1-p}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{p r}{(1-p)^{2}}\)</span></td></tr></tbody></table><ul><li>连续型随机变量</li></ul><p>连续型随机变量可能取值的范围是一个无限不可数集合（如全体实数)。连续型随机变量的定义是：设X为随机变量，存在非负函数f(x)使得：</p><p><span class="math display">\[\begin{aligned}P(a \leq X \leq b) &amp;=\int_{a}^{b} f(x) d x \\P(X&lt;x) &amp;=F(x)\end{aligned}\]</span></p><p><code>均匀分布(Uniform)</code></p><p>如果随机变量X在其支撑集上所有相同长度的区间上有相同的概率，即如果 <span class="math inline">\(b_{1}-a_{1}=b_{2}-a_{2}\)</span>,则</p><p><span class="math display">\[P\left(X \in\left[a_{1}, b_{1}\right]\right)=P\left(X \in\left[a_{2}, b_{2}\right]\right)\]</span></p><p>那么我们称 <span class="math inline">\(X\)</span> 服从均匀分布(Uniform)。比方说，我们一般可以假设人在一年中出生的概率是相等的，因此可以用均匀分布来模拟人的出生时间。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; a, b)=\left\{\begin{array}{l}\frac{1}{b-a} \text { for } x \in[a, b] \\ 0 \quad \text { otherwise }\end{array}\right.\)</span></td><td><span class="math inline">\(\frac{a+b}{2}\)</span></td><td><span class="math inline">\(\frac{(b-a)^{2}}{12}\)</span></td></tr></tbody></table><p><code>正态分布/高斯分布(Normal)</code></p><p>正态分布（也称高斯分布）的密度函数是一个钟形曲线。科学中常用正态分布来模拟许多小效应的叠加。比方说，我们知道人的身高是许多微小的基因和环境效应的叠加。因此可以用正态分布来表示人的身高，</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f\left(x ; \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\)</span></td><td><span class="math inline">\(\mu\)</span></td><td><span class="math inline">\(\sigma^{2}\)</span></td></tr></tbody></table><p><code>学生t分布(Student T)</code></p><p>学生t分布（也称t分布）往往在估计正态总体期望时出现。当我们只有较少的样本和未知的方差时，许多大样本性质并不适用，此时我们则需要用到t分布。</p><table><thead><tr class="header"><th>概率分布</th><th>说明</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(\frac{Z}{\sqrt{U / k}}\)</span></td><td><span class="math inline">\(Z \sim N(0,1)\)</span> <span class="math inline">\(U \sim \chi_{k}\)</span></td><td><span class="math inline">\(0\)</span></td><td><span class="math inline">\(\frac{k}{k-2}\)</span></td></tr></tbody></table><p><code>卡方分布(Chi Squared)</code></p><p>如果随机变量 <span class="math inline">\(X\)</span> 是 <span class="math inline">\(k\)</span> 个独立的标准正态随机变量的平方和，则称 <span class="math inline">\(X\)</span> 是自由度为k的卡方随机变量：<span class="math inline">\(X \sim \chi_{k}^{2}\)</span>. 卡方分布常见于假设检验和构造置信区间.</p><table><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(\sum_{i=1}^{k} Z_{i}^{2} \quad Z_{i} \stackrel{i: i, d}{\sim} N(0,1)\)</span></td><td><span class="math inline">\(k\)</span></td><td><span class="math inline">\(2 k\)</span></td></tr></tbody></table><p><code>指数分布(Exponential)</code></p><p>指数分布可以看作是几何分布的连续版本，其常用于描述等待时间。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; \lambda)=\left\{\begin{array}{ll}\lambda e^{-\lambda x} &amp; \text { if } x \geq 0 \\ 0 &amp; \text { otherwise }\end{array}\right.\)</span></td><td><span class="math inline">\(\frac{1}{\lambda}\)</span></td><td><span class="math inline">\(\frac{1}{\lambda^{2}}\)</span></td></tr></tbody></table><p><code>F分布(F)</code></p><p>F分布(Fisher–Snedecor分布)常在假设检验中出现，一个比较有名的例子是 方差分析。</p><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(\begin{array}{ll}\frac{U_{1} / d_{1}}{U_{2} / d_{2}} &amp; U_{1} \sim \chi_{d_{1}} \\ &amp; U_{2} \sim \chi_{d_{2}}\end{array}\)</span></td><td><span class="math inline">\(\frac{d_{2}}{d_{2}-2}\)</span></td><td><span class="math inline">\(\frac{2 d_{2}^{2}\left(d_{1}+d_{2}-2\right)}{d_{1}\left(d_{2}-2\right)^{2}\left(d_{2}-4\right)}\)</span></td></tr></tbody></table><p><code>Gamma分布(Gamma)</code></p><p>Gamma分布是一组连续型概率密度。</p><blockquote><p>指数分布和卡方分布是Gamma分布的两个特殊情形。</p></blockquote><table><colgroup><col style="width: 33%" /><col style="width: 33%" /><col style="width: 33%" /></colgroup><thead><tr class="header"><th>概率分布</th><th>期望</th><th>方差</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(f(x ; k, \theta)=\frac{1}{\Gamma(k) \theta^{k}} x^{k-1} e^{-\frac{x}{\theta}}\)</span></td><td><span class="math inline">\(k\theta\)</span></td><td><span class="math inline">\(k\theta^{2}\)</span></td></tr></tbody></table><p><code>连续概率分布表</code></p><table><colgroup><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /></colgroup><thead><tr class="header"><th>连续分布</th><th>概率分布</th><th style="text-align: center;">期望</th><th style="text-align: center;">方差</th></tr></thead><tbody><tr class="odd"><td>均匀分布(Uniform)</td><td><span class="math inline">\(f(x ; a, b)=\left\{\begin{array}{l}\frac{1}{b-a} \text { for } x \in[a, b] \\ 0 \quad \text { otherwise }\end{array}\right.\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{a+b}{2}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{(b-a)^{2}}{12}\)</span></td></tr><tr class="even"><td>正态分布/高斯分布(Normal)</td><td><span class="math inline">\(f\left(x ; \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\)</span></td><td style="text-align: center;"><span class="math inline">\(\mu\)</span></td><td style="text-align: center;"><span class="math inline">\(\sigma^{2}\)</span></td></tr><tr class="odd"><td>学生t分布(Student T)</td><td><span class="math inline">\(\frac{Z}{\sqrt{U / k}}\)</span></td><td style="text-align: center;"><span class="math inline">\(0\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{k}{k-2}\)</span></td></tr><tr class="even"><td>卡方分布(Chi Squared)</td><td><span class="math inline">\(\sum_{i=1}^{k} Z_{i}^{2} \quad Z_{i} \stackrel{i: i, d}{\sim} N(0,1)\)</span></td><td style="text-align: center;"><span class="math inline">\(k\)</span></td><td style="text-align: center;"><span class="math inline">\(2 k\)</span></td></tr><tr class="odd"><td>指数分布(Exponential)</td><td><span class="math inline">\(f(x ; \lambda)=\left\{\begin{array}{ll}\lambda e^{-\lambda x} &amp; \text { if } x \geq 0 \\ 0 &amp; \text { otherwise }\end{array}\right.\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{1}{\lambda}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{1}{\lambda^{2}}\)</span></td></tr><tr class="even"><td>F分布(F)</td><td><span class="math inline">\(\begin{array}{ll}\frac{U_{1} / d_{1}}{U_{2} / d_{2}} &amp; U_{1} \sim \chi_{d_{1}} \\ &amp; U_{2} \sim \chi_{d_{2}}\end{array}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{d_{2}}{d_{2}-2}\)</span></td><td style="text-align: center;"><span class="math inline">\(\frac{2 d_{2}^{2}\left(d_{1}+d_{2}-2\right)}{d_{1}\left(d_{2}-2\right)^{2}\left(d_{2}-4\right)}\)</span></td></tr><tr class="odd"><td>Gamma分布(Gamma)</td><td><span class="math inline">\(f(x ; k, \theta)=\frac{1}{\Gamma(k) \theta^{k}} x^{k-1} e^{-\frac{x}{\theta}}\)</span></td><td style="text-align: center;"><span class="math inline">\(k\theta\)</span></td><td style="text-align: center;"><span class="math inline">\(k\theta^{2}\)</span></td></tr></tbody></table><h3 id="中心极限定理">中心极限定理</h3><p>中心极限定理告诉我们，对于一个（性质比较好的）分布，如果我们有足够大的独立同分布的样本，其样本均值会（近似地）呈正态分布。样本数量越大，其分布与正态越接近。</p><h2 id="统计推断">统计推断</h2><p>通过观察数据来确定背后的概率分布</p><h3 id="频率学派">频率学派</h3><h4 id="点估计理论">点估计理论</h4><p>统计学中一个主要的问题是估计参数。我们用一个取值为样本的函数来估计我们感兴趣的参数，并称这个函数为估计量。这里我们用一个估计圆周率π的例子来具体说明这个想法。 我们知道π可以由圆与其外切正方形的面积比来表示：</p><h4 id="置信区间">置信区间</h4><p>与点估计不同，置信区间用估计的是一个参数的范围。一个置信区间对应着一个置信水平：一个置信水平为95%的置信区间表示这个置信区间包含了真实参数的概率为95%。</p><h4 id="bootstrap方法">Bootstrap方法</h4><p>许多频率学派的统计推断侧重于使用一些“性质比较良好”的估计量。但是我们知道这些统计量本身是样本的函数，因此往往比较难分析它们自己的概率分布。而Bootstrap方法则给我们提供了一种方便的近似确定估计量性质的方法。下面我们通过一个例子来说明Bootstrap方法。假设我们现在有 <span class="math inline">\(n\)</span> 个独立的样本 <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>，基于这些样本我们就有了一个经验分布函数：</p><p><span class="math display">\[F_{n}(x)=\sum_{i=1}^{n} 1_{\left\{X_{i} \leq x\right\}}\]</span></p><p>我们可以重复根据这个经验分布函数生成样本，利用这些新的样本来估计元样本均值的标准差。</p><h3 id="贝叶斯学派">贝叶斯学派</h3><p>用数据来更新特定假设的概率</p><h4 id="贝叶斯公式">贝叶斯公式</h4><h4 id="似然函数">似然函数</h4><p><span class="math display">\[L(\theta | x)=P(x | \theta)\]</span></p><p>似然函数的概念在频率学派和贝叶斯学派中都有重要的作用。</p><h4 id="从先验概率到后验概率">从先验概率到后验概率</h4><p>贝叶斯统计的核心思想是利用观察到的数据来更新先验信息。</p><h2 id="回归分析">回归分析</h2><p>建立两个变量之间线性模型的方法</p><h3 id="最小二乘法">最小二乘法</h3><p>最小二乘法是一个估计线性模型参数的方法。这个方法的目标是找到一组线性模型参数，使得这个模型预测的数据和实际数据间的平方误差达到最小。</p><h3 id="相关性">相关性</h3><p>相关性是一种刻画两个变量之间线性关系的度量。相关性的数学定义是</p><p><span class="math display">\[r=\frac{s_{x y}}{\sqrt{s_{x x}} \sqrt{s_{y y}}}\]</span></p><p>其中</p><p><span class="math display">\[\begin{aligned}&amp;\begin{array}{l}s_{x y}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right) \\s_{x x}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\end{array}\\&amp;s_{y y}=\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}\end{aligned}\]</span></p><p>由上述定义我们可以看出 <span class="math inline">\(r \in[-1.1]\)</span>。</p><h3 id="方差分析">方差分析</h3><p>方差分析（ANONA，Analysis of Variace）是一种检验各组数据是否有相同均值的统计学方法。方差分析将t检验从检验两组数据均值推广到检验多组数据均值，其主要方法是比较组内和组间平方误差。</p><p>可视化网站：<a href="https://seeing-theory.brown.edu/cn.html" target="_blank" rel="noopener" class="uri">https://seeing-theory.brown.edu/cn.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/11/seeing-theory/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;看见统计&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;看见统计由Daniel Kunin在布朗大学读本科的时候开始制作。致力于用数据可视化让统计概念更容易理解。 (数据可视化使用Mike Bostock的javascript库D3.js制作。)&lt;/p&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://2020.iosdevlog.com/categories/math/"/>
    
    
      <category term="Godot" scheme="https://2020.iosdevlog.com/tags/Godot/"/>
    
  </entry>
  
  <entry>
    <title>《机器学习：Python实践》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/03/10/9787121331107/"/>
    <id>https://2020.iosdevlog.com/2020/03/10/9787121331107/</id>
    <published>2020-03-10T13:53:06.000Z</published>
    <updated>2020-03-11T15:48:23.891Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/1.jpg" alt="" /><figcaption>《机器学习：Python实践》</figcaption></figure><p>书名：机器学习：Python实践<br />作者：魏贞原出版社：电子工业出版社<br />出版时间：2018-01<br />ISBN：9787121331107</p><p>GitHub: <a href="https://github.com/weizy1981/MachineLearning" target="_blank" rel="noopener" class="uri">https://github.com/weizy1981/MachineLearning</a></p><p>这本书是写给对机器学习感兴趣和立志学习机器学习的 <code>Python</code> 程序员的，是一本关于机器学习实践的书籍。</p><a id="more"></a><p><strong>这不是一本关于机器学习的教科书</strong></p><p>本书只会简单介绍机器学习的基本原理和算法。在这里假设你已经掌握了机器学习的基础知识，或者有能力自己来完成机器学习的基础知识的学习。</p><p><strong>这不是一本算法书</strong></p><p>本书不会详细介绍机器学习的算法。在这里假设你已经掌握了机器学习的相关算法，或者能够独立完成相关算法知识的学习。这不是一本关于Python的语法书。</p><p><strong>本书不会花费大量的篇幅来讲解Python的语法</strong></p><p>在这里假设你是一个经验丰富的开发人员，能够快速掌握一种类似于C语言的开发语言。</p><h2 id="内容简介">内容简介</h2><p>本书系统地讲解了机器学习的基本知识，以及在实际项目中使用机器学习的基本步骤和方法；详细地介绍了在进行数据处理、分析时怎样选择合适的算法，以及建立模型并优化等方法，通过不同的例子展示了机器学习在具体项目中的应用和实践经验，是一本非常好的机器学习入门和实践的书籍。</p><p>不同于很多讲解机器学习的书籍，本书以实践为导向，使用scikit-learn作为编程框架，强调简单、快速地建立模型，解决实际项目问题。读者通过对本书的学习，可以迅速上手实践机器学习，并利用机器学习解决实际问题。</p><h2 id="第一部分-初始">第一部分 初始</h2><blockquote><p>像一个优秀的工程师一样使用机器学习，而不要像一个机器学习专家一样使用机器学习方法。</p></blockquote><p>—— Google</p><h3 id="初识机器学习">初识机器学习</h3><p>学习机器学习的误区</p><ol type="1"><li>必须非常熟悉Python的语法和擅长Python的编程。</li><li>非常深入地学习和理解在scikit-learn中使用的机器学习的理论和算法。</li><li>避免或者很少参与完成项目，除机器学习之外的部分。</li></ol><h4 id="什么是机器学习">什么是机器学习</h4><p>机器学习（Machine Learning, ML）是一门多领域的交叉学科，涉及概率论、统计学、线性代数、算法等多门学科。</p><p>它专门研究计算机如何模拟和学习人的行为，以获取新的知识或技能，重新组织已有的知识结构使之不断完善自身的性能。机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。</p><h4 id="python-中的机器学习">Python 中的机器学习</h4><p>利用机器学习的预测模型来解决问题共有六个基本步骤</p><ol type="1"><li>定义问题：研究和提炼问题的特征，以帮助我们更好地理解项目的目标。</li><li>数据理解：通过描述性统计和可视化来分析现有的数据。</li><li>数据准备：对数据进行格式化，以便于构建一个预测模型。</li><li>评估算法：通过一定的方法分离一部分数据，用来评估算法模型，并选取一部分代表数据进行分析，以改善模型。</li><li>优化模型：通过调参和集成算法提升预测结果的准确度。</li><li>结果部署：完成模型，并执行模型来预测结果和展示。</li></ol><p><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/3.jpg" /></p><h4 id="学习机器学习的原则">学习机器学习的原则</h4><ul><li>学习机器学习是一段旅程。<ul><li>需要知道自己具备的技能、目前所掌握的知识，以及明确要达到的目标。要实现自己的目标需要付出时间和辛勤的工作，但是在目标的实现过程中，有很多工具可以帮助你快速达成目标。</li></ul></li><li>创建半正式的工作产品。<ul><li>以博客文章、技术报告和代码存储的形式记下学习和发现的内容，快速地为自己和他人提供一系列可以展示的技能、知识及反思。</li></ul></li><li>实时学习。<ul><li>不能仅在需要的时候才学习复杂的主题，例如，应该实时学习足够的概率和线性代数的指示来帮助理解正在处理的算法。在开始进入机器学习领域之前，不需要花费太多的时间来专门学习统计和数学方面的知识，而是要在平时进行实时学习，积累知识。</li></ul></li><li>利用现有的Skills。<ul><li>如果可以编码，那么通过实现算法来理解它们，而不是研究数学理论。使用自己熟悉的编程语言，让自己专注于正在学习的一件事情上，不要同时学习一种新的语言、工具或类库，这样会使学习过程复杂化。</li></ul></li><li>掌握是理想。<ul><li>掌握机器学习需要持续不断的学习。也许你永远不可能实现掌握机器学习的目标，只能持续不断地学习和改进所掌握的知识。</li></ul></li></ul><h4 id="学习机器学习的技巧">学习机器学习的技巧</h4><ul><li>启动一个可以在一个小时内完成的小项目。</li><li>通过每周完成一个项目来保持你的学习势头，并建立积累自己的项目工作区。</li><li>在微博、微信、Github等社交工具上分享自己的成果，或者随时随地地展示自己的兴趣，增加技能、知识，并获得反馈。</li></ul><h3 id="python-机器学习的生态圈">Python 机器学习的生态圈</h3><h4 id="python">Python</h4><figure><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/4.jpg" alt="" /><figcaption>TIOBE 2017年6月</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/5.jpg" alt="" /><figcaption>PYPL</figcaption></figure><h4 id="scipy">SciPy</h4><p>SciPy是在数学运算、科学和工程学方面被广泛应用的Python类库。它包括统计、优化、整合、线性代数模块、傅里叶变换、信号和图像处理、常微分方程求解器等，因此被广泛地应用在机器学习项目中。SciPy依赖以下几个与机器学习相关的类库。</p><ul><li><strong>NumPy</strong>：是Python的一种开源数值计算扩展。它可用来存储和处理大型矩阵，提供了许多高级的数值编程工具，如矩阵数据类型、矢量处理、精密的运算库。</li><li><strong>Matplotlib</strong>:Python中最著名的2D绘图库，十分适合交互式地进行制图；也可以方便地将它作为绘图控件，嵌入GUI应用程序中。</li><li><strong>Pandas</strong>：是基于NumPy的一种工具，是为了解决数据分析任务而创建的。Pandas纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具，也提供了大量能使我们快速、便捷地处理数据的函数和方法。</li></ul><h4 id="scikit-learn">scikit-learn</h4><p>scikit-learn是Python中开发和实践机器学习的著名类库之一，依赖于SciPy及其相关类库来运行。scikit-learn的基本功能主要分为六大部分：</p><ol type="1"><li>分类</li><li>回归</li><li>聚类</li><li>数据降维</li><li>模型选择</li><li>数据预处理</li></ol><h4 id="环境安装">环境安装</h4><h3 id="第一个机器学习项目">第一个机器学习项目</h3><h4 id="机器学习中的-hello-world-项目">机器学习中的 Hello World 项目</h4><p>鸢尾花（Iris Flower）进行分类</p><h4 id="导入数据">导入数据</h4><h4 id="概述数据">概述数据</h4><h4 id="数据可视化">数据可视化</h4><h4 id="评估算法">评估算法</h4><h4 id="实施预测">实施预测</h4><h3 id="python-和-scipy-速成">Python 和 SciPy 速成</h3><h4 id="python-速成">Python 速成</h4><h4 id="numpy-速成">NumPy 速成</h4><h4 id="matplotlib-速成">Matplotlib 速成</h4><h4 id="pandas-速成">Pandas 速成</h4><h2 id="第二部分-数据理解">第二部分 数据理解</h2><h3 id="数据导入">数据导入</h3><h4 id="csv-文件">CSV 文件</h4><h4 id="pima-indians-数据集">Pima Indians 数据集</h4><h4 id="采用标准-python-类库导入数据">采用标准 Python 类库导入数据</h4><h4 id="采用-numpy-导入数据">采用 NumPy 导入数据</h4><h4 id="采用-pandas-导入数据">采用 Pandas 导入数据</h4><h3 id="数据理解">数据理解</h3><h4 id="简单地查看数据">简单地查看数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="comment"># 显示数据的前10行</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>, <span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">peek = data.head(<span class="number">10</span>)</span><br><span class="line">print(peek)</span><br></pre></td></tr></table></figure><p><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/6.jpg" /></p><h4 id="数据的维度">数据的维度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="comment"># 显示数据的行和列数据</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">print(data.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(768, 9)</span><br></pre></td></tr></table></figure><h4 id="数据属性和类型">数据属性和类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="comment"># 显示数据的行和列数据</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">print(data.dtypes)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">preg     int64</span><br><span class="line">plas     int64</span><br><span class="line">pres     int64</span><br><span class="line">skin     int64</span><br><span class="line">test     int64</span><br><span class="line">mass   float64</span><br><span class="line">pedi   float64</span><br><span class="line">age       int64</span><br><span class="line">class     int64</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure><h4 id="描述性统计">描述性统计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> set_option</span><br><span class="line"><span class="comment"># 描述性统计</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">set_option(<span class="string">'display.width'</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># 设置数据的精确度</span></span><br><span class="line">set_option(<span class="string">'precision'</span>, <span class="number">4</span>)</span><br><span class="line">print(data.describe())</span><br></pre></td></tr></table></figure><p><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/7.jpg" /></p><h4 id="数据分组分布适用于分类算法">数据分组分布（适用于分类算法）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="comment"># 数据分类分布统计</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">print(data.groupby(<span class="string">'class'</span>).size())</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class</span><br><span class="line">0   500</span><br><span class="line">1   268</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><h4 id="数据属性的相关性">数据属性的相关性</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> set_option</span><br><span class="line"><span class="comment"># 显示数据的相关性</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">set_option(<span class="string">'display.width'</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># 设置数据的精确度</span></span><br><span class="line">set_option(<span class="string">'precision'</span>, <span class="number">2</span>)</span><br><span class="line">print(data.corr(method=<span class="string">'pearson'</span>))</span><br></pre></td></tr></table></figure><p><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/8.jpg" /></p><h4 id="数据的分布分析">数据的分布分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="comment"># 计算数据的高斯偏离</span></span><br><span class="line">filename = <span class="string">'pima_data.csv'</span></span><br><span class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>,</span><br><span class="line"><span class="string">'class'</span>]</span><br><span class="line">data = read_csv(filename, names=names)</span><br><span class="line">print(data.skew())</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">preg   0.901674</span><br><span class="line">plas   0.173754</span><br><span class="line">pres   -1.843608</span><br><span class="line">skin   0.109372</span><br><span class="line">test   2.272251</span><br><span class="line">mass   -0.428982</span><br><span class="line">pedi   1.919911</span><br><span class="line">age     1.129597</span><br><span class="line">class   0.635017</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h3 id="数据可视化-1">数据可视化</h3><h4 id="单一图表">单一图表</h4><h4 id="多重图表">多重图表</h4><h2 id="第三部分-数据准备">第三部分 数据准备</h2><blockquote><p>特征选择是困难耗时的，也需要对需求的理解和专业知识的掌握。在机器学习的应用开发中，最基础的是特征工程。</p></blockquote><p>——吴恩达</p><p>“使用正确的特征来构建正确的模型，以完成既定的任务”。</p><h3 id="数据预处理">数据预处理</h3><p>数据预处理大致分为三个步骤：</p><ol type="1"><li>数据的准备</li><li>数据的转换</li><li>数据的输出</li></ol><h4 id="为什么需要数据预处理">为什么需要数据预处理</h4><h4 id="格式化数据">格式化数据</h4><h4 id="调整数据尺度">调整数据尺度</h4><h4 id="正态化数据">正态化数据</h4><h4 id="标准化数据">标准化数据</h4><h4 id="二值数据">二值数据</h4><h3 id="数据特征选定">数据特征选定</h3><h4 id="特征选定">特征选定</h4><h4 id="单变量特征选定">单变量特征选定</h4><h4 id="递归特征消除">递归特征消除</h4><h4 id="主要成分分析">主要成分分析</h4><h4 id="特征重要性">特征重要性</h4><h2 id="第四部分-选择模型">第四部分 选择模型</h2><h3 id="评估算法-1">评估算法</h3><h4 id="评估算法的方法">评估算法的方法</h4><h4 id="分离训练数据集和评估数据集">分离训练数据集和评估数据集</h4><h4 id="k-折交叉验证分离">K 折交叉验证分离</h4><h4 id="弃一交叉验证分离">弃一交叉验证分离</h4><h4 id="重复随机分离评估数据集与训练数据集">重复随机分离评估数据集与训练数据集</h4><h3 id="算法评估矩阵">算法评估矩阵</h3><h4 id="算法评估矩阵-1">算法评估矩阵</h4><h4 id="分类算法矩阵">分类算法矩阵</h4><h4 id="回归算法矩阵">回归算法矩阵</h4><h3 id="审查分类算法">审查分类算法</h3><h4 id="算法审查">算法审查</h4><h4 id="算法概述">算法概述</h4><h4 id="线性算法">线性算法</h4><h4 id="非线性算法">非线性算法</h4><h3 id="审查回归算法">审查回归算法</h3><h4 id="算法概述-1">算法概述</h4><h4 id="线性算法-1">线性算法</h4><h4 id="非线性算法-1">非线性算法</h4><h3 id="算法比较">算法比较</h3><h4 id="选择最佳的机器学习算法">选择最佳的机器学习算法</h4><h4 id="机器学习算法的比较">机器学习算法的比较</h4><h3 id="自动流程">自动流程</h3><h4 id="机器学习的自动流程">机器学习的自动流程</h4><h4 id="数据准备和生成模型的-pipeline">数据准备和生成模型的 Pipeline</h4><h4 id="特征选择和生成模型的-pipeline">特征选择和生成模型的 Pipeline</h4><h2 id="第五部分-优化模型">第五部分 优化模型</h2><h3 id="集成算法">集成算法</h3><h4 id="集成的方法">集成的方法</h4><h4 id="装袋算法">装袋算法</h4><h4 id="提升算法">提升算法</h4><h4 id="投票算法">投票算法</h4><h3 id="算法调参">算法调参</h3><h4 id="机器学习算法调参">机器学习算法调参</h4><h4 id="网格搜索优化参数">网格搜索优化参数</h4><h4 id="随机搜索优化参数">随机搜索优化参数</h4><h2 id="第六部分-结果部署">第六部分 结果部署</h2><h3 id="持久化加载模型">持久化加载模型</h3><h4 id="通过-pickle-序列化和反序列化机器学习的模型">通过 pickle 序列化和反序列化机器学习的模型</h4><h4 id="通过-joblib-序列化和反序列化机器学习的模型">通过 joblib 序列化和反序列化机器学习的模型</h4><h4 id="生成模型的技巧">生成模型的技巧</h4><h2 id="第七部分-项目实践">第七部分 项目实践</h2><h3 id="预测模型项目模板">预测模型项目模板</h3><h4 id="在项目中实践机器学习">在项目中实践机器学习</h4><h4 id="机器学习项目的-python-模板">机器学习项目的 Python 模板</h4><h4 id="各步骤的详细说明">各步骤的详细说明</h4><h4 id="使用模板的小技巧">使用模板的小技巧</h4><h3 id="回归项目实例">回归项目实例</h3><h4 id="定义问题">定义问题</h4><h4 id="导入数据-1">导入数据</h4><h4 id="理解数据">理解数据</h4><h4 id="数据可视化-2">数据可视化</h4><h4 id="分离评估数据集">分离评估数据集</h4><h4 id="评估算法-2">评估算法</h4><h4 id="调参改善算法">调参改善算法</h4><h4 id="集成算法-1">集成算法</h4><h4 id="集成算法调参">集成算法调参</h4><h4 id="确定最终模型">20.10 确定最终模型</h4><h3 id="二分类实例">二分类实例</h3><h4 id="问题定义">问题定义</h4><h4 id="导入数据-2">导入数据</h4><h4 id="分析数据">分析数据</h4><h4 id="分离评估数据集-1">分离评估数据集</h4><h4 id="评估算法-3">评估算法</h4><h4 id="算法调参-1">算法调参</h4><h4 id="集成算法-2">集成算法</h4><h4 id="确定最终模型-1">确定最终模型</h4><h3 id="文本分类实例">文本分类实例</h3><h4 id="问题定义-1">问题定义</h4><h4 id="导入数据-3">导入数据</h4><h4 id="文本特征提取">文本特征提取</h4><h4 id="评估算法-4">评估算法</h4><h4 id="算法调参-2">算法调参</h4><h4 id="集成算法-3">集成算法</h4><h4 id="集成算法调参-1">集成算法调参</h4><h4 id="确定最终模型-2">确定最终模型</h4><p><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/9.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/10.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/11.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/12.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/13.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/14.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/15.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/16.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/17.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/18.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/19.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/20.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/21.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/22.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/23.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/24.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/25.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/10/9787121331107/26.jpg" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/10/9787121331107/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《机器学习：Python实践》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：机器学习：Python实践&lt;br /&gt;
作者：魏贞原出版社：电子工业出版社&lt;br /&gt;
出版时间：2018-01&lt;br /&gt;
ISBN：9787121331107&lt;/p&gt;
&lt;p&gt;GitHub: &lt;a href=&quot;https://github.com/weizy1981/MachineLearning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://github.com/weizy1981/MachineLearning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这本书是写给对机器学习感兴趣和立志学习机器学习的 &lt;code&gt;Python&lt;/code&gt; 程序员的，是一本关于机器学习实践的书籍。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="ML" scheme="https://2020.iosdevlog.com/tags/ML/"/>
    
      <category term="Python" scheme="https://2020.iosdevlog.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>2020年每位数据科学家必读的50本免费书籍</title>
    <link href="https://2020.iosdevlog.com/2020/03/09/50-books/"/>
    <id>https://2020.iosdevlog.com/2020/03/09/50-books/</id>
    <published>2020-03-09T14:35:40.000Z</published>
    <updated>2020-03-09T15:53:54.853Z</updated>
    
    <content type="html"><![CDATA[<p>数据科学是一个跨学科领域，包含来自统计，机器学习，贝叶斯等领域的方法和技术。它们都旨在从数据中产生特定的见解。在本文中，我们列出了一些出色的数据科学书籍，其中涵盖了数据科学下的各种主题。</p><a id="more"></a><h3 id="数据分析风格的要素-the-element-of-data-analytic-style">1. <a href="https://leanpub.com/datastyle" target="_blank" rel="noopener">数据分析风格的要素 / The Element of Data Analytic Style</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/B1.png" alt="" /><figcaption>The Element of Data Analytic Style</figcaption></figure><p>本书概述了数据科学。数据科学是一个很大的概括性术语，对于那些初次尝试涉足这一领域的人来说，这本书非常有用。阅读它以了解什么是数据科学，什么是一些常规任务和算法，以及一些常规技巧和窍门。</p><h3 id="数据科学基础-foundations-of-data-science">2. <a href="https://www.cs.cornell.edu/jeh/book.pdf" target="_blank" rel="noopener">数据科学基础 / Foundations of Data Science</a></h3><p>数据科学的基础是一些选定领域的论文，这些领域构成了数据科学的基础，例如线性代数，LDA，马尔可夫链，机器学习基础和统计。本书的理想读者是希望使他们在数学和理论上更好地掌握该领域的初学者数据科学家。</p><h3 id="海量数据集的挖掘-mining-of-massive-datasets">3. <a href="http://infolab.stanford.edu/~ullman/mmds/book0n.pdf" target="_blank" rel="noopener">海量数据集的挖掘 / Mining of Massive Datasets</a></h3><p>本书基于斯坦福大学CS246和CS35A课程，可帮助用户学习在大型数据集上进行数据挖掘的主题。数据科学家通常需要解决的一个非常普遍的问题是在非常大的数据集上执行简单的数字任务（您可以通过编写小程序来完成）。MMDS正是为此而努力。除此之外，您还有诸如降维和推荐系统之类的主题，可以帮助您了解线性代数和度量距离在现实世界中的应用。所有数据科学家的必读资料。</p><h3 id="python数据科学手册-python-data-science-handbook">4. <a href="https://jakevdp.github.io/PythonDataScienceHandbook/" target="_blank" rel="noopener">Python数据科学手册 / Python Data Science Handbook</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/PDSH-cover.png" alt="" /><figcaption>PDSH-cover</figcaption></figure><p>Python数据科学手册教了各种数据科学概念在Python中的应用。也许这是学习Python数据科学的最好书（仅相当于  <a href="https://github.com/wesm/pydata-book" target="_blank" rel="noopener">Wes McKinney的鼠标书</a>），这本书也可以在Github上免费阅读。因此，您无需花任何钱就可以学习。</p><h3 id="动手机器学习和大数据-hands-on-machine-learning-and-big-data">5. <a href="http://www.kareemalkaseer.com/books/ml/" target="_blank" rel="noopener">动手机器学习和大数据 / Hands-on Machine Learning and Big Data</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/Hands_on.png" alt="" /><figcaption>Hands_on</figcaption></figure><h3 id="统计思想-think-stats">6. <a href="http://greenteapress.com/thinkstats/" target="_blank" rel="noopener">统计思想 / Think Stats</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/think_stats_comp.png" alt="" /><figcaption>think_stats_comp</figcaption></figure><p>Think Stats教给读者统计学的基础知识，也就是说，读者将在现实世界的数据集上应用统计学的概念和分布，并尝试使用数学特征来了解有关数据的更多信息。如果您想使用Python学习统计信息，可能是最好的入门书籍之一。</p><h3 id="贝叶斯思想-think-bayes">7. <a href="https://greenteapress.com/wp/think-bayes/" target="_blank" rel="noopener">贝叶斯思想 / Think Bayes</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/think_bayes_cover_medium.png" alt="" /><figcaption>think_bayes_cover_medium</figcaption></figure><p>贝叶斯统计的工作原理与正常统计有所不同。不确定性和对真实数据集的拟合分布的概念使贝叶斯方法更适合于学习真实数据集。唐尼教授非常酷的“通过使用Python进行编程学习”的风格使这本书成为那些开始使用贝叶斯方法的人的不二之选。</p><h3 id="线性动力系统简介-introduction-to-linear-dynamical-systems">8. <a href="http://ee263.stanford.edu/" target="_blank" rel="noopener">线性动力系统简介 / Introduction to Linear Dynamical Systems</a></h3><p>这本书讲授了实际系统中的应用线性代数。这些应用程序涉及电路，信号处理，通信和控制系统。可在<a href="https://web.stanford.edu/class/archive/ee/ee263/ee263.1082/notes/ee263coursereader.pdf" target="_blank" rel="noopener">此处</a>找到与博伊德教授前几年课程笔记的链接  。</p><h3 id="凸优化-convex-optimization">9. <a href="http://stanford.edu/~boyd/cvxbook/" target="_blank" rel="noopener">凸优化 / Convex Optimization</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/bv_cvxbook_cover.jpg" alt="" /><figcaption>bv_cvxbook_cover</figcaption></figure><p>凸优化是许多机器学习（以及几乎所有深度学习算法）算法在后台用于获得最佳参数集的功能。</p><h3 id="启发式方法基础-essentials-of-metaheuristics">10. <a href="https://cs.gmu.edu/~sean/book/metaheuristics/" target="_blank" rel="noopener">启发式方法基础 / Essentials of Metaheuristics</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/Luke2013.jpg" alt="" /><figcaption>Luke2013</figcaption></figure><p>启发式方法是一种快速学习概率方法来完成任务的方法，这些方法可能需要您编写程序才能使用蛮力搜索。对于也许较小的数据，蛮力方法的实现工作量较小，但是随着添加的数据量的增加，它们将很快耗尽。这本书可能是遗传算法，爬山，协同进化和（基本）强化学习等元启发式方法的最佳介绍。</p><h3 id="python中的机器学习数据科学机器学习和人工智能的主要发展和技术趋势-machine-learning-in-python-main-developments-and-technology-trends-in-data-science-machine-learning-and-artificial-intelligence">11. <a href="https://arxiv.org/abs/2002.04803" target="_blank" rel="noopener">Python中的机器学习：数据科学，机器学习和人工智能的主要发展和技术趋势 / Machine Learning in Python: Main Developments and Technology Trends in Data Science, Machine Learning, and Artificial Intelligence</a></h3><p>数据科学中的Python工具的良好概述。对于想要进入数据科学领域的高级Python开发人员或从R for Data Science进入Python的人员来说，这是一个非常不错的文档。总体而言，如果您想了解Python对数据科学的作用，则应阅读本文。</p><h3 id="应用数据科学-applied-data-science">12. <a href="https://columbia-applied-data-science.github.io/appdatasci.pdf" target="_blank" rel="noopener">应用数据科学 / Applied Data Science</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/ads.png" alt="" /><figcaption>ads</figcaption></figure><p>Langmore和Krasner撰写的Applied Data Science是一本采用非常实用的方法教授Data Science的书。通过使用Git进行基础Python的教学，本书继续构建了各种算法的基础知识，这些算法在数据科学领域中经​​常使用。</p><h3 id="强盗书-bandit-book">13. <a href="https://tor-lattimore.com/downloads/book/book.pdf" target="_blank" rel="noopener">强盗书 / Bandit Book</a></h3><p>随着越来越多的数据积累，决策不再只是直觉的功能，而是所收集数据的功能。电子商务网站上用于进行药物测试和财务投资组合决策的“购买”按钮的正确颜色是什么，随处都使用强盗算法？一本很好的让自己熟悉“匪徒”的书！</p><h3 id="注释算法-annotated-algorithms">14. <a href="https://tor-lattimore.com/downloads/book/book.pdf" target="_blank" rel="noopener">注释算法 / Annotated Algorithms</a></h3><p>教您用Python编写许多数值算法的书。如果您想学习数学程序的实现方式，或者想通过有趣的问题陈述学习Python，这是一个极好的资源。</p><h3 id="计算机时代统计推断-computer-age-statistical-inference">15. <a href="https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf" target="_blank" rel="noopener">计算机时代统计推断 / Computer Age Statistical Inference</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/casi.png" alt="" /><figcaption>casi</figcaption></figure><p>埃夫隆（Efron）和传奇的哈斯提（Hastie）所著的一本书，思考了如何利用当今可用的计算能力，而不是大多数其他书籍所采用的笔纸方法，在现代进行统计推断（常客和贝叶斯）。这是打算在现实生活中使用“统计信息”的任何人（初学者或有经验的人）必须阅读的内容。</p><h3 id="因果推论书-causal-inference-book">16. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/" target="_blank" rel="noopener">因果推论书 / Causal Inference Book</a></h3><p>“关联不是因果关系”是数据科学家经常使用的短语。但是如何将两者分开？本书通过向数据科学家介绍因果推理技术来提供答案。您将需要良好的概率基础来阅读它，而不是针对初学者。</p><h3 id="计算最优运输-computational-optimal-transport">17. <a href="https://arxiv.org/abs/1803.00567" target="_blank" rel="noopener">计算最优运输 / Computational Optimal Transport</a></h3><p>最优运输是从一组分布到另一组分布的分配数学。这可能是数据科学领域中获得过多个菲尔兹奖章（数学领域的最高荣誉）的少数领域之一。数学概念已在许多机器学习和深度学习算法中用作距离度量和分配问题解决方案。</p><h3 id="计算机科学与机器学习的代数拓扑微积分和优化理论-algebra-topology-differential-calculus-and-optimization-theory-for-computer-science-and-machine-learning">18. <a href="https://www.cis.upenn.edu/~jean/math-deep.pdf" target="_blank" rel="noopener">计算机科学与机器学习的代数，拓扑，微积分和优化理论 / Algebra, Topology, Differential Calculus and Optimization Theory for Computer Science and Machine Learning</a></h3><p>该书旨在教授计算机科学和机器学习所需的各种数学领域。对于那些想从数学重领域进入数据科学领域的人来说，这是相当不错的数学知识和丰富的资源。</p><h3 id="数据挖掘与分析-data-mining-and-analysis">19. <a href="http://www.dataminingbook.info/pmwiki.php" target="_blank" rel="noopener">数据挖掘与分析 / Data Mining and Analysis</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/bookpic.jpg" alt="" /><figcaption>bookpic</figcaption></figure><p>正如您在前面提到的更著名的MMDS书中可能已经看到的那样，数据挖掘是一种有效地对大型数据集进行计算的方法。这些计算可以通过蛮力方法完成，并且在小型数据集上可能效果很好，但是在大型数据集上运行可能要花很长时间。很好的数据挖掘入门和参考书。</p><h3 id="计算与推理-computational-and-inferential-thinking">20. <a href="https://www.inferentialthinking.com/chapters/intro.html" target="_blank" rel="noopener">计算与推理 / Computational and Inferential Thinking</a></h3><p>从使用Python进行编程，因果关系，表，可视化和基本统计​​信息的角度研究数据科学的各个方面。从加州大学伯克利分校的一门基础课程开始，对初学者来说是一个很好的资源。</p><h3 id="数据科学的数学基础-mathematical-foundations-of-data-science">21. <a href="https://mathematical-tours.github.io/book-sources/FundationsDataScience.pdf" target="_blank" rel="noopener">数据科学的数学基础 / Mathematical Foundations of Data Science</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/mfd.png" alt="" /><figcaption>mfd</figcaption></figure><p>顾名思义，本书给出并解释了诸如凸优化和降维之类的数据科学概念背后的数学论文。如果您喜欢数学，或者特别想学习这些概念背后的数学，则推荐这本书。</p><h3 id="聪明人的信息论-information-theory-for-intelligent-people">22. <a href="http://tuvalu.santafe.edu/~simon/it.pdf" target="_blank" rel="noopener">聪明人的信息论 / Information Theory for Intelligent People</a></h3><p>信息论是与线性代数，凸优化和统计一起在数据科学中发现的四种数学理论之一。这是理解理论的好教程。好消息是，初学者可以使用本教程。</p><h3 id="应用线性代数简介-vmls书-introduction-to-applied-linear-algebra-the-vmls-book">23. <a href="http://vmls-book.stanford.edu/" target="_blank" rel="noopener">应用线性代数简介– VMLS书 / Introduction to Applied Linear Algebra – The VMLS Book</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/vmls_cover.jpg" alt="" /><figcaption>vmls_cover</figcaption></figure><p>在此列表中我将提到的众多书中，我最喜欢的线性代数书。初学者可以使用它，并具有非常实用的感觉，而不会使读者迷失于许多数学概念中。</p><h3 id="线性代数-hefferon-linear-algebra-hefferon">24. <a href="http://joshua.smcvt.edu/linearalgebra/" target="_blank" rel="noopener">线性代数– Hefferon / Linear Algebra – Hefferon</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/bookcover.png" alt="" /><figcaption>bookcover</figcaption></figure><p>许多人认为，这是Strong圣经之后可获得的最好的初学者线性代数资源。（在SAGE中进行编程练习，基本上是Python）也很实用，但是对于初学者来说，比从业者更多。</p><h3 id="线性代数作为抽象数学的入门-linear-algebra-as-an-introduction-to-abstract-mathematics">25. <a href="https://www.math.ucdavis.edu/~anne/linear_algebra/" target="_blank" rel="noopener">线性代数–作为抽象数学的入门 / Linear Algebra – As An Introduction to Abstract Mathematics</a></h3><p>这本书感觉就像我的大学线性代数书（许多与我一起学习工程学的学生都喜欢它）。当数学过多而应用程序略少时，我会迷茫，但很多人会喜欢这类书的优雅。</p><h3 id="线性代数的基础和最优化-fundamentals-of-linear-algebra-and-optimizations">26. <a href="https://www.seas.upenn.edu/~cis515/linalg.pdf" target="_blank" rel="noopener">线性代数的基础和最优化 / Fundamentals of Linear Algebra and Optimizations</a></h3><p>本书将线性代数与优化算法结合在一起。同样，面向喜欢该样式的人的更多面向数学的书籍。</p><h3 id="线性代数讲义-lerner-linear-algebra-lecture-notes-lerner">27. <a href="https://www-labs.iro.umontreal.ca/~grabus/courses/ift6760_files/LANotes.lerner.pdf" target="_blank" rel="noopener">线性代数讲义– Lerner / Linear Algebra Lecture Notes – Lerner</a></h3><p>我发现它真的很好，就像向您展示了多个已解决的问题以使您学习一样。不像以前的书那样严格，而是通过表演来学习。对于长时间不接触线性代数的人来说，是不错的复习。</p><h3 id="随机线性代数的讲义-lecture-notes-on-randomized-linear-algebra">28. <a href="https://arxiv.org/abs/1608.04481" target="_blank" rel="noopener">随机线性代数的讲义 / Lecture Notes on Randomized Linear Algebra</a></h3><p>并非所有人都需要阅读本书，因为本书涉及解决线性代数问题的概率算法。如果您要处理大型矩阵和向量，而简单的算法将无法使用，则很有用。</p><h3 id="通过外部产品的线性代数-linear-algebra-via-exterior-products">29. <a href="https://www.academia.edu/32968283/Linear_Algebra_via_Exterior_Products" target="_blank" rel="noopener">通过外部产品的线性代数 / Linear Algebra via Exterior Products</a></h3><p>线性代数的另一种截然不同的方式。如果您发现线性代数很棒，则应尝试以这种新方式可视化问题。</p><h3 id="线性代数-linear-algebra-cherney-et-al">30. <a href="https://www.math.ucdavis.edu/~linear/" target="_blank" rel="noopener">线性代数 / Linear Algebra – Cherney et al</a></h3><p>另一本针对大学级线性代数的免费书籍。适合初学者。如果您想练习，它也会带来作业问题。</p><h3 id="深度学习所需的矩阵微积分-matrix-calculus-you-need-for-deep-learning">31. <a href="https://arxiv.org/abs/1802.01528" target="_blank" rel="noopener">深度学习所需的矩阵微积分 / Matrix Calculus you need for Deep Learning</a></h3><p>顾名思义，本教程可帮助您了解深度学习所需的矩阵演算。</p><h3 id="优化简介-optimization-an-introduction">32. <a href="http://www3.imperial.ac.uk/pls/portallive/docs/1/7288263.PDF" target="_blank" rel="noopener">优化：简介 / Optimization: An Introduction</a></h3><p>在整个工程领域的问题中都需要优化参数。虽然在许多深度学习算法中使用了凸优化，但了解线性算法等其他算法后，单纯形却开阔了眼界。</p><h3 id="scipy讲义scipy-lecture-notes">33. Scipy讲义/Scipy Lecture Notes</h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/Scipy.png" alt="" /><figcaption>Scipy</figcaption></figure><p>如果您打算从事数据科学工作，则需要学习科学的Python堆栈。可能是学习Numpy，Scipy，Scikit-Learn，Scikit-Image以及所需的所有库的最佳通用教程。</p><h3 id="熊猫超级教程-pandas-mega-tutorial">34. <a href="https://pandas.pydata.org/docs/pandas.pdf" target="_blank" rel="noopener">熊猫超级教程 / Pandas Mega Tutorial</a></h3><p>这个庞大的教程是由Pandas开发团队学习和理解该库的。如果您从事数据科学工作，Pandas是一个必须学习的图书馆。跑不了的。</p><h3 id="python中的卡尔曼和贝叶斯过滤器-kalman-and-bayesian-filters-in-python">35. <a href="https://drive.google.com/file/d/0By_SW19c1BfhSVFzNHc0SjduNzg/view" target="_blank" rel="noopener">Python中的卡尔曼和贝叶斯过滤器 / Kalman and Bayesian Filters in Python</a></h3><p>当处理随时间而来的噪声数据时，卡尔曼滤波器和其他贝叶斯滤波器非常有用，这些噪声数据可以拟合到具有推论参数的特定模型。这些模型的双重作用是推导参数以及对噪声进行建模。尽管最常用的示例是位置数据，但是类似的过滤器也可以很好地进行预测。（也可以在  <a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python" target="_blank" rel="noopener">Github上获得</a>）</p><h3 id="数据科学的统计推断-statistical-inference-for-data-science">36. <a href="https://leanpub.com/LittleInferenceBook" target="_blank" rel="noopener">数据科学的统计推断 / Statistical Inference for Data Science</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/hero.png" alt="" /><figcaption>hero</figcaption></figure><p>在此之前，我们已经看过多本《统计推断》书籍，但是写这本书的时候尤其要牢记数据科学家的思想。如果您是一名数据科学家，并且试图快速掌握统计推断，那么这就是您的书。</p><h3 id="机器学习数学-mathematics-for-machine-learning">37. <a href="https://mml-book.github.io/" target="_blank" rel="noopener">机器学习数学 / Mathematics for Machine Learning</a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/09/50-books/mml-book-cover.jpg" alt="" /><figcaption>mml-book-cover</figcaption></figure><p>一本详细的教您数学的书需要理解其中的大多数机器学习算法。初学者的友好。</p><h3 id="看见统计---基础概率论-seeing-theory">38. <a href="https://seeing-theory.brown.edu/#firstPage" target="_blank" rel="noopener">看见统计 - 基础概率论 / Seeing Theory</a></h3><p>通过使用交互式可视化使学习概率容易的书。</p><h3 id="统计基础-basics-of-statistics">39. <a href="https://www.semanticscholar.org/paper/Basics-of-Statistics-Isotalo/c3cc90f6e11e9554f3de2c0da26e44ac22f8a1ff" target="_blank" rel="noopener">统计基础 / Basics of Statistics</a></h3><p>一本书向您介绍统计研究。从未学习过统计学的初学者应该从这里开始。</p><h3 id="公开统计-open-statistics">40. <a href="http://14.139.232.166/opstat/" target="_blank" rel="noopener">公开统计 / Open Statistics</a></h3><p>书和视频讲座相结合，向读者介绍统计学。</p><h3 id="从基本角度看高级数据分析-advanced-data-analysis-from-an-elementary-point-of-view">41. <a href="https://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/" target="_blank" rel="noopener">从基本角度看高级数据分析 / Advanced Data analysis From an Elementary Point of View</a></h3><p>数据科学的不同概念的一般介绍。这包括因果模型，回归模型，因子模型等。示例程序在R中。</p><h3 id="快速智能大规模-fast-data-smart-and-at-scale">42. <a href="https://www.voltdb.com/wp-content/uploads/2017/03/hv-ebook-fast-data-smart-and-at-scale.pdf" target="_blank" rel="noopener">快速，智能，大规模 / Fast Data, Smart and at Scale</a></h3><p>本书介绍了如何优化数据库以实现快速查询。它讲述了现实世界中的各种可能模型。</p><h3 id="多武装匪徒简介-introduction-to-multi-armed-bandits">43. <a href="https://arxiv.org/abs/1904.07272" target="_blank" rel="noopener">多武装匪徒简介 / Introduction to Multi-Armed Bandits</a></h3><p>多臂强盗是在不确定性下会随着时间做出决策的算法。这本书是多臂匪的入门论文。</p><h3 id="量化经济学讲座-quant-economics-lectures">44. <a href="https://quantecon.org/lectures/" target="_blank" rel="noopener">量化经济学讲座 / Quant Economics Lectures</a></h3><p>使用您喜欢的编程语言进行的定量经济学和代码讲座：Python或Julia。</p><h3 id="julia-统计-statistics-with-julia">45. <a href="https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf" target="_blank" rel="noopener">Julia 统计 / Statistics With Julia</a></h3><p>统计学家学习Julia还是（不太可能）Julia程序员学习统计学？试试这本书。</p><h3 id="信息论推理与学习算法-information-theory-inference-and-learning-algorithms">46. <a href="https://www.inference.org.uk/itprnn/book.pdf" target="_blank" rel="noopener">信息论，推理与学习算法 / Information Theory, Inference and Learning Algorithms</a></h3><p>信息理论和推理通常以不同的方式处理，但已故的MacKay教授的书试图解决这两个问题。</p><h3 id="科学改进决策和风险管理-scientific-improvement-of-decision-making-and-risk-management">47. <a href="https://yngve.hoiseth.net/Empiricast_White_Paper.pdf" target="_blank" rel="noopener">科学改进决策和风险管理 / Scientific Improvement of Decision Making and Risk Management</a></h3><p>关于概率决策的技术性不太强的教程。</p><h3 id="三十三个缩图线性代数的数学和算法应用-thirty-three-miniatures-mathematical-and-algorithmic-applications-of-linear-algebra">48. <a href="https://kam.mff.cuni.cz/~matousek/stml-53-matousek-1.pdf" target="_blank" rel="noopener">三十三个缩图：线性代数的数学和算法应用 / Thirty-three Miniatures: Mathematical and Algorithmic Applications of Linear Algebra</a></h3><p>这实际上不是一本关于线性代数的书，而是一本汇编成书的线性书的一些很酷的应用程序。</p><h3 id="遗传算法教程-a-genetic-algorithm-tutorial">49. <a href="https://www.cs.colostate.edu/~genitor/MiscPubs/tutorial.pdf" target="_blank" rel="noopener">遗传算法教程 / A Genetic Algorithm Tutorial</a></h3><p>遗传算法是所有数据科学家一生中都需要使用的工具。本教程可帮助初学者了解遗传算法的工作原理。</p><h3 id="使用-julia-在运营研究中计算-computing-in-operations-research-using-julia">50. <a href="https://arxiv.org/abs/1312.1431" target="_blank" rel="noopener">使用 Julia 在运营研究中计算 / Computing in Operations Research using Julia</a></h3><p>如果您正在处理排队或其他运营研究问题，Julia可能是您很喜欢的一种编程语言。这些程序像Python一样易于读取，运行速度非常快。</p><p>原文：<a href="https://www.kdnuggets.com/2020/03/50-must-read-free-books-every-data-scientist-2020.html" target="_blank" rel="noopener">50 Must-Read Free Books For Every Data Scientist in 2020</a></p><p><strong>By <a href="https://blog.paralleldots.com/author/reashikaa%20/" target="_blank" rel="noopener">Reashikaa Verma</a>, <a href="https://www.paralleldots.com/" target="_blank" rel="noopener">ParellelDots</a></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据科学是一个跨学科领域，包含来自统计，机器学习，贝叶斯等领域的方法和技术。它们都旨在从数据中产生特定的见解。在本文中，我们列出了一些出色的数据科学书籍，其中涵盖了数据科学下的各种主题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="DS" scheme="https://2020.iosdevlog.com/tags/DS/"/>
    
      <category term="book" scheme="https://2020.iosdevlog.com/tags/book/"/>
    
  </entry>
  
  <entry>
    <title>节选：常见机器学习算法列表（Python 调用）</title>
    <link href="https://2020.iosdevlog.com/2020/03/08/algorithms/"/>
    <id>https://2020.iosdevlog.com/2020/03/08/algorithms/</id>
    <published>2020-03-08T14:49:41.000Z</published>
    <updated>2020-03-08T15:48:54.648Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>线性回归</li><li>逻辑回归</li><li>决策树</li><li>支持向量机</li><li>朴素贝叶斯</li><li>神经网络</li><li>K均值</li><li>随机森林</li><li>降维算法</li><li>梯度提升算法<ol type="1"><li>GBM</li><li>XGBoost</li><li>LightGBM</li><li>Catboost</li></ol></li></ol><a id="more"></a><p>大致而言，共有 3 种类型的机器学习算法</p><ul><li>监督学习</li></ul><p>工作原理：此算法由目标/结果变量（或因变量）组成，该目标/结果变量将从给定的一组预测变量（因变量）中进行预测。使用这些变量集，我们生成了一个将输入映射到所需输出的函数。训练过程将继续进行，直到模型在训练数据上达到所需的准确性水平为止。</p><p>监督学习的例子：线性回归，决策树，随机森林，KNN，逻辑回归等。</p><ul><li>无监督学习</li></ul><p>工作原理： 在此算法中，我们没有任何目标或结果变量可以预测/估算。它用于对不同组中的人群进行聚类，广泛用于对不同组中的客户进行细分以进行特定干预。</p><p>无监督学习的示例：Apriori算法，K均值。</p><ul><li>强化学习：</li></ul><p>工作原理：使用此算法，机器经过训练后可以做出特定决策。它是这样工作的：机器处于反复试验不断训练自身的环境中。该机器将从过去的经验中学习，并尝试捕获最佳的知识以做出准确的业务决策。</p><p>强化学习的例子：马尔可夫决策过程</p><h2 id="常见机器学习算法列表">常见机器学习算法列表</h2><h3 id="线性回归">1.线性回归</h3><p>它用于根据连续变量估算实际价值（房屋成本，通话次数，总销售额等）。在这里，我们通过拟合一条最佳线来建立自变量和因变量之间的关系。该最佳拟合线称为回归线，并由线性方程 <span class="math inline">\(Y = a * X + b\)</span> 表示。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Linear_Regression.webp" alt="" /><figcaption>Linear_Regression</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Linear Regression</span></span><br><span class="line"><span class="string">Created by- ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Linear Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and normalize</span></span><br><span class="line"><span class="string">Documentation of sklearn LinearRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'\nCoefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'\nIntercept of model'</span>,model.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on training data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on training dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the testing dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on testing dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br></pre></td></tr></table></figure><h3 id="logistic回归">2. Logistic回归</h3><p>不要被它的名字弄糊涂了！它是一种分类，而不是回归算法。它用于基于给定的一组独立变量来估计离散值（二进制值，如 <code>0/1，yes/no，true/false</code>）。简而言之，它通过将数据拟合到logit函数来预测事件发生的可能性。因此，这也称为 <strong>对数回归</strong>。由于可以预测概率，因此其输出值介于0和1之间（如预期）。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Logistic_Regression.webp" alt="" /><figcaption>Logistic_Regression</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Logistic Regression</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(train_data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Logistic Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and penalty</span></span><br><span class="line"><span class="string">Documentation of sklearn LogisticRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'Coefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'Intercept of model'</span>,model.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="决策树">3. 决策树</h3><p>这是我最喜欢的算法之一，我经常使用它。它是一种监督学习算法，主要用于分类问题。令人惊讶的是，它适用于分类因变量和连续因变量。在此算法中，我们将总体分为两个或多个同构集合。这是基于最重要的属性/自变量来完成的，以尽可能地形成不同的组。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Decision_Tree.webp" alt="" /><figcaption>Decision Tree</figcaption></figure><p>理解决策树如何工作的最好方法是玩 Jezzball，这是 Microsoft 的经典游戏（下图）。本质上，您有一间活动墙的房间，您需要创建墙以使最大的区域在没有球的情况下被清除。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Jezzball.jpg" alt="" /><figcaption>Jezzball</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Decision Tree</span></span><br><span class="line"><span class="string">Created by - Analytics Vidhya</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Decision Tree model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and max_features</span></span><br><span class="line"><span class="string">Documentation of sklearn DecisionTreeClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># depth of the decision tree</span></span><br><span class="line">print(<span class="string">'Depth of the Decision Tree :'</span>, model.get_depth())</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="svm支持向量机">4. SVM（支持向量机）</h3><p>这是一种分类方法。在此算法中，我们将每个数据项绘制为n维空间（其中n是您拥有的特征数）中的一个点，其中每个特征的值就是特定坐标的值。</p><p>例如，如果我们只有两个特征，例如一个人的身高和头发长度，我们首先将这两个变量绘制在二维空间中，其中每个点都有两个坐标（这些坐标称为支持向量）</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM1.webp" alt="" /><figcaption>SVM1</figcaption></figure><p>现在，我们将找到一行将数据划分为两个不同分类的数据组。这条线将使距两组中最近点的距离最远。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/SVM2.webp" alt="" /><figcaption>SVM2</figcaption></figure><p>在上面显示的示例中，将数据分为两个不同类别的组的线是黑线，因为两个最接近的点距离该线最远。这行是我们的分类器。然后，根据测试数据在行两边的位置，可以将新数据归类为该类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Support Vector Machines</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Support Vector Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : kernal and degree</span></span><br><span class="line"><span class="string">Documentation of sklearn Support Vector Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="朴素贝叶斯">5. 朴素贝叶斯</h3><p>这是一种基于贝叶斯定理的分类技术，假设预测变量之间具有独立性。简单来说，朴素贝叶斯分类器假定类中某个特定功能的存在与任何其他功能的存在无关。例如，如果水果是红色，圆形且直径约3英寸，则可以将其视为苹果。即使这些特征相互依赖或依赖于其他特征的存在，朴素的贝叶斯分类器也会考虑所有这些特征，以独立地有助于该果实是苹果的可能性。</p><p>朴素贝叶斯模型易于构建，对于非常大的数据集特别有用。除简单之外，朴素的贝叶斯（Naive Bayes）甚至胜过非常复杂的分类方法。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Bayes_rule.webp" alt="" /><figcaption>Bayes_rule</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Naive Bayes</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Naive Bayes model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : var_smoothing</span></span><br><span class="line"><span class="string">Documentation of sklearn GaussianNB: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = GaussianNB()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="knnk-最近邻">6. kNN（k-最近邻）</h3><p>它可以用于分类和回归问题。但是，它更广泛地用于行业中的分类问题。K个最近邻居是一种简单的算法，可以存储所有可用案例，并通过其k个邻居的多数票对新案例进行分类。在通过距离函数测得的K个最近邻居中，分配给该类别的案例最为常见。</p><p>这些距离函数可以是欧几里得距离，曼哈顿距离，明可夫斯基距离和汉明距离。前三个函数用于连续函数，第四个函数（汉明）用于分类变量。如果K = 1，则将案例简单分配给其最近邻居的类别。有时，执行kNN建模时选择K确实是一个挑战。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/KNN.webp" alt="" /><figcaption>KNN</figcaption></figure><p>KNN可以轻松地映射到我们的现实生活。如果您想了解一个没有信息的人，则可能想了解他的密友和他所进入的圈子并获得他/她的信息！</p><p>选择kNN之前要考虑的事项：</p><ol type="1"><li>KNN在计算上很昂贵</li><li>变量应归一化，否则范围较大的变量会对其产生偏差</li><li>在进行kNN处理之前（如离群值，噪声消除）在预处理阶段进行更多工作</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Nearest Neighbors</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Nearest Neighbor model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_neighbors, leaf_size</span></span><br><span class="line"><span class="string">Documentation of sklearn K-Neighbors Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = KNeighborsClassifier()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Neighbors used to predict the target</span></span><br><span class="line">print(<span class="string">'\nThe number of neighbors used to predict the target : '</span>,model.n_neighbors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="k-均值聚类">7. K-均值聚类</h3><p>这是一种无监督算法，可以解决聚类问题。它的过程遵循一种简单的方法，可以通过一定数量的聚类（假设k个聚类）对给定的数据集进行分类。集群中的数据点对同级组是同质的，并且是异构的。</p><p>还记得从墨水印迹中找出形状吗？k表示此活动有点类似。您查看形状并展开以解释存在多少个不同的群集/种群！</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Ink.jpg" alt="" /><figcaption>Ink</figcaption></figure><p>K-均值如何形成聚类：</p><ol type="1"><li>K均值为每个聚类选择k个点，称为质心。</li><li>每个数据点形成一个具有最接近质心的聚类，即k个聚类。</li><li>根据现有集群成员查找每个集群的质心。在这里，我们有了新的质心。</li><li>当我们有了新的质心时，请重复步骤2和3。找到每个数据点与新质心的最近距离，并与新的k簇相关联。重复此过程，直到会聚即质心不变为止。</li></ol><p>如何确定K的值：</p><p>在K均值中，我们有簇，每个簇都有自己的质心。质心和群集中数据点之间的差平方和构成该群集的平方值之和。同样，当所有聚类的平方和相加时，它成为聚类解的平方和之和。</p><p>我们知道，随着簇数的增加，该值会不断减少，但是如果绘制结果，您可能会看到平方距离的总和急剧减小，直至达到某个k值，然后逐渐减小。在这里，我们可以找到最佳的群集数量。</p><figure><img src="https://2020.iosdevlog.com/2020/03/08/algorithms/Kmenas.webp" alt="" /><figcaption>Kmenas</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Means</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to divide the training data into differernt clusters</span></span><br><span class="line"><span class="comment"># and predict in which cluster a particular data point belongs.  </span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Means model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_clusters and max_iter</span></span><br><span class="line"><span class="string">Documentation of sklearn KMeans: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line"></span><br><span class="line">model = KMeans()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nDefault number of Clusters : '</span>,model.n_clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we will train a model with n_cluster = 3</span></span><br><span class="line">model_n3 = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_n3.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nNumber of Clusters : '</span>,model_n3.n_clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train_3 = model_n3.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train_3) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test_3 = model_n3.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test_3)</span><br></pre></td></tr></table></figure><h3 id="随机森林">8. 随机森林</h3><p>随机森林是决策树集合的商标术语。在随机森林中，我们收集了决策树（也称为“森林”）。为了基于属性对新对象进行分类，每棵树都进行了分类，我们称该树为该类“投票”。森林选择投票最多的类别（在森林中的所有树木上）。</p><p>每棵树的种植和生长如下：</p><ol type="1"><li>如果训练集中的病例数为N，则随机抽取N个病例作为样本，并进行替换。该样本将成为树木生长的训练集。</li><li>如果有M个输入变量，则指定数字m &lt;&lt; M，以便在每个节点上从M个中随机选择m个变量，并使用对这m个变量的最佳分割来分割节点。在森林生长过程中，m的值保持恒定。</li><li>每棵树都尽可能地生长。没有修剪。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Random Forest</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Create the object of the Random Forest model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_estimators and max_depth</span></span><br><span class="line"><span class="string">Documentation of sklearn RandomForestClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of trees used</span></span><br><span class="line">print(<span class="string">'Number of Trees used : '</span>, model.n_estimators)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h3 id="降维算法">9.降维算法</h3><p>在过去的4-5年中，每个可能阶段的数据捕获都呈指数级增长。公司/政府机构/研究组织不仅提供了新的来源，而且还非常详细地捕获数据。</p><p>例如：电子商务公司正在捕获有关客户的更多详细信息，例如他们的人口统计信息，网络爬网历史记录，他们喜欢或不喜欢的东西，购买历史记录，反馈以及许多其他信息，这些东西比最近的杂货店店主更能给予他们个性化的关注。</p><p>作为数据科学家，我们提供的数据还包含许多功能，这对于构建良好的鲁棒模型听起来不错，但仍存在挑战。您如何识别1000或2000中的高有效变量？在这种情况下，降维算法可与其他各种算法（例如决策树，随机森林，PCA，因子分析，基于相关矩阵识别，缺失值比率等）一起帮助我们。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Principal Component Analysis (PCA)</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error  </span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(train_x.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create the object of the PCA (Principal Component Analysis) model</span></span><br><span class="line"><span class="comment"># reduce the dimensions of the data to 12</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : svd_solver, iterated_power</span></span><br><span class="line"><span class="string">Documentation of sklearn PCA:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model_pca = PCA(n_components=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">new_train = model_pca.fit_transform(train_x)</span><br><span class="line">new_test  = model_pca.fit_transform(test_x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(new_train.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model_new = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_new.fit(new_train,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new train dataset</span></span><br><span class="line">predict_train_pca = model_new.predict(new_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train_pca = mean_squared_error(train_y,predict_train_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new train dataset : '</span>, rmse_train_pca)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new test dataset</span></span><br><span class="line">predict_test_pca = model_new.predict(new_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test_pca = mean_squared_error(test_y,predict_test_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new test dataset : '</span>, rmse_test_pca)</span><br></pre></td></tr></table></figure><h3 id="梯度提升算法">10. 梯度提升算法</h3><h4 id="gbm">10.1 GBM</h4><p>当我们处理大量数据以进行具有高预测能力的预测时，GBM是一种增强算法。Boosting实际上是一种学习算法的集合，该算法结合了多个基本估计量的预测，以提高单个估计量的鲁棒性。它将多个弱或平均预测变量组合为一个构建强的预测变量。这些增强算法在Kaggle，AV Hackathon，CrowdAnalytix等数据科学竞赛中始终能很好地发挥作用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Gradient Boosting</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the GradientBoosting Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : learning_rate, n_estimators</span></span><br><span class="line"><span class="string">Documentation of sklearn GradientBoosting Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = GradientBoostingClassifier(n_estimators=<span class="number">100</span>,max_depth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h4 id="xgboost">10.2 XGBoost</h4><p>在某些Kaggle比赛中，另一种经典的梯度提升算法是决定胜负的决定性选择。</p><p>XGBoost具有极高的预测能力，这使其成为事件准确性的最佳选择，因为它同时具有线性模型和树学习算法，这使得该算法比现有的梯度增强技术快了近10倍。</p><p>支持包括各种目标功能，包括回归，分类和排名。</p><p>关于XGBoost的最有趣的事情之一是，它也被称为正则化增强技术。这有助于减少过拟合模型，并且对Scala，Java，R，Python，Julia和C ++等多种语言提供了广泛的支持。</p><p>支持在包含GCE，AWS，Azure和Yarn群集的许多计算机上进行分布式和广泛的培训。XGBoost还可以与Spark，Flink和其他云数据流系统集成，在提升过程的每次迭代中都具有内置的交叉验证。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for XGBoost</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test-data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the XGBoost model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and n_estimators</span></span><br><span class="line"><span class="string">Documentation of xgboost:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://xgboost.readthedocs.io/en/latest/</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure><h4 id="lightgbm">10.3 LightGBM</h4><p>LightGBM 是使用基于树的学习算法的梯度增强框架。它被设计为分布式且高效的，具有以下优点：</p><ul><li>更快的训练速度和更高的效率</li><li>降低内存使用量</li><li>精度更高</li><li>支持并行和GPU学习</li><li>能够处理大规模数据</li></ul><p>该框架是基于决策树算法的一种快速，高性能的梯度提升算法，用于排名，分类和许多其他机器学习任务。它是在Microsoft的分布式机器学习工具包项目下开发的。</p><p>由于LightGBM基于决策树算法，因此它以最佳拟合的方式对树进行拆分，而其他增强算法则对树的深度或层次进行拆分，而不是对叶进行拆分。因此，当在Light GBM中的同一叶上生长时，与逐级算法相比，逐叶算法可以减少更多的损失，因此可以得到更好的精度，而现有的任何增强算法都很少达到这种精度。</p><p>而且，它出奇地快，因此是“ Light”一词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.rand(<span class="number">500</span>, <span class="number">10</span>) <span class="comment"># 500 entities, each contains 10 features</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">500</span>) <span class="comment"># binary target</span></span><br><span class="line"></span><br><span class="line">train_data = lgb.Dataset(data, label=label)</span><br><span class="line">test_data = train_data.create_valid(<span class="string">'test.svm'</span>)</span><br><span class="line"></span><br><span class="line">param = &#123;<span class="string">'num_leaves'</span>:<span class="number">31</span>, <span class="string">'num_trees'</span>:<span class="number">100</span>, <span class="string">'objective'</span>:<span class="string">'binary'</span>&#125;</span><br><span class="line">param[<span class="string">'metric'</span>] = <span class="string">'auc'</span></span><br><span class="line"></span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])</span><br><span class="line"></span><br><span class="line">bst.save_model(<span class="string">'model.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7 entities, each contains 10 features</span></span><br><span class="line">data = np.random.rand(<span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">ypred = bst.predict(data)</span><br></pre></td></tr></table></figure><h4 id="catboost">10.4 Catboost</h4><p>CatBoost是Yandex最近提供的开源机器学习算法。它可以轻松地与深度学习框架（如Google的TensorFlow和Apple的Core ML）集成。</p><p>关于CatBoost的最好之处在于，它不需要像其他ML模型一样进行大量的数据培训，并且可以处理多种数据格式。不会破坏它的坚固性。</p><p>在继续实施之前，请确保处理好丢失的数据。</p><p>Catboost可以自动处理分类变量，而不会显示类型转换错误，这可以帮助您专注于更好地调整模型，而不是解决琐碎的错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment">#Read training and testing files</span></span><br><span class="line">train = pd.read_csv(<span class="string">"train.csv"</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">"test.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Imputing missing values for both train and test</span></span><br><span class="line">train.fillna(<span class="number">-999</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">test.fillna(<span class="number">-999</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Creating a training set for modeling and validation set to check model performance</span></span><br><span class="line">X = train.drop([<span class="string">'Item_Outlet_Sales'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = train.Item_Outlet_Sales</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=<span class="number">0.7</span>, random_state=<span class="number">1234</span>)</span><br><span class="line">categorical_features_indices = np.where(X.dtypes != np.float)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#importing library and building model</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressormodel=CatBoostRegressor(iterations=<span class="number">50</span>, depth=<span class="number">3</span>, learning_rate=<span class="number">0.1</span>, loss_function=<span class="string">'RMSE'</span>)</span><br><span class="line"></span><br><span class="line">model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_validation, y_validation),plot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">submission = pd.DataFrame()</span><br><span class="line"></span><br><span class="line">submission[<span class="string">'Item_Identifier'</span>] = test[<span class="string">'Item_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Outlet_Identifier'</span>] = test[<span class="string">'Outlet_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Item_Outlet_Sales'</span>] = model.predict(test)</span><br></pre></td></tr></table></figure><p>节选自：<a href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms" target="_blank" rel="noopener">Commonly used Machine Learning Algorithms (with Python and R Codes)</a><br />作者：<a href="https://www.analyticsvidhya.com/blog/author/sunil-ray/" target="_blank" rel="noopener">SUNIL RAY</a></p>]]></content>
    
    <summary type="html">
    
      &lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;线性回归&lt;/li&gt;
&lt;li&gt;逻辑回归&lt;/li&gt;
&lt;li&gt;决策树&lt;/li&gt;
&lt;li&gt;支持向量机&lt;/li&gt;
&lt;li&gt;朴素贝叶斯&lt;/li&gt;
&lt;li&gt;神经网络&lt;/li&gt;
&lt;li&gt;K均值&lt;/li&gt;
&lt;li&gt;随机森林&lt;/li&gt;
&lt;li&gt;降维算法&lt;/li&gt;
&lt;li&gt;梯度提升算法
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;GBM&lt;/li&gt;
&lt;li&gt;XGBoost&lt;/li&gt;
&lt;li&gt;LightGBM&lt;/li&gt;
&lt;li&gt;Catboost&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="https://2020.iosdevlog.com/categories/algorithm/"/>
    
    
      <category term="ml" scheme="https://2020.iosdevlog.com/tags/ml/"/>
    
  </entry>
  
  <entry>
    <title>《神经网络与深度学习》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/03/07/nn/"/>
    <id>https://2020.iosdevlog.com/2020/03/07/nn/</id>
    <published>2020-03-07T11:53:40.000Z</published>
    <updated>2020-03-08T15:02:17.574Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/07/nn/1.png" alt="" /><figcaption>神经网络与深度学习</figcaption></figure><a id="more"></a><h2 id="使用神经网络识别手写数字">使用神经网络识别手写数字</h2><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/001014.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000774.jpg" /></p><h3 id="感知机">感知机</h3><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/001124.jpg" /></p><ul><li>输入</li><li>输出</li><li>权重（weight）</li><li>阈值（threshold value）</li></ul><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000011.jpg" /></p><ul><li><p>偏置（bias）</p></li><li><p>与非门 (NAND gate)</p></li></ul><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000155.jpg" /></p><p>感知机网络计算任何逻辑函数</p><figure><img src="https://2020.iosdevlog.com/2020/03/07/nn/000495.jpg" alt="" /><figcaption>NAND</figcaption></figure><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000706.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000303.jpg" /></p><p>一个没有输入的感知机，那么加权和恒为 0。</p><p>所以，我们最好不要将输入感知机当做感知机，而是理解为一个特殊的单元，它能够输出我们想要的值。</p><figure><img src="https://2020.iosdevlog.com/2020/03/07/nn/000617.jpg" alt="" /><figcaption>输入感知机</figcaption></figure><h3 id="sigmoid神经元">sigmoid神经元</h3><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000110.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000277.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000127.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000625.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000586.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000463.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/001018.jpg" /></p><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000626.jpg" /></p><h3 id="神经网络的结构">神经网络的结构</h3><h3 id="用简单的网络结构解决手写数字识别">用简单的网络结构解决手写数字识别</h3><h3 id="通过梯度下降法学习参数">通过梯度下降法学习参数</h3><h3 id="实现我们的神经网络来分类数字">实现我们的神经网络来分类数字</h3><h3 id="迈向深度学习">迈向深度学习</h3><h2 id="反向传播算法是如何工作的">反向传播算法是如何工作的</h2><h3 id="热身一个基于矩阵的快速计算神经网络输出的方法">热身：一个基于矩阵的快速计算神经网络输出的方法</h3><h3 id="关于代价函数的两个假设">关于代价函数的两个假设</h3><h3 id="hadamard积st">Hadamard积，s⨀t</h3><h3 id="反向传播背后的四个基本等式">反向传播背后的四个基本等式</h3><h3 id="四个基本方程的证明自选">四个基本方程的证明（自选）</h3><h3 id="反向传播算法">反向传播算法</h3><h3 id="反向传播算法代码">反向传播算法代码</h3><h3 id="为什么说反向传播算法很高效">为什么说反向传播算法很高效</h3><h3 id="反向传播整体描述">反向传播：整体描述</h3><h2 id="改进神经网络的学习方法">改进神经网络的学习方法</h2><h3 id="交叉熵代价函数">交叉熵代价函数</h3><h3 id="用交叉熵解决手写数字识别问题">用交叉熵解决手写数字识别问题</h3><h3 id="交叉熵的意义是什么它又是怎么来的">交叉熵的意义是什么？它又是怎么来的？</h3><h3 id="softmax">Softmax</h3><h3 id="过拟合和正则化">过拟合和正则化</h3><ul><li><p>正则化</p></li><li><p>为什么正则化能够降低过拟合</p></li></ul><h3 id="其它正则化技术">其它正则化技术</h3><h3 id="参数初始化">参数初始化</h3><h3 id="重温手写数字识别代码">重温手写数字识别：代码</h3><h3 id="如何选择神经网络的超参数">如何选择神经网络的超参数</h3><h3 id="其它技术">其它技术</h3><h2 id="神经网络可以计算任何函数的可视化证明">神经网络可以计算任何函数的可视化证明</h2><h3 id="两个预先声明">两个预先声明</h3><h3 id="一个输入和一个输出的普遍性">一个输入和一个输出的普遍性</h3><h3 id="多个输入变量">多个输入变量</h3><h3 id="s型神经元的延伸">S型神经元的延伸</h3><h3 id="修补阶跃函数">修补阶跃函数</h3><h3 id="结论">结论</h3><h2 id="为什么深度神经网络的训练是困难的">为什么深度神经网络的训练是困难的</h2><h3 id="梯度消失问题">梯度消失问题</h3><h3 id="什么导致了消失的梯度问题深度神经网络中的梯度不稳定性">什么导致了消失的梯度问题？深度神经网络中的梯度不稳定性</h3><h3 id="在更加复杂网络中的不稳定梯度">在更加复杂网络中的不稳定梯度</h3><h3 id="其他深度学习的障碍">其他深度学习的障碍</h3><h2 id="深度学习">深度学习</h2><h3 id="介绍卷积网络">介绍卷积网络</h3><h3 id="卷积神经网络在实际中的应用">卷积神经网络在实际中的应用</h3><h3 id="卷积网络的代码">卷积网络的代码</h3><h3 id="图像识别领域中的近期进展">图像识别领域中的近期进展</h3><h3 id="其他的深度学习模型">其他的深度学习模型</h3><h3 id="神经网络的未来">神经网络的未来</h3><p><img src="https://2020.iosdevlog.com/2020/03/07/nn/000058.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000073.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000077.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000085.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000217.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000264.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000275.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000280.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000294.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000296.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000476.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000508.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000543.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000546.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000570.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000610.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000657.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000700.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000729.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000742.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000771.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000805.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000817.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000883.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000894.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000906.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000911.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/000916.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001008.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001035.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001047.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001059.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001070.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001089.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001110.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001119.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001120.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/001145.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/03/07/nn/.jpg" /></p><p>源码：<a href="https://github.com/mnielsen/neural-networks-and-deep-learning" target="_blank" rel="noopener" class="uri">https://github.com/mnielsen/neural-networks-and-deep-learning</a></p><p>英文：<a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener" class="uri">http://neuralnetworksanddeeplearning.com/</a></p><p>中文：<a href="https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/" target="_blank" rel="noopener" class="uri">https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/07/nn/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;神经网络与深度学习&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="dl" scheme="https://2020.iosdevlog.com/tags/dl/"/>
    
      <category term="nn" scheme="https://2020.iosdevlog.com/tags/nn/"/>
    
  </entry>
  
  <entry>
    <title>深度学习简介</title>
    <link href="https://2020.iosdevlog.com/2020/03/06/dl/"/>
    <id>https://2020.iosdevlog.com/2020/03/06/dl/</id>
    <published>2020-03-06T14:23:02.000Z</published>
    <updated>2020-03-06T14:27:19.310Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/06/dl/1.png" alt="" /><figcaption>深度学习简介</figcaption></figure><a id="more"></a><h2 id="统计学基础随机性是如何改变数据拟合的本质的">统计学基础：随机性是如何改变数据拟合的本质的？</h2><h3 id="出发点">出发点</h3><ul><li><p>数学定理表明，任何一个函数都可以用多项式无限接近的拟合。</p></li><li><p>为什么我们不用多项式呢？</p></li></ul><h3 id="随机性是如何改变数据拟合本质的">随机性是如何改变数据拟合本质的</h3><ul><li><p>数据的拟合有两种随机性：</p><ul><li><p>噪声-&gt;无法消除</p></li><li><p>函数拟合的随机性-&gt;可以提升</p></li></ul></li><li><p>过拟合和欠拟合</p></li><li><p>引入其他信息的必要性</p></li><li><p>多角度考虑问题</p></li></ul><h3 id="随机性对算法工程师意味着什么">随机性对算法工程师意味着什么</h3><ul><li><p>过拟合和欠拟合是对神经网络设计和训练很重要的一点，但不是全部</p></li><li><p>能否解决问题在很大程度上取决于数据是否有足够信息</p><ul><li><p>引入结构化数据的必要性</p></li><li><p>为什么人解决不了的问题机器也解决不了</p></li></ul></li><li><p>算法除了考虑数学之外，还需要考虑实际数据的情况</p></li><li><p>训练集和测试集不同是机器学习算法最大的坑</p></li></ul><h2 id="神经网络基础神经网络还是复合函数">神经网络基础：神经网络还是复合函数</h2><h3 id="关于神经网络错误的说法">关于神经网络错误的说法</h3><ul><li>神经网络是大家根据神经科学得到的最伟大的发明</li></ul><h3 id="神经网络的数学本质">神经网络的数学本质</h3><ul><li><p>由于神经网络复合函数的本质，使得神经网络可以很方便地组合出很多复杂的函数</p></li><li><p>由于复合函数求导法则，所以大部分神经网络的训练过程可以自动化（反向梯度传递）</p></li></ul><h3 id="一些神经网络术语">一些神经网络术语</h3><ul><li><p>神经网络的训练</p></li><li><p>神经层</p></li><li><p>激活函数</p></li><li><p>隐含层</p></li></ul><h2 id="神经网络基础训练神经网络">神经网络基础：训练神经网络</h2><h3 id="传统优化求解方法的问题">传统优化求解方法的问题</h3><ul><li><p>传统的求解方法：</p><ul><li><p>拟牛顿法等</p></li><li><p>Proximal Methods</p></li></ul></li><li><p>传统求解方法的问题</p><ul><li>传统方法需要根据全部样本计算梯度（导数），这导致对于非常复杂的网络，求解计算上根本不可行</li></ul></li></ul><h3 id="基础的梯度下降算法">基础的梯度下降算法</h3><ul><li><p>经典的优化算法</p><ul><li><p>SGD</p></li><li><p>SGD with Momentum</p></li><li><p>Adagrad</p></li><li><p>Adam</p></li></ul></li></ul><h3 id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</h3><ul><li><p>由于求解过程的复杂性，这使得神经网络的求解并不一定会收敛到最优解</p></li><li><p>对于神经网络训练最大的敌人是梯度消失和梯度爆炸</p></li><li><p>解决梯度消失和梯度爆炸往往是网络设计和优化算法需要考虑的问题</p></li></ul><h2 id="神经网络基础神经网络的基础构成">神经网络基础：神经网络的基础构成</h2><h3 id="全连接层">全连接层</h3><h3 id="激活函数">激活函数</h3><h3 id="dropout">Dropout</h3><h3 id="batch-normalization">Batch Normalization</h3><h2 id="embedding-简介">Embedding 简介</h2><h3 id="什么是-embedding">什么是 Embedding</h3><h3 id="为什么我们需要-embedding">为什么我们需要 Embedding</h3><h3 id="embedding-是怎么训练的">Embedding 是怎么训练的</h3><h2 id="rnn-简介">RNN 简介</h2><h3 id="rnn">RNN</h3><h3 id="lstm">LSTM</h3><h3 id="马尔科夫过程">马尔科夫过程</h3><h3 id="隐马尔科夫过程">隐马尔科夫过程</h3><h2 id="cnn-简介">CNN 简介</h2><h3 id="cnn">CNN</h3><h3 id="cnn-如何应用在文本当中">CNN 如何应用在文本当中</h3><ul><li><p>传统来说，NLP 当中的 CNN 一般较浅，但有证据表明更深的 CNN 更有效。</p></li><li><p>在传统文本分类模型当中，CNN 效果往往要比 LSTM 分类效果好（但不一定）。</p></li></ul><p>参考：<a href="https://github.com/geektime-geekbang/NLP" target="_blank" rel="noopener" class="uri">https://github.com/geektime-geekbang/NLP</a></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/06/dl/1.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;深度学习简介&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://2020.iosdevlog.com/categories/AI/"/>
    
    
      <category term="dl" scheme="https://2020.iosdevlog.com/tags/dl/"/>
    
  </entry>
  
  <entry>
    <title>反向图灵测试 Reverse Turing test</title>
    <link href="https://2020.iosdevlog.com/2020/03/05/Reverse-Turing-test/"/>
    <id>https://2020.iosdevlog.com/2020/03/05/Reverse-Turing-test/</id>
    <published>2020-03-05T13:27:58.000Z</published>
    <updated>2020-03-05T13:54:26.717Z</updated>
    
    <content type="html"><![CDATA[<p>如果漫画家手冢治虫还活着，会在漫画中描绘出什么样的未来？AI 是否能够帮他呈现？</p><figure><img src="https://2020.iosdevlog.com/2020/03/05/Reverse-Turing-test/1.gif" alt="" /><figcaption>AI复活已故漫画家手冢治虫</figcaption></figure><p>通过分析其作品，人工智能产生了角色设计和基本故事情节。据悉，新漫画的主人公是 AI 学习了 6000 张角色图像之后生成的。之后由专业创作者添加诸如服装和对话之类的元素以完善作品。</p><a id="more"></a><h2 id="验证码-captcha">验证码 / CAPTCHA</h2><p>全自动区分计算机和人类的公开图灵测试（英语：Completely Automated Public Turing test to tell Computers and Humans Apart，简称CAPTCHA），俗称验证码，是一种区分用户是计算机或人的公共全自动程序。在 CAPTCHA 测试中，作为服务器的计算机会自动生成一个问题由用户来解答。这个问题可以由计算机生成并评判，但是必须只有人类才能解答。由于计算机无法解答 CAPTCHA 的问题，所以回答出问题的用户就可以被认为是人类。</p><p>一种常用的 CAPTCHA 测试是让用户输入一个扭曲变形的图片上所显示的文字或数字，扭曲变形是为了避免被 <code>光学字符识别</code>（<strong>OCR</strong>, Optical Character Recognition）之类的计算机程序自动识别出图片上的文数字而失去效果。由于这个测试是由计算机来考人类，而不是标准图灵测试中那样由人类来考计算机，人们有时称 CAPTCHA 是一种 <em>反向图灵测试</em>。</p><h2 id="图灵测试">图灵测试</h2><p>图灵测试（英语：Turing test，又译图灵试验）是图灵于1950年提出的一个关于判断机器是否能够思考的著名思想实验，测试某机器是否能表现出与人等价或无法区分的智能。测试的谈话仅限于使用唯一的文本管道，例如计算机键盘和屏幕，这样的结果不依赖于计算机把单词转换为音频的能力。</p><h3 id="测试内容">测试内容</h3><blockquote><p>如果一个人（代号C）使用测试对象皆理解的语言去询问两个他不能看见的对象任意一串问题。对象为：一个是正常思维的人（代号B）、一个是机器（代号A）。如果经过若干询问以后，C不能得出实质的区别来分辨A与B的不同，则此机器A通过图灵测试。</p></blockquote><h3 id="完成图灵测试涉及的技术课题">完成图灵测试涉及的技术课题</h3><p>根据人们的大体判断，达成能够通过图灵测试的技术涉及以下课题</p><ul><li>自然语言处理</li><li>知识表示</li><li>自动推理</li><li>机器学习</li></ul><p>但是为了通过完全图灵测试，还需要另外两项额外技术课题：</p><ul><li>计算机视觉</li><li>机器人学</li></ul><h3 id="反向图灵测试和验证码">反向图灵测试和验证码</h3><p>验证码（CAPTCHA）是一种反向图灵测试。在网站上运行一些动作之前，用户被给予一个扭曲的图形，并要求用户输入图中的字母或数字。这是为了防止网站被自动化系统用来滥用。理由是能够精细地阅读和准确地重现扭曲的形象的系统并不存在（或不提供给普通用户），所以能够做到这一点的任何系统可能是一个人类。</p><p>可以破解验证码的软件正在被积极开发，软件拥有一个有一定的准确性的验证码分析模式生成引擎。而在破解验证码软件被积极开发的同时，另一种通过反向图灵测试的准则也被提出来。其认为即使破解验证码软件被成功研发，也只是具有智能的人类透过编程对验证码所作出的破解手段而已，并非真正通过反向图灵测试或图灵测试。而如果一台机器能够规划出如同验证码一类的防止自动化系统的规避程序，此台机器才算是真正通过了反向图灵测试。</p><h3 id="完全图灵测试">完全图灵测试</h3><p>普通的图灵测试一般避免审问者与被测试计算机发生物理上的互动，因为物理上模拟人（比如像模拟人的外表）并不是人工智能的研究范畴。然而一些人工智能可能涉及一些人机在物理上的交互，所以人们又拓展出了“完全图灵测试”。在完全图灵测试中，可以包含必要的人机在物理层面上的交互。但是为了通过完全图灵测试，还需要在普通图灵测试之外另外两项额外技术课题。询问者还可以测试的受试者感知能力（需要计算机视觉），和受试者操纵物体的能力（需要机器人学）。</p><h2 id="反向图灵测试-reverse-turing-test">反向图灵测试 Reverse Turing test</h2><p>可以说，反向图灵测试的标准形式是受试者试图表现为计算机而非人类的形式。</p><p>在反向图灵测试中表现最佳的人员是最了解计算机的人员，因此知道计算机在对话中可能会犯的错误的类型。</p><p>在计算机编程尤其是调试过程中，反向图灵测试的技巧与思维上模拟程序操作的技巧之间有着很多共识。结果，<code>程序员（尤其是黑客）</code> 有时会沉迷于非正式的反向图灵测试中以进行娱乐。</p><p>参考：<a href="https://www.wikipedia.org" target="_blank" rel="noopener" class="uri">https://www.wikipedia.org</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果漫画家手冢治虫还活着，会在漫画中描绘出什么样的未来？AI 是否能够帮他呈现？&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/05/Reverse-Turing-test/1.gif&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;AI复活已故漫画家手冢治虫&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;通过分析其作品，人工智能产生了角色设计和基本故事情节。据悉，新漫画的主人公是 AI 学习了 6000 张角色图像之后生成的。之后由专业创作者添加诸如服装和对话之类的元素以完善作品。&lt;/p&gt;
    
    </summary>
    
    
      <category term="game" scheme="https://2020.iosdevlog.com/categories/game/"/>
    
    
      <category term="Godot" scheme="https://2020.iosdevlog.com/tags/Godot/"/>
    
  </entry>
  
  <entry>
    <title>线性回归  Manim 演示</title>
    <link href="https://2020.iosdevlog.com/2020/03/04/manim/"/>
    <id>https://2020.iosdevlog.com/2020/03/04/manim/</id>
    <published>2020-03-04T14:00:06.000Z</published>
    <updated>2020-03-04T14:06:20.253Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/03/dl/0.jpg" alt="" /><figcaption>Linear Regression Overview</figcaption></figure><p><a href="https://youtube.com/watch?v=3vl17ymkODg" target="_blank" rel="noopener" class="uri">https://youtube.com/watch?v=3vl17ymkODg</a></p><p>机器学习算法如果能向 3B1B 一样展示，必能加深对算法的理解。</p><p>准备做一些视频展示，可以直接调用 sklearn，当然也可以自己写一套算法，为了了解原理，还是直接调用 sklearn等成熟的算法库好了（自己写有点慢，把代码看懂还是有必要的）。</p><p>Manim 非官方文档：<a href="https://elteoremadebeethoven.github.io/manim_3feb_docs.github.io/html/index.html" target="_blank" rel="noopener" class="uri">https://elteoremadebeethoven.github.io/manim_3feb_docs.github.io/html/index.html</a></p><a id="more"></a><p><img src="https://2020.iosdevlog.com/2020/03/03/dl/1.jpg" alt="1" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/2.jpg" alt="2" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/3.jpg" alt="3" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/4.jpg" alt="4" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/5.jpg" alt="5" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/6.jpg" alt="6" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/7.jpg" alt="7" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/8.jpg" alt="8" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/9.jpg" alt="9" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/10.jpg" alt="10" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/11.jpg" alt="11" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/12.jpg" alt="12" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/13.jpg" alt="13" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/14.jpg" alt="14" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/15.jpg" alt="15" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/16.jpg" alt="16" /><br /><img src="https://2020.iosdevlog.com/2020/03/03/dl/17.jpg" alt="17" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/03/dl/0.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Linear Regression Overview&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://youtube.com/watch?v=3vl17ymkODg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://youtube.com/watch?v=3vl17ymkODg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;机器学习算法如果能向 3B1B 一样展示，必能加深对算法的理解。&lt;/p&gt;
&lt;p&gt;准备做一些视频展示，可以直接调用 sklearn，当然也可以自己写一套算法，为了了解原理，还是直接调用 sklearn等成熟的算法库好了（自己写有点慢，把代码看懂还是有必要的）。&lt;/p&gt;
&lt;p&gt;Manim 非官方文档：&lt;a href=&quot;https://elteoremadebeethoven.github.io/manim_3feb_docs.github.io/html/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://elteoremadebeethoven.github.io/manim_3feb_docs.github.io/html/index.html&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="dl" scheme="https://2020.iosdevlog.com/categories/dl/"/>
    
    
      <category term="-lr -manim" scheme="https://2020.iosdevlog.com/tags/lr-manim/"/>
    
  </entry>
  
  <entry>
    <title>我的微信公众号头像侵权</title>
    <link href="https://2020.iosdevlog.com/2020/03/03/copyright/"/>
    <id>https://2020.iosdevlog.com/2020/03/03/copyright/</id>
    <published>2020-03-03T15:23:24.000Z</published>
    <updated>2020-03-03T15:55:29.538Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/03/copyright/1.jpg" alt="" /><figcaption>侵权</figcaption></figure><a id="more"></a><p>今天需要上传 <code>ipa</code> 到 <code>App Store</code>，使用 <code>Apple</code> 最近推出的上传工具 <code>Transporter</code> 上传。</p><p>期间遇到卡住问题，于是更新了一篇 Blog，准备也发到我的公众号：iOSDevLog。</p><p>好长时间没有登录这个帐号群发消息，一进入就发现我公众号的头像侵权了。</p><p>你的帐号经查涉嫌头像侵权，违规内容已清空处理。</p><p>你可重新进行设置但请遵守规范。如果再有类似违规情况，将加重处罚甚至永久性屏蔽所有功能。</p><p>违反规范：《微信公众平台运营规范》4.1.1条规定</p><p>微信公众平台已依法进行侵权投诉处理，法定的平台义务已经履行完毕。若你对于投诉方的意见有异议，建议你另行通过行政投诉、诉讼等方式与投诉方解决。</p><table><colgroup><col style="width: 21%" /><col style="width: 21%" /><col style="width: 15%" /><col style="width: 21%" /><col style="width: 21%" /></colgroup><tbody><tr class="odd"><td style="text-align: left;">权利人</td><td style="text-align: left;">姓名/名称</td><td style="text-align: left;">苹果</td><td style="text-align: left;">有效证件（复印件附后）</td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">通讯地址</td><td style="text-align: left;">中国 - 上海 - 浦东新区 外高桥保税区马吉路88号C区6号楼全幢</td><td style="text-align: left;">邮编</td><td style="text-align: left;">200000</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;">联系人</td><td style="text-align: left;">O********</td><td style="text-align: left;">电话</td><td style="text-align: left;">182211*****</td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">E-mail</td><td style="text-align: left;">e******<span class="citation" data-cites="apple.com">@apple.com</span></td><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;">投诉帐号</td><td style="text-align: left;">iOS开发日志 （iOSDevLog）</td><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">投诉类型</td><td style="text-align: left;">头像侵权</td><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;">被侵权内容</td><td style="text-align: left;">商标</td><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">投诉描述</td><td style="text-align: left;">以下内容非微信官方提供，由权利人投诉时填写，请谨慎操作。</td><td style="text-align: left;">被投诉公众号未经苹果公司授权注册或运营。其账号、名称、头像及内容等多处未经授权使用苹果公司注册商标，侵犯我公司商标权，严重误导消费者。权利人要求立即停止上述侵权行为。</td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;">证明资料</td><td style="text-align: left;">商标注册书</td><td style="text-align: left;">营业执照</td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">保证声明</td><td style="text-align: left;">权利人及其代理人（统称为：声明人）诚意作如下声明</td><td style="text-align: left;">声明人在通知书中的陈述和提供的相关材料皆是真实、有效、合法的，并保证承担和赔偿腾讯因根据声明人的通知书对相关帐号的处理而给腾讯造成的任何损失，包括但不限于腾讯因向被投诉方或用户赔偿而产生的损失及腾讯名誉、商誉损害等。</td><td style="text-align: left;"></td><td style="text-align: left;"></td></tr></tbody></table><p>对此我的态度就是 <strong>认错</strong>，要改头像。一时间又没有想好想改成什么样，就直接用我 <code>AIDevLog</code> 的二维码好了。</p><h2 id="苹果不让坏人用-iphone-好莱坞导演透露电影业潜规则1">苹果不让坏人用 iPhone !好莱坞导演透露电影业潜规则<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></h2><p>瑞安·约翰逊（Rian Johnson），最受欢迎的电影制片人之一（布鲁克，布卢姆兄弟，洛珀（2012），《星球大战：最后的绝地武士》，《刀叉》）进行了有趣的采访 “名利场”。 他特别提到了安置协议 iPhone 在电影院里。 据约翰逊说， η 苹果公司 允许 使用 iPhone，但不允许坏人拥有它们 电影.</p><p>瑞安·约翰逊（Rian Johnson）具体说：</p><blockquote><p>“另外一件有趣的事，我不知道是否要说……不是因为它不好或什么，而是因为它会影响下一个 电影 我正在写一个谜..算了！ 我会说。 非常有趣</p><p>苹果…允许使用iPhone，但是-如果您正在观看一部神秘电影，这非常重要- 电影中的坏人无法拥有iPhone。</p><p>所以...哦，不！ 每一个 创造者 他的电影中有小人，他现在想杀了我！”</p></blockquote><p>众所周知 <strong>苹果公司</strong> 有 <strong>严格的规则</strong> 关于如何使用，显示和拍照iPhone和其他产品 家电 的。 例如，苹果公司报告说 该 制品 它应该只在“尽可能好的光线下”出现， 以便以最佳方式展示 iPhone。</p><p>过去许多人已经注意到，只有“好人”才能在电视节目和电影中使用Apple产品。 播放“ 24”时， 有线 写一个 理论 粉丝曾经说过 好孩子用 苹果电脑 而坏人会用它 个人电脑。 该理论似乎是正确的。</p><p>约翰逊发表声明后，观众肯定会更加专心，并观看 家电 演员用来了解坏人在电影中的适时出现。</p><p>看来 <strong>苹果公司</strong> 是非常注重它的品牌，以后对头像，图片，Code，数据等使用，最好选择无版权的或者是公开的，避免陷入不必要的麻烦（大公司让个人免费用盗版，等公司能交得起时...）。</p><section class="footnotes" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>苹果不允许坏人在电影中使用iPhone！：<a href="https://zh-cn.secnews.gr/213337/iphone苹果酱kakoi/" target="_blank" rel="noopener" class="uri">https://zh-cn.secnews.gr/213337/iphone苹果酱kakoi/</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/03/copyright/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;侵权&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="运营" scheme="https://2020.iosdevlog.com/categories/%E8%BF%90%E8%90%A5/"/>
    
    
      <category term="公众号" scheme="https://2020.iosdevlog.com/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/"/>
    
      <category term="Apple" scheme="https://2020.iosdevlog.com/tags/Apple/"/>
    
      <category term="版权" scheme="https://2020.iosdevlog.com/tags/%E7%89%88%E6%9D%83/"/>
    
  </entry>
  
  <entry>
    <title>Transporter 上传慢解决方案</title>
    <link href="https://2020.iosdevlog.com/2020/03/03/Transporter/"/>
    <id>https://2020.iosdevlog.com/2020/03/03/Transporter/</id>
    <published>2020-03-03T14:56:11.000Z</published>
    <updated>2020-03-03T15:08:08.776Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/03/Transporter/1.jpg" alt="" /><figcaption>Transporter</figcaption></figure><a id="more"></a><p>解决使用 Transporter 上传 <strong>ipa</strong> 到 App Store 时，有时间会卡住或者非常慢。</p><h2 id="使用">使用</h2><ol type="1"><li>下载 <code>Release</code> 下面的 <code>zip</code> 包，或者 <code>git clone https://github.com/iOSDevLog/com.apple.amp.itmstransporter</code></li><li>替换<code>~/Library/Caches/com.apple.amp.itmstransporter</code></li></ol><h2 id="原因">原因</h2><p>Transporter 安装上第一次打开后，会在硬盘 <code>~/Library/Caches/com.apple.amp.itmstransporter</code> 目录下下载一些缓存文件，这些缓存文件没有下载完，或者下载失败没下载完时，使用Transporter去提交应用这个页面就会卡住或者这个页面很慢。</p><h2 id="解决方案">解决方案</h2><p>终端运行命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Applications/Transporter.app/Contents/itms/bin/iTMSTransporter</span><br></pre></td></tr></table></figure><p>查看 <code>~/Library/Caches/com.apple.amp.itmstransporter</code> 变化</p><p>如果有报错信息 <code>https://...jar</code>，把 <code>jar</code> 文件下载下来，放入 <code>~/Library/Caches/com.apple.amp.itmstransporter/obr/2.2.0/</code></p><p>再次运行</p><p><code>/Applications/Transporter.app/Contents/itms/bin/iTMSTransporter</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[2020-03-03 12:28:39 CST] &lt;main&gt;  INFO: Configuring logging...</span><br><span class="line">[2020-03-03 12:28:39 CST] &lt;main&gt;  INFO: Logging level <span class="built_in">set</span> to eXtreme</span><br><span class="line">[2020-03-03 12:28:39 CST] &lt;main&gt;  INFO: Transporter is searching <span class="keyword">for</span> new software components.</span><br><span class="line">[2020-03-03 12:28:39 CST] &lt;main&gt;  INFO: INFO: using cached repository.xml file.</span><br><span class="line">[2020-03-03 12:28:40 CST] &lt;main&gt;  INFO: Update check complete.</span><br><span class="line">[2020-03-03 12:28:41 CST] &lt;main&gt; DEBUG: Attempting refresh of configuration data from https://contentdelivery.itunes.apple.com/transporter/Defaults.properties</span><br><span class="line">[2020-03-03 12:28:41 CST] &lt;main&gt; DEBUG: Configuration refresh successful.</span><br><span class="line">[2020-03-03 12:28:41 CST] &lt;main&gt; DEBUG: Saving configuration to <span class="built_in">local</span> path: /Users/iosdevlog/Library/Caches/com.apple.amp.itmstransporter/Defaults.properties</span><br><span class="line">usage: iTMSTransporter [-<span class="built_in">help</span> &lt;arg&gt; | -info | -m &lt;arg&gt; | -version]   [-o &lt;arg&gt;] [-v</span><br><span class="line">       &lt;arg&gt;]  [-WONoPause &lt;arg&gt;] [-Xmx4096m]</span><br><span class="line">iTMSTransporter : iTunes Store Transporter 2.0.0</span><br><span class="line"> -<span class="built_in">help</span> &lt;arg&gt;        Show this <span class="built_in">help</span>.  If a mode value is specified, show <span class="built_in">help</span> specific</span><br><span class="line">                    to that mode.</span><br><span class="line"> -info              The -info option should be used by itself and returns the</span><br><span class="line">                    copyright notice and acknowledgements.</span><br><span class="line"> -m &lt;arg&gt;           The -m option specifies the tool<span class="string">'s mode.  The valid values are:</span></span><br><span class="line"><span class="string">                    verify, upload, provider, diagnostic, lookupMetadata,</span></span><br><span class="line"><span class="string">                    createArtist, lookupArtist, status, statusAll,</span></span><br><span class="line"><span class="string">                    createMetadataTicket, queryTickets, generateSchema, transferTest,</span></span><br><span class="line"><span class="string">                    downloadMetadataGuides, listReports, requestReport</span></span><br><span class="line"><span class="string"> -o &lt;arg&gt;           The -o option specifies the directory and filename you want to use</span></span><br><span class="line"><span class="string">                    to log output information.  By default, Transporter logs output</span></span><br><span class="line"><span class="string">                    information to standard out. If you specify a filename,</span></span><br><span class="line"><span class="string">                    Transporter logs the output to the specified file, as well as to</span></span><br><span class="line"><span class="string">                    standard out.</span></span><br><span class="line"><span class="string"> -v &lt;arg&gt;           The -v option specifies the level of logging.  The five values</span></span><br><span class="line"><span class="string">                    are: off, detailed, informational, critical, eXtreme.</span></span><br><span class="line"><span class="string"> -version           The -version option should be used by itself and returns the</span></span><br><span class="line"><span class="string">                    version of the tool.</span></span><br><span class="line"><span class="string"> -WONoPause &lt;arg&gt;   The -WONoPause option is only valid on Windows and its value can</span></span><br><span class="line"><span class="string">                    be '</span><span class="literal">true</span><span class="string">' or '</span><span class="literal">false</span><span class="string">'.  If an error occurs during script execution,</span></span><br><span class="line"><span class="string">                    the process idles because the message '</span>Press any key...<span class="string">' is</span></span><br><span class="line"><span class="string">                    displayed on the console and the system awaits a keypress. To</span></span><br><span class="line"><span class="string">                    avoid this behavior, set this property to true</span></span><br><span class="line"><span class="string"> -Xmx4096m          Specifies that you want to change the Java Virtual Machine'</span>s (JVM)</span><br><span class="line">                    allocated memory by increasing the JVM heap size.  By default,</span><br><span class="line">                    Transporter uses a 2048MB heap size. You can use the -Xmx4096m</span><br><span class="line">                    option to specify a 4-gigabyte (GB) heap size. Apple recommends,</span><br><span class="line">                    <span class="keyword">if</span> needed, increasing the heap size to 4096MB by specifying the</span><br><span class="line">                    -Xmx4096m (or -Xmx4g) option and adjusting as needed.</span><br><span class="line">[2020-03-03 12:28:41 CST] &lt;main&gt; DBG-X: Returning 0</span><br></pre></td></tr></table></figure><p>出现以上结果说明正常。</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/03/Transporter/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Transporter&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Tool" scheme="https://2020.iosdevlog.com/categories/Tool/"/>
    
    
      <category term="iOS" scheme="https://2020.iosdevlog.com/tags/iOS/"/>
    
  </entry>
  
  <entry>
    <title>《Google工作法》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/03/02/9787540492908/"/>
    <id>https://2020.iosdevlog.com/2020/03/02/9787540492908/</id>
    <published>2020-03-02T12:01:27.000Z</published>
    <updated>2020-03-02T15:15:07.579Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/1.jpg" alt="" /><figcaption>Google工作法</figcaption></figure><p>书名：Google工作法<br />作者：[波]彼得·费利克斯·格日瓦奇<br />译者：朱悦玮<br />出版社：湖南文艺出版社<br />出版时间：2019-08<br />ISBN：9787540492908</p><blockquote><p>明明很努力地工作，但工作总是做不完。<br />明明很努力地工作，但工作总是不顺利。<br />而且，这样的状态还一直在持续...</p></blockquote><p>——这本书将彻底解决你的烦恼。</p><a id="more"></a><h2 id="简介">简介</h2><p>《Google工作法》是一本介绍Google内部高效工作法的经管图书。 工作高效的人为什么不爱用邮件？为什么明明很努力工作，却怎么也做不完，而且还不顺利？本书传授57个核心技巧，一次性把Google的高效秘密倾囊相授。</p><p>AI时代来临，与其担心工作是否被取代，不如改变低效的工作方式，找到让个人或者企业立足的强有力资本。所谓高效，并不是快速完成某项工作而已，而是把更多时间留给更有价值的工作。把握这个核心，就能很好地理解Google为什么能成为令全世界侧目的高科技企业。</p><p>本书适合企业中各个层次的读者阅读，在快速变化的时代找到自己的核心价值。 Google“每一分钟”的使用方法都不一样！ 不把工作带回去。明白就是明白，不明白就是不明白。不要过分依赖邮件。不做过多分析。需要休息的时候就休息一下。考虑让自己的工作消失。</p><h2 id="为什么日本的企业生产效率低下">为什么日本的企业生产效率低下</h2><ol type="1"><li>过度推迟讨论</li><li>过分讨论</li><li>过度的交流</li></ol><h2 id="改变工作方式方法才是生存之道">改变工作方式方法才是生存之道</h2><p>很多人都害怕自己的工作会被IT（信息技术）和AI（人工智能）所取代。</p><p>我们不应该害怕“自己的工作消失”，而是应该思考“怎样做才能够用IT来代替自己的工作”“怎样做才能够更加自动化、省力化”。</p><p>当时我最深刻的感受就是 <strong>变化突然就到来了</strong>，并且认识到 <strong>自己也必须做出改变才行</strong>。</p><h2 id="让你比世界更快的工作术-不要依赖邮件">让你比世界更快的工作术 不要依赖邮件</h2><p>我认为决定工作效率的关键在于对“现在”的使用方法。</p><p>谷歌为了取得10倍的成果，“现在做”和“现在不做的话那要等到什么时候做”的意识非常强。</p><ul><li>过度“推迟”会浪费许多人的时间<ul><li>明明当场就能够做完的事情，很多人却用“我以后再做”将这件事推迟到后面去。</li></ul></li><li>不要“推迟讨论”<ul><li>“如果现在有必要的话，现在就联系。”</li><li>“如果现在应该决定的话，现在就决定。”</li><li>通过谷歌文档（Google Docs，一款可以在网页上共享文件的文件制作软件）等共享工具，能够实现随时随地访问自己的文件，从而增加你“立刻能做”的事情。</li></ul></li><li>当场做出决定<ul><li>一定要给“做出决定”规定期限</li></ul></li><li>活用“身边的人”<ul><li>要想解决这个问题，需要收集这些必要的资源</li></ul></li><li>即便“不知道应该怎样做才好”仍然能够采取行动的人才会成功<ul><li>将“知道的内容”和“不知道的内容”区分开</li><li>提出问题</li><li>留出时间</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/2.jpg" alt="" /><figcaption>在“不知道应该怎样做才好”的时候仍然能做的事</figcaption></figure><ul><li>增加“现在”的密度<ul><li>一次结束</li><li>当场做完</li></ul></li><li>不用邮件，所有人同时工作的话可以将工作时间缩短到原本的十分之一<ul><li>当场一次完成</li><li>微软的Office 365</li><li>苹果的iCloud</li><li>谷歌文档</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/3.jpg" alt="" /><figcaption>利用谷歌文档共享资料</figcaption></figure><ul><li>绝对不要用邮件来进行日程调整<ul><li>谷歌日历（Google Calendar）</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/4.jpg" alt="" /><figcaption>谷歌日历可以添加附件</figcaption></figure><ul><li>为了提高效率，英语必不可少<ul><li>翻译：时间和成本的二次浪费</li></ul></li><li>直接见面最有效率！</li><li>邮件是“等待文化”，即时通信是“实时文化”<ul><li>当场将问题全部解决。这种速度上的差异会非常明显地表现在工作成果上。</li></ul></li><li>限制访问是阻碍竞争的主要因素</li><li><strong>给“尽快”规定一个期限</strong><ul><li>规定期限，集中精神</li></ul></li><li>由委托人来决定优先顺序<ul><li>明确工作的优先顺序和品质要求是专业人士的基本素养。</li></ul></li><li>创意性工作也需要规定期限<ul><li>如果不规定一个期限，工作就很容易停滞不前。</li></ul></li><li>大胆地将期限提前</li><li>不要把时间浪费在选择衣服上</li><li>对“此时此刻”持有明确的目的</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/5.jpg" alt="" /><figcaption>会议前的准备列表</figcaption></figure><ul><li>事先预测、控制局面</li><li>将一周每天要做的事情区分开</li><li>选择舒适的工作环境</li><li>如果想提高工作效率，一个舒适的工作环境十分重要。</li></ul><h3 id="总结">总结</h3><ul><li>想办法“一次结束”</li><li>先将能够当场确定的事情确定下来，切实地取得进展</li><li>思考不用邮件而让所有人一次做完的方法</li><li>给所有的工作都规定期限</li><li>将精力集中于“此时此刻”</li><li>选择一个能够让自己集中精神工作的环境</li></ul><h2 id="没时间去进行逻辑分析用集体智慧来进行思考">没时间去进行逻辑分析！用集体智慧来进行思考</h2><ul><li>没有结论的分析毫无意义<ul><li>不知道自己究竟为什么要调查</li><li>也就是没有明确调查的目的</li></ul></li><li>分析的目的是什么<ul><li>创意思维需要的是灵感以及来自丰富经验的直觉</li><li>多准备一些能够激发灵感的材料</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/6.jpg" alt="" /><figcaption>线索卡的示例</figcaption></figure><ul><li>通过制造混乱让大脑活跃起来<ul><li>通过人为地制造混乱，可以使潜意识活性化，从而更容易思考出新的创意</li></ul></li><li>靠集体智慧才能产生创意思维<ul><li>集体智慧（Collective intelligence）是产生创意的秘诀</li></ul></li><li>只对竞争对手进行“分析”不可能开发出新产品<ul><li>只对竞争对手的商品进行分析无法实现差异化</li></ul></li><li>一味地模仿不可能实现差异化</li><li>企划会议不需要总结报告</li><li>总结报告式的会议无法拓展思考</li><li>需要的不是“评价”而是“成果”</li><li>独自思考不如大家一起思考</li><li>积极听取不同类型和立场的意见</li></ul><h2 id="总结-1">总结</h2><ul><li>与逻辑分析相比“灵感”更加重要</li><li>灵活利用线索卡，大家一起进行思考</li><li>将企划会议变成大家一起思考的会议</li><li>积极听取其他部门和其他领域的人的意见</li></ul><h2 id="第三章取得10倍成果的方法-以10倍的速度思考就能更快地取得成果">第三章取得10倍成果的方法 以10倍的速度思考，就能更快地取得成果</h2><ul><li>目标不是提高 <code>10%</code>，而是提高到 <code>10</code> 倍</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/7.jpg" alt="" /><figcaption>以取得10倍的成果为目标，就算没达成目标也是成功</figcaption></figure><ul><li>不打破规则就不可能取得10倍的成果</li><li>做一个敢于打破规则的人</li><li>承担风险是为了取得成功</li><li>“比去年提高10%”这一目标的错误之处</li><li>活用“20%规则”的方法</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/8.jpg" alt="" /><figcaption>应该自己做的工作与应该交给别人的工作</figcaption></figure><ul><li>为了走入新的阶段必须“让自己的工作消失”</li><li>Think like an owner</li><li>成功取得10倍成果的人的共同点<ol type="1"><li>拥有预见性<ul><li>预见机会与威胁</li><li>寻找周期、趋势以及规律</li><li>短期、中期与长期思考</li></ul></li><li>换位思考</li><li>敢于提出自己的见解</li><li>敢说真话</li><li>积极参与交流</li><li>倾听自己内心的声音</li><li>打破常规</li><li>不害怕失败</li><li>勤于思考、保持怀疑</li><li>改变视角<ul><li>整体视角</li><li>局部视角</li><li>反面视角</li><li>未来视角</li><li>顾客视角</li><li>竞争对手视角</li><li>特殊视角（一般情况下、更深层次的情况下、反常的情况下）</li></ul></li></ol></li></ul><h3 id="总结-2">总结</h3><ul><li>思考如何取得10倍的成果</li><li>为了取得10倍的成果必须要打破规则</li><li>为了进入下一个阶段，必须“让自己的工作消失”</li><li>像公司的所有者那样思考</li></ul><h2 id="创建提高工作效率的人际关系的方法-能够让每个人都发挥出全部实力的心理安全究竟是什么">创建提高工作效率的人际关系的方法 能够让每个人都发挥出全部实力的“心理安全”究竟是什么</h2><ul><li>用“实物”说话</li></ul><blockquote><p>与对程序员说“我想在这里增加一个这样的功能……”相比，将拥有这个功能的程序实际运行起来给对方看更加便于理解。</p></blockquote><ul><li>让自己平易近人</li><li>告诉部下“上司的使用方法”<ul><li>自己能解决的事情请自己解决。</li><li>不要只带着问题来找我，同时还要带来解决办法。</li><li>遇到无法解决的问题，请告诉我你需要什么（比如需要建议、决定，还是需要我出面动用权限）。</li></ul></li><li>如何创建心理安全程度较高的环境</li><li>创建“反馈渠道”</li><li>绝对不能完全否定对方的意见</li><li>提高工作效率的不是流程而是“人”</li><li>你的人际圈将改变你的人生</li><li>发现最有能力的人</li><li>改变人际关系的优先顺序</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/11.jpg" alt="" /><figcaption>人际关系的优先顺序</figcaption></figure><ul><li>与关键人物建立联系</li></ul><h3 id="总结-3">总结</h3><ul><li>用“实物”说话可以使工作更有效率</li><li>取消多余的会议</li><li>与部下的交流每周一次就够了</li><li>在工作之外也建立起人际关系，可以使工作更有效率</li><li>优先与“新结识的人”“不断变化的人”“高水平的人”交流</li></ul><h2 id="迅速学习必要技能的方法-去学校学习不如向同事学习">迅速学习必要技能的方法 去学校学习不如向同事学习</h2><ul><li>应该学习的不是知识而是经验</li><li>“检索时代”学习的基本原则</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/12.jpg" alt="" /><figcaption>新的“学习循环”</figcaption></figure><ul><li>与学习相关的“询问”规则<ul><li>向别人询问的时候，一定要提出自己的假设</li></ul></li><li>向擅长工作的人询问</li><li>在职场中“学习”</li><li>利用反馈获得自己意想不到的情报</li><li>工作前进行“前馈”</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/13.jpg" alt="" /><figcaption>反馈与前馈</figcaption></figure><ul><li>提问 4 要素<ol type="1"><li>具体来说</li><li>要在什么地方</li><li>改变什么</li><li>怎样做，才能让工作比较顺利</li></ol></li><li>实践比研修更容易获得自信</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/14.jpg" alt="" /><figcaption>NLP（神经语言程序学）行动金字塔</figcaption></figure><ul><li>通过交流学习</li><li>多参加交流</li><li>不要排斥不同领域的人</li><li>孤身一人不如齐心协力</li><li>“for”与“with”</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/15.jpg" alt="" /><figcaption>“for”与“with”</figcaption></figure><ul><li>为什么要学习<ul><li>拥有的“选项”越多，在竞争中生存下来的可能性就越大</li><li>不一定是最强大，但一定是最有适应性</li></ul></li><li>思维模式<ul><li><strong>成长型思维</strong></li><li>学习型思维</li><li>回避型思维</li><li>证明型思维。</li></ul></li><li>不断改变，坚持学习</li></ul><h3 id="总结-4">总结</h3><ul><li>学习=检索+询问专业人士·询问他人·询问同事</li><li>只有反馈远远不够，还要灵活利用“前馈”</li><li>预先建立一个能够轻松询问的交流关系</li><li>不断改变，坚持学习</li></ul><h2 id="谷歌的轻松工作方法-简化心灵">谷歌的轻松工作方法 简化心灵</h2><ul><li>留出关闭电脑的时间</li><li>将同时进行多项工作的时间与专心致志的时间区分开</li><li>同时进行多项工作的技<ul><li>冲刺工作法</li></ul></li><li>应对感情波动<ul><li><strong>你发现自己现在正在生气，那就将这个情绪状态说出来</strong></li></ul></li><li>睡午觉、吃零食、放松是自己的责任</li><li>用性善论来管理企业</li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/16.jpg" alt="" /><figcaption>日本人拥有“工作价值”的比率较低</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/17.jpg" alt="" /><figcaption>new work rules（新的工作要求）</figcaption></figure><h3 id="总结-5">总结</h3><ul><li>偶尔关闭电脑</li><li>一分钟的冥想就能够改变注意力</li><li>在不同的时间段集中精力做一件事</li><li>不要尝试消灭感情，要保持中庸</li><li>休息也是自己的责任</li></ul><h2 id="破坏自己工作的人将创建下一个时代">破坏自己工作的人，将创建下一个时代</h2><ul><li>不让AI抢走自己的工作</li><li>分析时代的发展变化</li><li>如何掌握最新的科技</li><li>积极尝试热门应用程序</li><li>就算对技术细节不了解，也要跟上趋势<ul><li>自动化</li><li>就算自己做不到，也可以去找相应领域的工程师或者程序员来帮忙</li></ul></li></ul><figure><img src="https://2020.iosdevlog.com/2020/03/02/9787540492908/18.jpg" alt="" /><figcaption>就连专家也无法准确预测手机市场的发展趋势</figcaption></figure><ul><li>不要害怕变化</li><li>你是否成了习惯的奴隶<ul><li>人一旦习惯了每天的行动模式，就会不再思考自己为什么工作以及怎样做才能让工作变得更有效率。</li><li>而一旦停止思考，就不会有新的发现。没有新的发现，当然也不会出现改变。</li><li>利用IT实现自动化，找别人帮忙，将工作分解成许多小任务分派下去，利用外部资源。</li></ul></li><li>工作不能“和昨天一样”</li><li>现在的世界绝对不是理所当然的</li></ul><h3 id="总结-6">总结</h3><ul><li>思考如何用IT代替自己工作</li><li>站在革新的一侧，不能袖手旁观</li><li>就算对技术细节不了解，也要跟上趋势</li><li>工作不能“和昨天一样”</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/02/9787540492908/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;Google工作法&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：Google工作法&lt;br /&gt;
作者：[波]彼得·费利克斯·格日瓦奇&lt;br /&gt;
译者：朱悦玮&lt;br /&gt;
出版社：湖南文艺出版社&lt;br /&gt;
出版时间：2019-08&lt;br /&gt;
ISBN：9787540492908&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;明明很努力地工作，但工作总是做不完。&lt;br /&gt;
明明很努力地工作，但工作总是不顺利。&lt;br /&gt;
而且，这样的状态还一直在持续...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;——这本书将彻底解决你的烦恼。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Google" scheme="https://2020.iosdevlog.com/tags/Google/"/>
    
  </entry>
  
  <entry>
    <title>Manim 分析</title>
    <link href="https://2020.iosdevlog.com/2020/03/01/manim-turorial/"/>
    <id>https://2020.iosdevlog.com/2020/03/01/manim-turorial/</id>
    <published>2020-03-01T07:19:30.000Z</published>
    <updated>2020-03-02T12:18:15.401Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/0.png" alt="" /><figcaption>manim</figcaption></figure><p><a href="https://github.com/3b1b/manim" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim</a></p><p>Installation 安装</p><p>Manim runs on <code>Python 3.7</code>. You can install it from PyPI via pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install manimlib</span><br></pre></td></tr></table></figure><p>System requirements are cairo, ffmpeg, sox, latex (optional, if you want to use LaTeX).</p><p>You can now use it via the manim command. For example:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">manim my_project.py MyScene</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="manim">Manim</h2><p>manim 库的大部分功能都分解为功能不同的文件夹。用于编写动画脚本的主要工具是 scene, mobject, camera, 和 animation 文件夹，其中包含它们各自的类。在这四个文件夹中，mobject 文件夹是用户大多数时间与之交互的文件夹。它包含动画中使用的所有几何图形，文本和图形的类。</p><p>程序的实际结构很容易掌握。通过在 python 文件中声明 Scene 类的子类来创建动画或场景。动画的实际代码进入一种称为 “construct 构造” 的方法。这是manim场景的关键字。每当 Scene 类中的对象被初始化时，它都会调用 <code>self.setup()</code> 和 <code>self.construct()</code> 方法。如果未实现后者，则会出现错误。但是，前者是可选的，但在同时处理多个场景时很有用。</p><p>播放和保存动画是从命令行进行的。上面显示了播放动画的基本命令，并将python文件的名称和场景子类传递给 <code>manim.py</code>（实际上是 <code>manimlib/__init__.py</code>）。<code>-pm</code> 标志将预览中等（720p）品质的动画并将其保存在媒体文件夹中。在 <code>config.py</code> 中可以找到更多标志类型，例如裁剪某些帧的标志或导出 <code>.gif</code> 动画的标志。</p><p>当命令行调用其文件时，也会在场景声明之外执行任何 python 代码。这意味着可以删除不明确依赖 <code>manim</code> 功能的代码 <code>construct(self)</code>。这很有用，因为它可以防止结构定义混乱。</p><p>manim 中的大多数类都带有 <code>CONFIG</code> 与之关联的字典。它始终出现在类定义的顶部。这是 <code>Camera</code> 类的 CONFIG：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Camera</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">  CONFIG = &#123;</span><br><span class="line">    <span class="string">"background_image"</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">"pixel_height"</span>: DEFAULT_PIXEL_HEIGHT,</span><br><span class="line">    <span class="string">"pixel_width"</span>: DEFAULT_PIXEL_WIDTH,</span><br><span class="line">    <span class="string">"frame_rate"</span>: DEFAULT_FRAME_RATE,</span><br><span class="line">    <span class="string">"frame_height"</span>: FRAME_HEIGHT,</span><br><span class="line">    <span class="string">"frame_width"</span>: FRAME_WIDTH,</span><br><span class="line">    <span class="string">"frame_center"</span>: ORIGIN,</span><br><span class="line">    <span class="string">"background_color"</span>: BLACK,</span><br><span class="line">    <span class="string">"background_opacity"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">"max_allowable_norm"</span>: FRAME_WIDTH,</span><br><span class="line">    <span class="string">"image_mode"</span>: <span class="string">"RGBA"</span>,</span><br><span class="line">    <span class="string">"n_channels"</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">"pixel_array_dtype"</span>: <span class="string">'uint8'</span>,</span><br><span class="line">    <span class="string">"z_buff_func"</span>: <span class="keyword">lambda</span> m: np.round(m.get_center()[<span class="number">2</span>], <span class="number">2</span>),</span><br><span class="line">    <span class="string">"cairo_line_width_multiple"</span>: <span class="number">0.01</span>,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>初始化对象时，CONFIG 的条目用作要通过 <code>__init__</code> 传递的关键字参数。这对于创建场景非常方便，因为在命令行中将几个关键字参数传递给感兴趣的场景很麻烦。通常，这也是用户与 <code>Camera</code> 类进行交互的地方，因为 <code>camera</code> CONFIG是场景CONFIG中的一个条目。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Scene(Container):</span><br><span class="line"></span><br><span class="line">  CONFIG &#x3D; &#123;</span><br><span class="line">    &quot;camera_class&quot;: Camera,</span><br><span class="line">    &quot;camera_config&quot;: &#123;&#125;,</span><br><span class="line">    &quot;file_writer_config&quot;: &#123;&#125;,</span><br><span class="line">    &quot;skip_animations&quot;: False,</span><br><span class="line">    &quot;always_update_mobjects&quot;: False,</span><br><span class="line">    &quot;random_seed&quot;: 0,</span><br><span class="line">    &quot;start_at_animation_number&quot;: None,</span><br><span class="line">    &quot;end_at_animation_number&quot;: None,</span><br><span class="line">    &quot;leave_progress_bars&quot;: False,</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>所有大写变量都来自文件 <code>constants.py</code>，该文件可用作参考，因为许多类和方法都将这些常量用作默认参数。CONFIG 字典尊重类和子类之间的继承，因此 manim 中的许多类具有比其类定义中更大的 CONFIG 参数。这对于大量使用子类化的 mobjects 特别重要。例如，这是的子类结构 <code>mobject/geometry.py</code>。</p><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/1.png" alt="" /><figcaption>manim</figcaption></figure><h2 id="animationswithmanim1">AnimationsWithManim<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></h2><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/2.png" alt="" /><figcaption>Manim</figcaption></figure><p><span class="math display">\[Manim = Python3（核心）+ latex（文字排版） + cairo（生成图形）+ ffmpeg（转码视频）+ sox（音频处理）\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/3.png" alt="" /><figcaption>优点</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/4.png" alt="" /><figcaption>大纲</figcaption></figure><p>具体安装可参考：<a href="https://github.com/Elteoremadebeethoven/AnimationsWithManim/blob/master/English/0_instalation/macOS/INSTRUCTIONS.md" target="_blank" rel="noopener">Installation on MacOS</a></p><h3 id="mactex2">MacTeX<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></h3><figure><img src="https://2020.iosdevlog.com/2020/03/01/manim-turorial/5.png" alt="" /><figcaption>MacTeX</figcaption></figure><p>下载 <code>MacTeX.pkg</code> 安装</p><h3 id="homebrew3">Homebrew<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/ruby -e <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></span><br></pre></td></tr></table></figure><h3 id="python34">Python3<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></h3><p>可以直接去官网官下载最新版的 <code>Python3</code></p><p>或者用 <code>brew</code> 安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install python3</span><br></pre></td></tr></table></figure><p><code>python3</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Python 3.7.4 (default, Sep 28 2019, 16:39:19) </span><br><span class="line">[Clang 11.0.0 (clang-1100.0.33.8)] on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><h3 id="下载cairoffmpegsoxlatex和其他的包">下载cairo，ffmpeg，sox，latex和其他的包</h3><p>返回终端的根目录（如果你之前进入了python3，输入exit() 退出，或者重新打开终端），终端输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">brew install cairo</span><br><span class="line">brew install ffmpeg</span><br><span class="line">brew install sox</span><br></pre></td></tr></table></figure><h3 id="manim5">Manim<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></h3><p>Manim is an animation engine for explanatory math videos. It's used to create precise animations programmatically, as seen in the videos at 3Blue1Brown.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/3b1b/manim.git</span><br></pre></td></tr></table></figure><p>Install list requirements.txt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -r requirements.txt</span><br><span class="line">python3 -m pip install pyreadline</span><br><span class="line">python3 -m pip install pydub</span><br></pre></td></tr></table></figure><p>Run Manim</p><p>With the terminal in manim-master directory run this:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m manim example_scenes.py WriteStuff -pl</span><br><span class="line">python3 -m manim example_scenes.py SquareToCircle -pl</span><br></pre></td></tr></table></figure><p>The <code>-p</code> flag in the command above is for <strong>previewing</strong>, meaning the video file will automatically open when it is done rendering.</p><p>The <code>-l</code> flag is for a faster rendering at a <strong>lower quality</strong>.</p><p>Some other useful flags include:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-s to skip to the end and just show the final frame.</span><br><span class="line">-n &lt;number&gt; to skip ahead to the n<span class="string">'th animation of a scene.</span></span><br><span class="line"><span class="string">-f to show the file in finder (for OSX).</span></span><br></pre></td></tr></table></figure><p>Anaconda Install</p><p>Install sox and latex as above.<br />Create a conda environment using</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure><p>Using virtualenv and virtualenvwrapper</p><p>After installing virtualenv and virtualenvwrapper</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip3 install virtualenvwrapper</span><br><span class="line">VIRTUALENVWRAPPER_PYTHON=/usr/<span class="built_in">local</span>/bin/python3</span><br><span class="line"><span class="built_in">source</span> /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">virtualenvwrapper.sh</span><br></pre></td></tr></table></figure><p>mk_manim</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv -r requirements.txt mk_manim</span><br><span class="line">(mk_manim) $ python -m pip install pycairo</span><br><span class="line">(mk_manim) $ python3 -m manim example_scenes.py SquareToCircle -pl</span><br></pre></td></tr></table></figure><h2 id="error">Error</h2><p>Manim ModuleNotFoundError: No module named 'cairo'<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install pycairo</span><br></pre></td></tr></table></figure><h2 id="参考">参考</h2><section class="footnotes" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>AnimationsWithManim: <a href="https://github.com/Elteoremadebeethoven/AnimationsWithManim" target="_blank" rel="noopener" class="uri">https://github.com/Elteoremadebeethoven/AnimationsWithManim</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn2" role="doc-endnote"><p>MacTex: <a href="https://www.tug.org/mactex/mactex-download.html" target="_blank" rel="noopener" class="uri">https://www.tug.org/mactex/mactex-download.html</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn3" role="doc-endnote"><p>Homebrew: <a href="https://brew.sh" target="_blank" rel="noopener" class="uri">https://brew.sh</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn4" role="doc-endnote"><p>Python: <a href="https://www.python.org/downloads/" target="_blank" rel="noopener" class="uri">https://www.python.org/downloads/</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn5" role="doc-endnote"><p>Manim: <a href="https://github.com/3b1b/manim" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn6" role="doc-endnote"><p><a href="https://github.com/3b1b/manim/issues/392" target="_blank" rel="noopener" class="uri">https://github.com/3b1b/manim/issues/392</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/03/01/manim-turorial/0.png&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;manim&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/3b1b/manim&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;uri&quot;&gt;https://github.com/3b1b/manim&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Installation 安装&lt;/p&gt;
&lt;p&gt;Manim runs on &lt;code&gt;Python 3.7&lt;/code&gt;. You can install it from PyPI via pip:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip3 install manimlib&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;System requirements are cairo, ffmpeg, sox, latex (optional, if you want to use LaTeX).&lt;/p&gt;
&lt;p&gt;You can now use it via the manim command. For example:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;manim my_project.py MyScene&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="math" scheme="https://2020.iosdevlog.com/categories/math/"/>
    
    
      <category term="manim" scheme="https://2020.iosdevlog.com/tags/manim/"/>
    
  </entry>
  
  <entry>
    <title>《Python神经网络编程》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/29/9787115474810/"/>
    <id>https://2020.iosdevlog.com/2020/02/29/9787115474810/</id>
    <published>2020-02-29T14:47:41.000Z</published>
    <updated>2020-03-02T12:22:46.494Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/1.jpg" alt="" /><figcaption>《Python神经网络编程》</figcaption></figure><p>书名：Python神经网络编程<br />作者：[英]塔里克·拉希德（Tariq Rashid）<br />译者：林赐<br />出版社：人民邮电出版社<br />出版时间：2018-04<br />ISBN：9787115474810</p><p><strong>参照本书，自己可以动手写一个简单的神经网络，还不快来看看。</strong></p><a id="more"></a><h2 id="内容提要">内容提要</h2><p>神经网络是一种模拟人脑的神经网络，以期能够实现类人工智能的机器学习技术。</p><p>本书揭示神经网络背后的概念，并介绍如何通过Python实现神经网络。</p><p>全书分为3章和两个附录。</p><ol type="1"><li>第1章介绍了神经网络中所用到的数学思想。<ul><li>我们将如清风拂面般，一览在简单的神经网络中所用的数学思想。我们有意不介绍任何计算机编程知识，以避免喧宾夺主地干扰了本书的核心思想。</li></ul></li><li>第2章 介绍使用Python实现神经网络，识别手写数字，并测试神经网络的性能。<ul><li>我们将学习足以实现自己的神经网络的Python知识。我们将训练神经网络，识别手写数字，并且会测试神经网络的性能。</li></ul></li><li>第3章 带领读者进一步了解简单的神经网络，观察已受训练的神经网络内部，尝试进一步改善神经网络的性能，并加深对相关知识的理解。<ul><li>我们将进一步了解简单的神经网络，这超出了了解基本神经网络知识的范畴，但是我们这样做只是为了获得一些乐趣。我们将尝试一些想法，进一步改善神经网络的性能，我们将观察已受训练的神经网络内部，看看我们是否理解神经网络所学习到的知识，是否理解神经网络是如何做出决定进行回答的。</li></ul></li></ol><p>附录分别介绍了所需的微积分知识和树莓派知识。</p><h3 id="本书适合">本书适合</h3><ol type="1"><li>想要从事神经网络研究和探索的读者学习参考</li><li>对人工智能、机器学习和深度学习等相关领域感兴趣</li></ol><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/2.jpg" alt="" /><figcaption>国际象棋机器Turkey</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/3.jpg" alt="" /><figcaption>MNIST</figcaption></figure><h2 id="第1章-神经网络如何工作">第1章 神经网络如何工作</h2><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/4.jpg" alt="" /><figcaption>处理图像</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/4.jpg" alt="" /><figcaption>对比</figcaption></figure><blockquote><p>有些任务，对传统的计算机而言很容易，对人类而言却很难。例如，对数百万个数字进行乘法运算。</p><p>另一方面，有些任务对传统的计算机而言很难，对人类而言却很容易。例如，从一群人的照片中识别出面孔。</p></blockquote><h3 id="一台简单的预测机">一台简单的预测机</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/6.jpg" alt="" /><figcaption>机器</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/7.jpg" alt="" /><figcaption>计算</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/8.jpg" alt="" /><figcaption>一组加法</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/9.jpg" alt="" /><figcaption>转化</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/10.jpg" alt="" /><figcaption>真实情况</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/11.jpg" alt="" /><figcaption>常数C</figcaption></figure><p><span class="math display">\[误差值=真实值-计算值=62.137-50=12.137\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/12.jpg" alt="" /><figcaption>误差值</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/13.jpg" alt="" /><figcaption>误差值变小</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/14.jpg" alt="" /><figcaption>超调</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/15.jpg" alt="" /><figcaption>微调C</figcaption></figure><blockquote><p>所有有用的计算机系统都有一个输入和一个输出，并在输入和输出之间进行某种类型的计算。神经网络也是如此。</p><p>当我们不能精确知道一些事情如何运作时，我们可以尝试使用模型来估计其运作方式，在模型中，包括了我们可以调整的参数。</p><p>如果我们不知道如何将千米转换为英里，那么我们可以使用线性函数作为模型，并使用可调节的梯度值作为参数。改进这些模型的一种好方法是，基于模型和已知真实示例之间的比较，得到模型偏移的误差值，调整参数。</p></blockquote><h3 id="分类器与预测器并无太大差别">分类器与预测器并无太大差别</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/16.jpg" alt="" /><figcaption>小虫子的宽度和长度</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/17.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/18.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/19.jpg" alt="" /><figcaption>分界线</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/20.jpg" alt="" /><figcaption>未知小虫</figcaption></figure><h3 id="训练简单的分类器">训练简单的分类器</h3><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/21.jpg" alt="" /><figcaption>实例</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/22.jpg" alt="" /><figcaption>可视化数据</figcaption></figure><p><span class="math display">\[y=A x\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/23.jpg" alt="" /><figcaption>斜率</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/24.jpg" alt="" /><figcaption>误差值</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/25.jpg" alt="" /><figcaption>ΔA)</figcaption></figure><p><span class="math display">\[\Delta \mathrm{A}=\mathrm{L}(\mathrm{E} / x)\]</span></p><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/26.jpg" alt="" /><figcaption>最终直线</figcaption></figure><blockquote><p>我们使用简单的数学，理解了线性分类器输出误差值和可调节斜率参数之间的关系。也就是说，我们知道了在何种程度上调整斜率，可以消除输出误差值。</p><p>使用朴素的调整方法会出现一个问题，即改进后的模型只与最后一次训练样本最匹配，“有效地”忽略了所有以前的训练样本。解决这个问题的一种好方法是使用学习率，调节改进速率，这样单一的训练样本就不能主导整个学习过程。</p><p>来自真实世界的训练样本可能充满噪声或包含错误。适度更新有助于限制这些错误样本的影响。</p></blockquote><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/27.jpg" alt="" /><figcaption>27</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/28.jpg" alt="" /><figcaption>28</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/29.jpg" alt="" /><figcaption>29</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/30.jpg" alt="" /><figcaption>30</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/31.jpg" alt="" /><figcaption>31</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/32.jpg" alt="" /><figcaption>32</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/33.jpg" alt="" /><figcaption>33</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/34.jpg" alt="" /><figcaption>34</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/35.jpg" alt="" /><figcaption>35</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/36.jpg" alt="" /><figcaption>36</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/37.jpg" alt="" /><figcaption>37</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/38.jpg" alt="" /><figcaption>38</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/39.jpg" alt="" /><figcaption>39</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/40.jpg" alt="" /><figcaption>40</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/41.jpg" alt="" /><figcaption>41</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/42.jpg" alt="" /><figcaption>42</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/43.jpg" alt="" /><figcaption>43</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/44.jpg" alt="" /><figcaption>44</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/45.jpg" alt="" /><figcaption>45</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/46.jpg" alt="" /><figcaption>46</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/47.jpg" alt="" /><figcaption>47</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/48.jpg" alt="" /><figcaption>48</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/49.jpg" alt="" /><figcaption>49</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/50.jpg" alt="" /><figcaption>50</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/51.jpg" alt="" /><figcaption>51</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/52.jpg" alt="" /><figcaption>52</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/53.jpg" alt="" /><figcaption>53</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/54.jpg" alt="" /><figcaption>54</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/55.jpg" alt="" /><figcaption>55</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/56.jpg" alt="" /><figcaption>56</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/57.jpg" alt="" /><figcaption>57</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/58.jpg" alt="" /><figcaption>58</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/59.jpg" alt="" /><figcaption>59</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/60.jpg" alt="" /><figcaption>60</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/61.jpg" alt="" /><figcaption>61</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/62.jpg" alt="" /><figcaption>62</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/63.jpg" alt="" /><figcaption>63</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/64.jpg" alt="" /><figcaption>64</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/65.jpg" alt="" /><figcaption>65</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/66.jpg" alt="" /><figcaption>66</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/67.jpg" alt="" /><figcaption>67</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/68.jpg" alt="" /><figcaption>68</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/69.jpg" alt="" /><figcaption>69</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/70.jpg" alt="" /><figcaption>70</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/71.jpg" alt="" /><figcaption>71</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/72.jpg" alt="" /><figcaption>72</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/73.jpg" alt="" /><figcaption>73</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/74.jpg" alt="" /><figcaption>74</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/75.jpg" alt="" /><figcaption>75</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/76.jpg" alt="" /><figcaption>76</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/77.jpg" alt="" /><figcaption>77</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/78.jpg" alt="" /><figcaption>78</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/79.jpg" alt="" /><figcaption>79</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/80.jpg" alt="" /><figcaption>80</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/81.jpg" alt="" /><figcaption>81</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/82.jpg" alt="" /><figcaption>82</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/83.jpg" alt="" /><figcaption>83</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/84.jpg" alt="" /><figcaption>84</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/85.jpg" alt="" /><figcaption>85</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/86.jpg" alt="" /><figcaption>86</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/87.jpg" alt="" /><figcaption>87</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/88.jpg" alt="" /><figcaption>88</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/89.png" alt="" /><figcaption>89</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/90.jpg" alt="" /><figcaption>90</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/91.jpg" alt="" /><figcaption>91</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/92.jpg" alt="" /><figcaption>92</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/93.jpg" alt="" /><figcaption>93</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/94.jpg" alt="" /><figcaption>94</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/95.jpg" alt="" /><figcaption>95</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/96.jpg" alt="" /><figcaption>96</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/97.jpg" alt="" /><figcaption>97</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/98.jpg" alt="" /><figcaption>98</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/99.jpg" alt="" /><figcaption>99</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/100.jpg" alt="" /><figcaption>100</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/101.jpg" alt="" /><figcaption>101</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/102.jpg" alt="" /><figcaption>102</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/103.jpg" alt="" /><figcaption>103</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/104.jpg" alt="" /><figcaption>104</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/105.jpg" alt="" /><figcaption>105</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/106.jpg" alt="" /><figcaption>106</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/107.jpg" alt="" /><figcaption>107</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/108.jpg" alt="" /><figcaption>108</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/109.jpg" alt="" /><figcaption>109</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/110.jpg" alt="" /><figcaption>110</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/111.jpg" alt="" /><figcaption>111</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/112.jpg" alt="" /><figcaption>112</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/113.jpg" alt="" /><figcaption>113</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/114.jpg" alt="" /><figcaption>114</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/115.jpg" alt="" /><figcaption>115</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/116.jpg" alt="" /><figcaption>116</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/117.jpg" alt="" /><figcaption>117</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/118.png" alt="" /><figcaption>118</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/119.png" alt="" /><figcaption>119</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/120.png" alt="" /><figcaption>120</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/121.png" alt="" /><figcaption>121</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/122.jpg" alt="" /><figcaption>122</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/123.jpg" alt="" /><figcaption>123</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/124.jpg" alt="" /><figcaption>124</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/125.jpg" alt="" /><figcaption>125</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/126.jpg" alt="" /><figcaption>126</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/29/9787115474810/127.jpg" alt="" /><figcaption>127</figcaption></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/29/9787115474810/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《Python神经网络编程》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：Python神经网络编程&lt;br /&gt;
作者：[英]塔里克·拉希德（Tariq Rashid）&lt;br /&gt;
译者：林赐&lt;br /&gt;
出版社：人民邮电出版社&lt;br /&gt;
出版时间：2018-04&lt;br /&gt;
ISBN：9787115474810&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参照本书，自己可以动手写一个简单的神经网络，还不快来看看。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="NN" scheme="https://2020.iosdevlog.com/tags/NN/"/>
    
      <category term="Python" scheme="https://2020.iosdevlog.com/tags/Python/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>《神经网络与深度学习》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/28/9787121288692/"/>
    <id>https://2020.iosdevlog.com/2020/02/28/9787121288692/</id>
    <published>2020-02-28T15:02:30.000Z</published>
    <updated>2020-03-02T12:22:46.500Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/1.jpg" alt="" /><figcaption>《神经网络与深度学习》</figcaption></figure><p>书名：神经网络与深度学习<br />作者：吴岸城<br />出版社：电子工业出版社<br />出版时间：2016-06<br />ISBN：9787121288692</p><p>本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。</p><p>对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。</p><a id="more"></a><h2 id="介绍">介绍</h2><p>第0章，介绍机器学习、神经网络的历史，好让大家有基本的了解。<br />第1章，解释大脑的运作结构和如何利用仿生学产生逻辑上的神经元和神经网络。<br />第2章，我们用仿生学的知识试着构造一个神经网络（感知机）并使用它做些事情，解释了XOR问题。在2.6节给出一些例子，让我们能更好地了解神经网络是如何分类学习和预测的。<br />第3章，介绍深度学习的基本概念，深度学习和神经网络的联系。<br />第4章，介绍深度学习的常用方法。<br />第5章，介绍AlphaGo。<br />第6章，两个重要概念，迁移学习和概率图模型PGM。<br />第7章，给出了一些经验以加快大家学习和研究的效率。</p><h2 id="术语">术语</h2><ol type="1"><li><strong>图灵</strong>：全名艾伦·麦席森·图灵，英国人，因性倾向遭到当时的英国政府迫害，职业生涯尽毁。他可以说是人工智能之父，笔者十分佩服其才智。</li><li><strong>决策树</strong>：是一个预测模型；它代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，每个叶节点对应从根节点到该叶节点所经历的路径所表示的对象的值。</li><li><strong>条件概率</strong>：就是事件A在另外一个事件B已经发生的条件下的发生概率。条件概率表示为P（A|B），读作“在B条件下A的概率”。</li><li><strong>树突、轴突</strong>：神经元的输入和输出部分。5. AND/XOR/OR：数学逻辑运算。</li><li><strong>人工神经元</strong>：是一种模仿生物神经元的结构和功能的数学模型或计算模型。</li><li><strong>感知机</strong>：它被视为是一种最简单的前馈神经网络，是一种二元线性分类器。</li><li><strong>前馈神经网络</strong>：最简单的人工神经网络类型。在它的内部，参数从输入层向输出层单向传播。</li><li><strong>特征</strong>：本书中指将现实生活中的事物的部分特点提取并抽象出一种数学或物理模型。</li><li><strong>特征粒度</strong>：提取特征的维度。</li><li><strong>浅层学习/深度学习</strong>：相对概念，深度学习相对浅层学习抽象层级要多。12. BP算法（反向传播算法）：是一种监督学习算法，常被用来训练多层感知机，利用反向传播原理修正权值。</li><li><strong>自动编码器（AE）</strong>：自动编码器就是一个运用了反向传播进行无监督学习的神经网络，学习的目的是为了让输出值和输入值相等。14. RBM（限制波兹曼机）：是一种可通过输入数据集学习概率分布的随机生成神经网络。</li><li><strong>概率模型</strong>：是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系。</li><li><strong>能量模型（EBM）</strong>：基于能量的模型，把我们关心的变量的各种组合和一个标量能量联系在一起。我们训练模型的过程就是不断改变标量能量的过程。</li><li><strong>DBN（深度信度网络）</strong>：通过自底向上组合多个RBM可以构建一个DBN，利用非监督贪心逐层训练算法，解决深层结构相关的优化问题。18. CNN（卷积神经网络/ConvNets）：是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</li><li><strong>概率图</strong>：是一种使用图来表达随机变量之间条件独立性的概率模型。</li><li><strong>贝叶斯定理</strong>：事件A在事件B（发生）的条件下的概率。</li><li><strong>SVM（支持向量机）</strong>：监督学习方法，属于一般化线性分类器。这种分类器的特点是它们能够同时最小化经验误差与最大化几何边缘区，因此支持向量机也被称为最大边缘区分类器。</li><li><strong>K-Means</strong>：把n个点（可以是样本的一次观察或一个实例）划分到k个聚类中，使得每个点都属于离它最近的均值（此即聚类中心）对应的聚类。</li><li><strong>Java</strong>：一种面向对象的高级语言。</li><li><strong>Python</strong>：是一种解释型的计算机程序语言，具有近20年的发展历史。它包含了一组功能完备的标准库，能够轻松完成很多常见的任务。</li><li><strong>MATLAB</strong>：是一款由美国TheMathWorks公司出品的商业数学软件。MATLAB是一种用于算法开发、数据可视化、数据分析及数值计算的高级技术计算语言和交互式环境。</li><li><strong>C++</strong>：是一种广泛使用的计算机程序设计语言。</li><li><strong>并行计算</strong>：一般是指许多指令得以同时进行的计算模式。</li><li><strong>NASA</strong>：国家航空航天局（英语：National Aeronautics and SpaceAdministration，缩写为NASA），是美国联邦政府的一个行政机构，负责制定、实施美国的民用太空计划，并开展航空科学暨太空科学的研究。</li></ol><h2 id="写在前面神经网络的历史">0 写在前面：神经网络的历史</h2><p>神经网络，是机器学习的一个分支，学名应该叫人工神经网络，与之相对应的是生物神经网络（Biological Neural Networks, BNN），我们将模拟生物神经网络的数学模型统称为人工神经网络模型，简称人工神经网络或者神经网络。</p><p><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/2.jpg" alt="阿兰·麦席森·图灵" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/3.jpg" alt="约翰·麦卡锡" /></p><p>图灵测试（Turing test，又译图灵试验）是图灵提出的一个关于机器能否思考的著名判断原则。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/4.jpg" alt="" /><figcaption>麦卡洛可</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/5.jpg" alt="" /><figcaption>皮茨</figcaption></figure><p>麦卡洛可: 神经科学</p><p>+</p><p>皮茨: 数学</p><p>=</p><p>《神经活动中思想内在性的逻辑演算》（A LogicalCalculus of Ideas Immanent in Nervous Activity）</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/6.jpg" alt="" /><figcaption>诺伯特·维纳</figcaption></figure><p>诺伯特·维纳：控制论</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/7.jpg" alt="" /><figcaption>迈克尔·阿比卜</figcaption></figure><p>迈克尔·阿比卜：创立麻省理工学院的计算机</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/8.jpg" alt="" /><figcaption>弗兰克·罗森布拉特</figcaption></figure><blockquote><p>“感知器最终将能够学习，做出决策和翻译语言”</p></blockquote><p>弗兰克·罗森布拉特：“感知机”（Perceptron）的神经网络模型</p><p>《神经动力学原理：感知机和大脑机制的理论》（Principles of Neurodynamics: Perceptrons and the Theory ofBrainMechanisms）</p><p>保罗·沃波斯（Paul Werbos）：“反向传播算法”（Backpropagation Algorithm，简称BP算法）</p><p>是一种监督学习算法，常被用来训练多层感知机。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/9.jpg" alt="" /><figcaption>霍普菲尔德</figcaption></figure><p>霍普菲尔德：递归神经网络</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/10.jpg" alt="" /><figcaption>鲁姆哈特（David Rumelhart）</figcaption></figure><p>鲁姆哈特（David Rumelhart）：完整地提出了BP算法，完整的推导。</p><figure><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/11.jpg" alt="" /><figcaption>杰弗里·辛顿（Geoffrey Hinton）</figcaption></figure><p>杰弗里·辛顿（Geoffrey Hinton）：反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者</p><p>吴恩达：识别“猫”，“深度学习”领域的经典案例</p><h2 id="神经网络是个什么东西">1 神经网络是个什么东西</h2><p><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/12.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/13.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/14.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/15.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/16.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/17.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/18.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/19.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/20.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/21.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/22.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/23.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/24.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/25.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/26.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/27.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/28.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/29.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/30.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/31.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/32.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/33.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/34.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/35.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/36.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/37.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/38.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/39.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/40.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/41.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/42.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/43.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/44.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/45.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/46.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/47.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/48.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/49.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/50.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/51.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/52.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/53.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/54.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/55.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/56.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/57.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/58.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/59.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/60.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/61.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/62.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/63.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/64.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/65.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/66.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/67.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/68.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/69.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/70.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/71.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/72.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/73.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/74.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/75.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/76.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/77.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/78.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/79.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/80.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/81.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/82.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/83.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/84.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/85.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/86.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/87.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/88.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/89.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/90.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/91.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/92.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/93.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/94.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/95.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/96.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/97.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/98.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/99.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/100.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/101.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/102.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/103.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/104.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/105.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/106.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/107.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/108.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/109.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/110.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/111.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/112.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/113.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/114.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/115.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/116.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/117.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/118.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/119.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/120.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/121.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/122.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/123.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/124.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/125.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/126.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/127.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/128.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/129.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/130.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/131.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/132.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/133.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/134.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/135.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/136.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/137.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/138.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/139.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/140.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/141.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/142.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/143.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/144.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/145.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/146.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/147.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/148.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/149.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/150.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/151.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/152.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/153.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/154.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/155.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/156.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/157.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/158.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/159.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/160.jpg" /><br /><img src="https://2020.iosdevlog.com/2020/02/28/9787121288692/161.jpg" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/28/9787121288692/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《神经网络与深度学习》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：神经网络与深度学习&lt;br /&gt;
作者：吴岸城&lt;br /&gt;
出版社：电子工业出版社&lt;br /&gt;
出版时间：2016-06&lt;br /&gt;
ISBN：9787121288692&lt;/p&gt;
&lt;p&gt;本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。&lt;/p&gt;
&lt;p&gt;对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>《深度学习与图像识别：原理与实践》读书笔记</title>
    <link href="https://2020.iosdevlog.com/2020/02/27/9787111630036/"/>
    <id>https://2020.iosdevlog.com/2020/02/27/9787111630036/</id>
    <published>2020-02-27T11:41:38.000Z</published>
    <updated>2020-02-27T15:39:26.676Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/1.jpg" alt="" /><figcaption>《深度学习与图像识别：原理与实践》</figcaption></figure><p>书名：深度学习与图像识别：原理与实践<br />作者：魏溪含，涂铭，张修鹏<br />出版社：机械工业出版社<br />出版时间：2019-06<br />ISBN：9787111630036</p><a id="more"></a><h2 id="介绍">介绍</h2><p>第 1 章 介绍图像识别的一些应用场景，让读者对图像识别有个初步的认识。<br />第 2 章 主要对图像识别的工程背景做简单介绍，同时介绍了本书后续章 节实战案例中会用到的环境，因此该章 是实战的基础。<br />第 3～6 章 是图像识别的技术基础，包括机器学习、神经网络等。该部分的代码主要使用Python实现。没有机器学习基础的同学需要理解这几章 之后再往下看，有机器学习基础的同学可以有选择地学习。<br />第 7 章 是一个过渡章 节，虽然<br />第 6 章 中手动用Python实现了神经网络，但由于本书后面的图像识别部分主要使用PyTorch实现，因此使用该章 作为过渡，介绍如何使用PyTorch来搭建神经网络。<br />第 8～12章 为图像识别的核心。<br />第 8 章 首先介绍了图像中的卷积神经网络与普通神经网络的异同，并给出了常见的卷积神经网络结构。接下来的<br />第 9 ～12章 分别介绍了图像识别中的检测、分割、产生式模型以及可视化的问题，并在每章 后面给出相应的实战案例。<br />第 13 章 简单介绍了图像识别的工业部署模式，以帮助读者构建一个更完整的知识体系。</p><h2 id="第1章-机器视觉在行业中的应用">第1章 机器视觉在行业中的应用</h2><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/2.jpg" alt="" /><figcaption>人工智能相关领域关系图</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/3.jpg" alt="" /><figcaption>人工智能的第三个“春天”</figcaption></figure><h3 id="机器视觉的主要应用场景">机器视觉的主要应用场景</h3><h4 id="人脸识别face-recognition">人脸识别（Face Recognition）</h4><p>处理过程</p><p>人脸图像采集及检测<br />人脸图像预处理<br />人脸图像特征提取<br />匹配与识别</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/4.jpg" alt="" /><figcaption>人脸识别的主要应用场景</figcaption></figure><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/5.jpg" alt="" /><figcaption>人脸识别应用场景</figcaption></figure><h4 id="视频监控分析">视频监控分析</h4><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/6.jpg" alt="视频监控分析的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/7.jpg" alt="交通异常事件监测" /></p><h4 id="工业瑕疵检测">工业瑕疵检测</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/8.jpg" alt="" /><figcaption>工业瑕疵诊断应用场景</figcaption></figure><h4 id="图片识别分析">图片识别分析</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/9.jpg" alt="" /><figcaption>图片识别应用效果</figcaption></figure><h4 id="自动驾驶驾驶辅助">自动驾驶/驾驶辅助</h4><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/10.jpg" alt="" /><figcaption>自动驾驶汽车应用场景</figcaption></figure><p>技术链</p><ul><li>感知阶段<ol type="1"><li>使用机器视觉获取场景中的深度信息，以帮助进行后续的图像语义理解，在自动驾驶中帮助探索可行驶区域和目标障碍物。</li><li>通过视频预估每一个像素的运动方向和运动速度。</li><li>对物体进行检测与追踪。在无人驾驶中，检测与追踪的目标主要是各种车辆、行人、非机动车。</li><li>对于整个场景的理解。最重要的有两点，第一是道路线检测，其次是在道路线检测下更进一步，即将场景中的每一个像素都打成标签，这也称为场景分割或场景解析。</li><li>同步地图构建和定位技术。</li></ol></li><li>规划阶段</li><li>控制阶段</li></ul><h4 id="三维图像视觉">三维图像视觉</h4><h4 id="医疗影像诊断">医疗影像诊断</h4><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/11.jpg" alt="医疗影像诊断的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/12.jpg" alt="肝脏及结节分割技术" /></p><h4 id="文字识别ocr">文字识别（OCR）</h4><p>计算机文字识别，俗称光学字符识别（Optical Character Recognition），是利用光学扫描技术将票据、报刊、书籍、文稿及其他印刷品的文字转化为图像信息，再利用文字识别技术将图像信息转化为可以使用的计算机输入技术。</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/13.jpg" alt="文字识别技术的应用场景" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/14.jpg" alt="文字识别技术的应用场景" /></p><h4 id="图像视频的生成及设计">图像/视频的生成及设计</h4><h2 id="第2章-图像识别前置技术">第2章 图像识别前置技术</h2><h3 id="深度学习框架">深度学习框架</h3><ul><li>Theano</li><li>Tensorflow</li><li>MXNet</li><li>Keras</li><li>PyTorch</li><li>Caffe</li></ul><h3 id="搭建图像识别开发环境">搭建图像识别开发环境</h3><p>Anaconda</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/16.jpg" alt="Anaconda的下载" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/17.jpg" alt="打开Anaconda进入Jupyter" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/18.jpg" alt="Jupyter notebook界面" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/19.jpg" alt="Anaconda环境测试界面" /></p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/20.jpg" alt="" /><figcaption>通过conda搜索beautifulsoup</figcaption></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建第2~7章代码运行的环境：</span></span><br><span class="line">conda create -n basic_env  python=3.7        <span class="comment"># 创建一个名为basic_env的环境</span></span><br><span class="line"><span class="built_in">source</span> activate basic_env                <span class="comment"># 激活这个环境—Linux和macOS代码</span></span><br><span class="line">activate basic_env                        <span class="comment"># 激活这个环境—Windows代码</span></span><br><span class="line"><span class="comment"># 创建第8~12章代码运行的环境：</span></span><br><span class="line">conda create -n imgrecognition_env  python=3.7</span><br><span class="line">                                                <span class="comment"># 创建一个名为imgrecognition _env的环境</span></span><br><span class="line"><span class="built_in">source</span> activate imgrecognition _env        <span class="comment"># 激活这个环境—Linux和macOS代码</span></span><br><span class="line">activate imgrecognition_env                <span class="comment"># 激活这个环境—Windows代码</span></span><br></pre></td></tr></table></figure><p>Pytorch 的下载与安装</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/22.jpg" alt="" /><figcaption>PyTorch安装界面</figcaption></figure><h3 id="numpy">Numpy</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/24.jpg" alt="创建数组" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/25.jpg" alt="创建数组" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/26.jpg" alt="在Notebook中引入Numpy" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/28.jpg" alt="Numpy预置函数及说明" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/31.jpg" alt="KNN例子" /></p><h2 id="第3章-图像分类之knn算法">第3章 图像分类之KNN算法</h2><h3 id="knn的理论基础与实现">KNN的理论基础与实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/33.jpg" alt="KNN例子的散点图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/34.jpg" alt="电脑看到的图片均为0～255的数字" /></p><h3 id="图像分类识别预备知识">图像分类识别预备知识</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/36.jpg" alt="归一化图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/37.jpg" alt="数字5" /></p><h3 id="knn实战">KNN实战</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/38.jpg" alt="两张图片曼哈顿距离的计算方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/39.jpg" alt="数字7" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/40.jpg" alt="Cifar10数据集示例" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/41.jpg" alt="青蛙图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/42.jpg" alt="整个数据集" /></p><h3 id="模型参数调优">模型参数调优</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/43.jpg" alt="整个数据集拆分成训练集和测试集" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/44.jpg" alt="训练集、验证集和测试集" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/45.jpg" alt="交叉验证的数据拆分方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/46.jpg" alt="图像中具体某个像素值的无意义性" /></p><h2 id="第4章-机器学习基础">第4章 机器学习基础</h2><h3 id="线性回归模型">线性回归模型</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/48.jpg" alt="" /><figcaption>线性回归拟合直线</figcaption></figure><h3 id="逻辑回归模型">逻辑回归模型</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/68.jpg" alt="逻辑回归分类示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/69.jpg" alt="Sigmoid函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/73.jpg" alt="Sigmoid函数图像" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/74.jpg" alt="损失函数示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/75.jpg" alt="一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/76.jpg" alt="学习率η=0.01时，一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/77.jpg" alt="学习率η=0.8时，一元二次损失函数梯度下降过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/78.jpg" alt="学习率η=1.1时，一元二次损失函数不收敛" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/82.jpg" alt="损失函数if y=1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/84.jpg" alt="损失函数if y=0" /></p><h2 id="第5章-神经网络基础">第5章 神经网络基础</h2><h3 id="神经网络">神经网络</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/95.jpg" alt="神经网络全连接结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/96.jpg" alt="多隐藏层结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/97.jpg" alt="神经元结构图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/98.jpg" alt="简单神经元" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/99.jpg" alt="训练网络" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/100.jpg" alt="神经元个数较少" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/101.jpg" alt="神经元个数较多" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/102.jpg" alt="神经元个数更多" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/103.jpg" alt="线性分类图1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/104.jpg" alt="线性分类图2" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/105.jpg" alt="线性不可分" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/106.jpg" alt="激活函数表达能力" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/108.jpg" alt="Sigmoid函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/110.jpg" alt="Tanh函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/111.jpg" alt="ReLU函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/112.jpg" alt="前向传播 1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/113.jpg" alt="节点1节点2" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/116.jpg" alt="前向传播 2" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/118.jpg" alt="增加bias" /></p><h3 id="输出层">输出层</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/119.jpg" alt="Softmax" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/124.jpg" alt="猫狗小鸡分类" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/127.jpg" alt="输出层的神经元个数" /></p><h3 id="批处理">批处理</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/128.jpg" alt="单个处理" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/129.jpg" alt="批处理" /></p><h3 id="广播原则">广播原则</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/130.jpg" alt="广播原则1" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/131.jpg" alt="广播原则2" /></p><h3 id="损失函数">损失函数</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/132.jpg" alt="均方误差" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/136.jpg" alt="交叉熵误差" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/137.jpg" alt="带入Loss函数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/138.jpg" alt="Mini-batch" /></p><h3 id="最优化">最优化</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/139.jpg" alt="" /><figcaption>一维函数求导</figcaption></figure><h2 id="第6章-误差反向传播">第6章 误差反向传播</h2><h3 id="激活函数层的实现">激活函数层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/144.jpg" alt="x+y计算图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/145.jpg" alt="（x+y）*z的计算图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/148.jpg" alt="ReLU反向传播实现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/149.jpg" alt="导数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/150.jpg" alt="Sigmoid反向传播实现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/151.jpg" alt="Sigmoid计算图" /></p><h3 id="affine层的实现">Affine层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/152.jpg" alt="152" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/153.jpg" alt="153" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/154.jpg" alt="154" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/155.jpg" alt="155" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/162.jpg" alt="162" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/163.jpg" alt="163" /></p><h3 id="softmaxwithloss层的实现">Softmaxwithloss层的实现</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/164.jpg" alt="164" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/165.jpg" alt="165" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/166.jpg" alt="166" /></p><h3 id="正则化惩罚">正则化惩罚</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/167.jpg" alt="167" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/169.jpg" alt="169" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/171.jpg" alt="正则化项在神经网络中的重要作用" /></p><h2 id="第7章-pytorch实现神经网络图像分类">第7章 PyTorch实现神经网络图像分类</h2><h3 id="pytorch的使用">PyTorch的使用</h3><p>Variable</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/172.jpg" alt="" /><figcaption>Variable</figcaption></figure><p>激活函数</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/173.jpg" alt="" /><figcaption>激活函数可视化</figcaption></figure><h3 id="pytorch实战">PyTorch实战</h3><h2 id="第8章-卷积神经网络">第8章 卷积神经网络</h2><p>卷积神经网络（Convolutional Neural Network，CNN）是一种深度前馈神经网络，目前在图片分类、图片检索、目标检测、目标分割、目标跟踪、视频分类、姿态估计等图像视频相关领域中已有很多较为成功的应用。</p><h3 id="卷积神经网络基础">卷积神经网络基础</h3><p>全连接层（Fully Connected Layer）</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/174.jpg" alt="" /><figcaption>全连接示意图</figcaption></figure><p>卷积层（Convolution Layer）</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/175.jpg" alt="一维卷积kernel=1*3，stride=1计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/176.jpg" alt="一维卷积kernel=1*3，stride=2计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/177.jpg" alt="二维卷积，kernel=3*3，stride=1计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/178.jpg" alt="二维卷积，kernel=3*3，stride=2计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/179.jpg" alt="三维卷积kernel=553，stride=1，计算过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/181.jpg" alt="卷积神经网络示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/182.jpg" alt="kernel=3*3，pad=1示意图" /></p><p>池化层</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/182.jpg" alt="" /><figcaption>池化filter=2*2，stride=2的最大池化（max pooling）操作</figcaption></figure><h3 id="常见卷积神经网络结构">常见卷积神经网络结构</h3><p>AlexNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/187.jpg" alt="AlexNet" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/188.jpg" alt="ReLUs与tanh作为激活函数在4层卷积神经网络中的收敛速度对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/189.jpg" alt="ILSVRC图像识别分类比赛优胜情况" /></p><p>VGGNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/190.jpg" alt="AlexNet和VGGNet网络结构对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/191.jpg" alt="一维卷积中3组33与1组77kernel效果相同的原理解说图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/192.jpg" alt="VGG16Net网络结构" /></p><p>GoogLeNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/193.jpg" alt="矩阵转换方式" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/194.jpg" alt="简单的inception结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/195.jpg" alt="简单inception结构对应计算量" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/196.jpg" alt="降维的inception结构及计算量推导" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/197.jpg" alt="GoogLeNet网络结构图" /></p><p>ResNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/198.jpg" alt="一个20层和56层卷积神经网络中训练和预测过程中的误差情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/201.jpg" alt="普通卷积层与残差卷积层" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/202.jpg" alt="ResNet网络结构缩略图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/203.jpg" alt="不同网络结构性能对比" /></p><p>ResNeXT</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/204.jpg" alt="加宽的残差网络模块" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/205.jpg" alt="ResNeXT网络模块" /></p><p>DenseNet</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/206.jpg" alt="" /><figcaption>DenseNet核心网络结构</figcaption></figure><h3 id="vgg16实现cifar10分类">VGG16实现Cifar10分类</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/207.jpg" alt="" /><figcaption>VGG16训练Cifar10过程输出</figcaption></figure><h2 id="第9章-目标检测">第9章 目标检测</h2><h3 id="定位分类">定位+分类</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/208.jpg" alt="检测问题定义" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/209.jpg" alt="分类问题vs定位问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/210.jpg" alt="分类+定位网络结构设计" /></p><h3 id="目标检测">目标检测</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/211.jpg" alt="使用定位+分类解决目标检测存在的问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/212.jpg" alt="使用滑窗方法做目标检测存在的问题：滑窗的尺寸、大小、位置不同将产生非常大的计算量" /></p><p>R-CNN</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/213.jpg" alt="R-CNN训练过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/214.jpg" alt="不同压缩方法图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/215.jpg" alt="IOU图示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/217.jpg" alt="R-CNN中的ROI结果微调" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/218.jpg" alt="Fast R-CNN训练和预测过程示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/219.jpg" alt="Fast R-CNN中的ROI Pooling" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/220.jpg" alt="R-CNN和Fast R-CNN训练和测试时间对比" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/221.jpg" alt="Faster R-CNN训练流程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/222.jpg" alt="RPN原理" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/223.jpg" alt="RCNN、Fast R-CNN、Faster R-CNN模型耗时对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/224.jpg" alt="RCNN、Fast R-CNN、Faster R-CNN模型对比" /></p><p>YOLO</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/225.jpg" alt="" /><figcaption>基于PASCAL VOC2012目标检测数据集的YOLO示意图</figcaption></figure><p>SSD</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/226.jpg" alt="SSD特征层与anchor示意图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/227.jpg" alt="SSD结构图" /></p><h3 id="ssd实现voc目标检测">SSD实现VOC目标检测</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/228.jpg" alt="原始图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/229.jpg" alt="语义分割的真实label图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/230.jpg" alt="实例分割的真实label图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/231.jpg" alt="ResNet50训练PASCAL VOC过程部分打印结果展示" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/232.jpg" alt="SSD效果示意图（未完全迭代的结果）" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/233.jpg" alt="SSD作者在VOC2007数据集上达到的效果" /></p><h2 id="第10章-分割">第10章 分割</h2><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/234.jpg" alt="分割问题定义" /></p><p>FCN</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/235.jpg" alt="最简单直观的语义分割方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/236.jpg" alt="改良后的CNN语义分割网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/237.jpg" alt="Unpooling的几种方法" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/238.jpg" alt="卷积和反卷积图例" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/239.jpg" alt="kernel为3、stride为2的1维反卷积计算过程" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/240.jpg" alt="U-Net结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/241.jpg" alt="CrackForest训练数据展示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/242.jpg" alt="U-Net预测CrackForest结果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/243.jpg" alt="SegNet的网络结构" /></p><p>PSPNet</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/244.jpg" alt="语义分割容易出现的问题" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/245.jpg" alt="PSPNet的网络结构" /></p><h3 id="实例分割">实例分割</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/246.jpg" alt="检测、分割任务对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/247.jpg" alt="多任务学习中“head”的设定方法" /></p><p>层叠式</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/248.jpg" alt="" /><figcaption>层叠式实例分割网络结构</figcaption></figure><p>扁平式</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/249.jpg" alt="Mask R-CNN的网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/250.jpg" alt="Mask-RCNN的网络head的设计细节" /></p><h2 id="第11章-产生式模型">第11章 产生式模型</h2><p>机器学习</p><ol type="1"><li>有监督学习</li><li>无监督学习</li><li>强化学习</li></ol><p>数据集</p><ol type="1"><li>数据x</li><li>标签y</li></ol><h3 id="自编码器autoencoder">自编码器（Autoencoder）</h3><h3 id="对抗生成网络">对抗生成网络</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/251.jpg" alt="Autoencoder学习过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/252.jpg" alt="GAN的训练结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/254.jpg" alt="GAN最终使用的产生器" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/255.jpg" alt="产生器生成的一些假图的例子" /></p><h3 id="dcgan及实战">DCGAN及实战</h3><p>DCGAN（Deep Convolutional Generative Adversarial Network）由Radford等人提出，结合了深度卷积神经网络和GAN，并对上述GAN进行了扩展。DCGAN将GAN中的产生器G和判别器D都换成了卷积神经网络，并对其中的卷积做了一些改动以提高收敛速度，具体如下。</p><ol type="1"><li>用不同步长的卷积层替换所有Pooling层。</li><li>在D和G中均使用BatchNorm层。</li><li>在G网络中，除最后一层使用tanh以外，其余层均使用ReLU作为激活函数。</li><li>D网络均使用LeakyRelu作为激活函数。</li></ol><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/256.jpg" alt="DCGAN结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/257.jpg" alt="CelebFaces一些数据的展示" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/258.jpg" alt="产生网络和判别网络的Loss变化情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/259.jpg" alt="真假数据对比图" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/260.jpg" alt="DCGAN在LSUN上生成的卧室图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/261.jpg" alt="GAN和DCGAN在MNIST上的生成效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/262.jpg" alt="生成向量包含的数学信息" /></p><h3 id="lsgan">LSGAN</h3><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/263.jpg" alt="" /><figcaption>不同Loss差异图示</figcaption></figure><h3 id="wgan">WGAN</h3><h3 id="pg-gan">PG-GAN</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/265.jpg" alt="PG-GAN思想" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/266.jpg" alt="PG-GAN中从1616到3232的转换过程" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/267.jpg" alt="PG-GAN产生的高清图片" /></p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/268.jpg" alt="各种GAN方法效果对比" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/269.jpg" alt="一些扩展的GAN可以实现风格转换效果" /></p><h2 id="第12章-神经网络可视化">第12章 神经网络可视化</h2><h3 id="卷积核">卷积核</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/270.jpg" alt="ConvNetJS在Cifar10上训练得到的参数" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/271.jpg" alt="几种常见网络结构的第一层卷积" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/272.jpg" alt="特征层表征" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/273.jpg" alt="卷积神经网络特征层可视化工具" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/274.jpg" alt="不同图片在conv5151上的激活情况，每个特征层都是13*13个像素" /></p><p>通过重构观测</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/275.jpg" alt="“逆”卷积神经网络结构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/276.jpg" alt="反向池化" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/278.jpg" alt="Layer3左上角第一张图的重构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/279.jpg" alt="完全训练的AlexNet在1～5个卷积层中选取被激活最强的9个通道复原后的图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/280.jpg" alt="对图12-4a进行重构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/281.jpg" alt="5个特征层经过不同迭代次数的重构效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/282.jpg" alt="末端CNN特征层的激活情况" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/283.jpg" alt="遮挡不同区域对图片分类的影响" /></p><p>特征层的作用</p><figure><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/284.jpg" alt="" /><figcaption>利用CNN做特征提取可实现图像搜索功能</figcaption></figure><p>图片风格化</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/285.jpg" alt="图片风格化效果" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/290.jpg" alt="CNN在不同层上风格和内容重构的表现" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/291.jpg" alt="示例中的风格图片和内容图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/292.jpg" alt="输入的内容图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/293.jpg" alt="风格化后的图片" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/294.jpg" alt="风格和内容权重的比例对生成图片效果的影响" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/295.jpg" alt="通过大量图片训练得到“风格网络”，从而对输入图片进行快速预测的方法" /></p><h2 id="图像识别算法的部署模式">图像识别算法的部署模式</h2><h3 id="图像算法部署模式介绍">图像算法部署模式介绍</h3><p>基于公共云云计算的计算机集群</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/296.jpg" alt="阿里巴巴云计算公司提供的人脸识别服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/297.jpg" alt="百度云计算公司提供的图像审核服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/298.jpg" alt="腾讯云计算公司提供的图像文字识别OCR服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/299.jpg" alt="AWS云计算公司提供的图像识别服务" /></p><p>基于私有云云计算的计算机集群</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/300.jpg" alt="图像识别算法基于云计算架构的系统架构" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/301.jpg" alt="图像识别算法基于私有云容器的架构" /></p><p>X86架构单机+备份模式</p><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/302.jpg" alt="算法文件封装" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/303.jpg" alt="图像识别算法基于普通X86服务器的部署架构" /></p><h3 id="实际应用场景和部署模式的匹配">实际应用场景和部署模式的匹配</h3><p><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/304.jpg" alt="百度云、阿里云、腾讯云人脸属性识别公有云服务测试响应速度表" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/305.jpg" alt="百度云计算公司在其公有云上提供的图像相关服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/306.jpg" alt="阿里云计算公司在其公有云上提供的图像相关服务" /><br /><img src="https://2020.iosdevlog.com/2020/02/27/9787111630036/307.jpg" alt="腾讯云计算公司在其公有云上提供的图像相关服务" /></p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://2020.iosdevlog.com/2020/02/27/9787111630036/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;figcaption&gt;《深度学习与图像识别：原理与实践》&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;书名：深度学习与图像识别：原理与实践&lt;br /&gt;
作者：魏溪含，涂铭，张修鹏&lt;br /&gt;
出版社：机械工业出版社&lt;br /&gt;
出版时间：2019-06&lt;br /&gt;
ISBN：9787111630036&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书" scheme="https://2020.iosdevlog.com/categories/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="DL" scheme="https://2020.iosdevlog.com/tags/DL/"/>
    
      <category term="CV" scheme="https://2020.iosdevlog.com/tags/CV/"/>
    
  </entry>
  
</feed>
